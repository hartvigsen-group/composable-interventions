defaults:
  - edit: none  # Choose any of [memit, lora, ft]
  - compression: none  # Choose any of [wanda, sparsegpt, gptq, awq]
  - unlearn: none  # Choose any of [rmu]
  - _self_

# model_name: meta-llama/Meta-Llama-3-8B
model_name: microsoft/Phi-3-mini-4k-instruct
dtype: torch.bfloat16
device: 0
# model_parallel: true
model_parallel: false
seed: 42
interventions: []  # List of interventions, choose any number of [edit, compress, unlearn]

# Weights and Biases Settings
wandb: disabled # disabled or online
wandb_entity: "dri-ice"
wandb_project: "Composable_Interventions"
tag: "default"

alg_name: FT # overwritten by edit config but needs to be here
edit_dataset: "zsre"
stats_dir: "/scratch/{USER}/stats"
max_length: 30
batch_size: 50

save: out/
save_model: null
eval_zero_shot: false
compress: false
method: none
sparsity_ratio: 0.0
wbits: 16
compression_dataset: c4
dataset: c4

number_of_edits: 50
edit_set: 1

# The max number of questions per QA set. Should be null for main
# results,but can be set lower for fast debugging~
qa_question_count_limit: null

# RMU configs which can be overwritten
rmu_max_num_batches: 0
rmu_layer_id: -1

# GA configs which can be overwritten
ga_train_size: null
ga_lr: null
ga_retain_weight: 1

load_ckpt: False
ckpt_path: null
save_ckpt: False
