{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font family to serif\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# plotting constants\n",
    "TITLE_FONT_SIZE = 18\n",
    "LEGEND_FONT_SIZE = 12\n",
    "WSPACE = 0.3\n",
    "FIGURE_HEIGHT = 3\n",
    "LINE_WIDTH = 2\n",
    "FIG_SIZE = 3\n",
    "MARKER_SIZE = 8\n",
    "X_LABEL_ROTATION = 20\n",
    "\n",
    "# Set colors for compositons with compression\n",
    "colors = {\"Wanda\": \"C1\", \"SparseGPT\": \"C2\", \"AWQ\": \"C3\", \"GPTQ\": \"C4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull and Dedup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composable_Interventions has all the results\n",
    "project_paths = [\"dri-ice/Composable_Interventions\",]\n",
    "\n",
    "filter_dict = { \"state\": \"finished\" }\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "\n",
    "    # Iterate over eachrun and capture the c        onfig and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-10-29 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "\n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_keep_frame(frame):\n",
    "    if frame[\"edit_dataset\"] == \"zsre\":\n",
    "        return True\n",
    "    \n",
    "    if \"edit\" not in frame[\"interventions\"]:\n",
    "        return True\n",
    "    \n",
    "    print(f\"Skipping {frame['tag']} for edit dataset {frame['edit_dataset']}\")\n",
    "    return False\n",
    "\n",
    "# Sort by \"tag\" and \"_timestamp\" in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# Keep only the current edit dataset\n",
    "all_runs_df = all_runs_df[all_runs_df.progress_apply(lambda x: should_keep_frame(x), axis=1)]\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=[\"tag\", \"_timestamp\"], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit=\"s\")\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=[\"_timestamp\"], ascending=[False])\n",
    "all_runs_df_sorted[\"Avg WMDP\"] = (all_runs_df_sorted[\"wmdp_bio accuracy\"] + all_runs_df_sorted[\"wmdp_cyber accuracy\"]) / 2\n",
    "all_runs_df_sorted = all_runs_df_sorted[all_runs_df_sorted[\"qa_question_count_limit\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the recency column, for example, \"date\"\n",
    "all_runs_df_sorted = all_runs_df_sorted.sort_values(by=\"date\")\n",
    "\n",
    "# Drop duplicates, keeping only the most recent occurrence for each \"tag\" and \"edit_set\"\n",
    "latest_runs_df = all_runs_df_sorted.drop_duplicates(subset=[\"model_name\", \"tag\", \"edit_set\"], keep=\"last\")\n",
    "\n",
    "# Define a function to calculate standard error\n",
    "def standard_error(x):\n",
    "    return x.std() / np.sqrt(len(x))\n",
    "\n",
    "# Group by the \"tag\" column and calculate the mean for numerical columns\n",
    "grouped_df = latest_runs_df.groupby([\"model_name\", \"tag\"]).agg([\"mean\", standard_error])\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "grouped_df.columns = [f\"{col[0]}_{col[1]}\" for col in grouped_df.columns]\n",
    "\n",
    "# Split the columns into means and standard errors\n",
    "mean_columns = [col for col in grouped_df.columns if col.endswith(\"_mean\")]\n",
    "se_columns = [col for col in grouped_df.columns if col.endswith(\"_standard_error\")]\n",
    "\n",
    "# Create separate DataFrames for means and standard errors\n",
    "mean_df = grouped_df[mean_columns].rename(columns=lambda x: x.replace(\"_mean\", \"\"))\n",
    "se_df = grouped_df[se_columns].rename(columns=lambda x: x.replace(\"_standard_error\", \"_se\"))\n",
    "\n",
    "# Merge the means and standard errors back into one DataFrame\n",
    "all_runs_df_sorted_averaged = pd.concat([mean_df, se_df], axis=1).copy()\n",
    "\n",
    "# Reset index if needed\n",
    "all_runs_df_sorted_averaged.reset_index(inplace=True)\n",
    "\n",
    "# Add non-numerical columns from the latest_runs_df\n",
    "non_numerical_columns = latest_runs_df.select_dtypes(exclude=[np.number]).drop_duplicates(subset=[\"model_name\", \"tag\"])\n",
    "all_runs_df_sorted_averaged = all_runs_df_sorted_averaged.merge(non_numerical_columns, on=[\"model_name\", \"tag\"], how=\"left\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "all_runs_df_sorted_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The experiment tags can be inconsistent, so we need to manually map them to standard names\n",
    "def set_tag(experiment_row):\n",
    "    if experiment_row[\"interventions\"] in [None, np.nan]:\n",
    "        return \"NONE\"\n",
    "\n",
    "    intervention_categories = None\n",
    "    if isinstance(experiment_row[\"interventions\"], str):\n",
    "        intervention_categories = ast.literal_eval(experiment_row[\"interventions\"])\n",
    "    else:\n",
    "        intervention_categories = experiment_row[\"interventions\"]\n",
    "\n",
    "    interventions = []\n",
    "    for category in intervention_categories:\n",
    "        category = \"compression\" if category == \"compress\" else category\n",
    "        intervention = experiment_row[category].upper()\n",
    "        if intervention in [\"AWQ\", \"GPTQ\"]:\n",
    "            intervention += str(int(experiment_row[\"wbits\"])) + \"bit\"\n",
    "        if intervention in [\"WANDA\", \"SPARSEGPT\"]:\n",
    "            intervention += str(int(experiment_row[\"sparsity_ratio\"] * 100)) + \"%\"\n",
    "\n",
    "        interventions.append(intervention)\n",
    "    \n",
    "    if len(interventions) == 0:\n",
    "        interventions.append(\"NONE\")\n",
    "\n",
    "    return \"_\".join(interventions)\n",
    "\n",
    "all_runs_df_sorted_averaged[\"tag\"] = all_runs_df_sorted_averaged.progress_apply(set_tag, axis=1)\n",
    "print(all_runs_df_sorted_averaged[all_runs_df_sorted_averaged[\"model_name\"] == \"mistralai/Mistral-7B-Instruct-v0.3\"].value_counts([\"tag\", \"model_name\"]).sort_index())\n",
    "# print(all_runs_df_sorted_averaged[[\"tag\", \"model_name\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to None if empty dict\n",
    "all_runs_df_sorted_averaged[\"edit\"] = all_runs_df_sorted_averaged[\"edit\"].apply(lambda x: None if x == {} else x)\n",
    "all_runs_df_sorted_averaged[\"unlearn\"] = all_runs_df_sorted_averaged[\"unlearn\"].apply(lambda x: None if x == {} else x)\n",
    "all_runs_df_sorted_averaged[\"compression\"] = all_runs_df_sorted_averaged[\"compression\"].apply(lambda x: None if x == {} else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted_averaged.drop_duplicates(subset=[\"model_name\", \"tag\"], keep=\"first\")\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": \"Mistral (7b)\",\n",
    "    \"01-ai/Yi-1.5-9B-Chat\": \"Yi 1.5 (9b)\",\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": \"Phi-3 (3.8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"LoRA\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "}\n",
    "all_runs_df_deduplicated[\"model_name\"] = all_runs_df_deduplicated[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"edit\"] = all_runs_df_deduplicated[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"compression\"] = all_runs_df_deduplicated[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"unlearn\"] = all_runs_df_deduplicated[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = all_runs_df_deduplicated\n",
    "display(all_runs_df_deduplicated.value_counts([\"model_name\", \"tag\"]).sort_index())\n",
    "print(f\"Number of experiments: {len(all_runs_df_deduplicated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Ablation Experments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearning_interventions = []\n",
    "editing_interventions = [\"memit\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Unlearning and compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Editing and compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [], \"edit\": None, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just edit\n",
    "for editor in editing_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just unlearn\n",
    "for unlearner in unlearning_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just pruning\n",
    "for pruner in pruning_interventions:\n",
    "    for pruning_level in pruning_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "# Just quantization\n",
    "for quantizer in quant_interventions:\n",
    "    for quant_level in quant_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "print(f\"Total experiment combinations for Mistral ablation: {len(experiment_combinations)}\")\n",
    "# model_name = \"Mistral (7b)\"\n",
    "model_name = \"Yi 1.5 (9b)\"\n",
    "mistral_tags = set(all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == model_name][\"tag\"].unique())\n",
    "experiment_statuses = []\n",
    "for experiment in experiment_combinations:\n",
    "    experiment_tag = set_tag(experiment)\n",
    "    experiment_statuses.append({\n",
    "        \"experiment_tag\": experiment_tag,\n",
    "        \"first_intervention\": experiment_tag.split(\"_\")[0],\n",
    "        \"second_intervention\": experiment_tag.split(\"_\")[1] if len(experiment_tag.split(\"_\")) > 1 else None,\n",
    "        \"completed\": experiment_tag in mistral_tags,\n",
    "    })\n",
    "\n",
    "experiment_statuses_df = pd.DataFrame(experiment_statuses)\n",
    "experiment_statuses_df.to_csv(\"mistral_experiment_statuses.csv\", index=False)\n",
    "\n",
    "# Percent of experiments completed\n",
    "print(f\"Percent of experiments completed: {experiment_statuses_df['completed'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Missing experiments\n",
    "missing_experiments = experiment_statuses_df[experiment_statuses_df[\"completed\"] == False].sort_values(by=\"experiment_tag\")\n",
    "display(missing_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yi Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearning_interventions = []\n",
    "editing_interventions = [\"memit\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Unlearning and compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Editing and compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [], \"edit\": None, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just edit\n",
    "for editor in editing_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just unlearn\n",
    "for unlearner in unlearning_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just pruning\n",
    "for pruner in pruning_interventions:\n",
    "    for pruning_level in pruning_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "# Just quantization\n",
    "for quantizer in quant_interventions:\n",
    "    for quant_level in quant_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "print(f\"Total experiment combinations for Yi ablation: {len(experiment_combinations)}\")\n",
    "yi_tags = set(all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == \"Yi 1.5 (9b)\"][\"tag\"].unique())\n",
    "experiment_statuses = []\n",
    "for experiment in experiment_combinations:\n",
    "    experiment_tag = set_tag(experiment)\n",
    "    experiment_statuses.append({\n",
    "        \"experiment_tag\": experiment_tag,\n",
    "        \"first_intervention\": experiment_tag.split(\"_\")[0],\n",
    "        \"second_intervention\": experiment_tag.split(\"_\")[1] if len(experiment_tag.split(\"_\")) > 1 else None,\n",
    "        \"completed\": experiment_tag in yi_tags,\n",
    "    })\n",
    "\n",
    "experiment_statuses_df = pd.DataFrame(experiment_statuses)\n",
    "experiment_statuses_df.to_csv(\"mistral_experiment_statuses.csv\", index=False)\n",
    "\n",
    "# Percent of experiments completed\n",
    "print(f\"Percent of experiments completed: {experiment_statuses_df['completed'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Missing experiments\n",
    "missing_experiments = experiment_statuses_df[experiment_statuses_df[\"completed\"] == False].sort_values(by=\"experiment_tag\")\n",
    "display(missing_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Main Results Experiment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Math for determining number of interventions\n",
    "awq_settings = 6\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_df_deduplicated[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UNLEARNING = 3\n",
    "NUM_EDITING = 3\n",
    "NUM_COMPRESSION = 4 + 6 + 6 + 6\n",
    "combination_of_unlearning = 2 * NUM_UNLEARNING * NUM_COMPRESSION\n",
    "combination_of_unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "main_results = all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == \"Llama-3 (8b)\"]\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": main_results[main_results[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1, f\"{len(categories['No Intervention'])} != 1\"\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "# assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 ) - 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "assert len(categories[\"Unlearn\"]) == 3, f\"{len(categories['Unlearn'])} != 3\"\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 9, f\"{len(categories['Edit to Unlearn'])} != 9\"\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 9, f\"{len(categories['Unlearn to Edit'])} != 9\"\n",
    "\n",
    "display(categories[\"Compress to Unlearn\"])\n",
    "assert len(categories[\"Compress to Unlearn\"]) == combination_of_unlearning // 2, f\"{len(categories['Compress to Unlearn'])} != {combination_of_unlearning // 2}\"\n",
    "\n",
    "display(categories[\"Unlearn to Compress\"])\n",
    "assert len(categories[\"Unlearn to Compress\"]) == combination_of_unlearning // 2, f\"{len(categories['Unlearn to Compress'])} != {rmucombination_of_unlearning_count // 2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intervention names and types\n",
    "intervention_names = [intervention for intervention in list(main_results[\"edit\"].unique()) + list(main_results[\"unlearn\"].unique()) + list(main_results[\"compression\"].unique()) if intervention is not None]\n",
    "intervention_type = {\n",
    "    \"LoRA\": \"edit\",\n",
    "    \"MEMIT\": \"edit\",\n",
    "    \"Fine-tune\": \"edit\",\n",
    "    \"SparseGPT\": \"compression\",\n",
    "    \"Wanda\": \"compression\",\n",
    "    \"GPTQ\": \"compression\",\n",
    "    \"AWQ\": \"compression\",\n",
    "    \"RMU\": \"unlearn\",\n",
    "    \"GA\": \"unlearn\",\n",
    "    \"GD\": \"unlearn\",\n",
    "}\n",
    "\n",
    "# Initialize heatmap main_results frames with default values\n",
    "default_value = None\n",
    "mmlu_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Initialize max value main_results frames\n",
    "mmlu_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Populate the heatmap and max value main_results frames\n",
    "for first_intervention in intervention_names:\n",
    "    for second_intervention in intervention_names:\n",
    "        first_intervention_type = intervention_type[first_intervention]\n",
    "        second_intervention_type = intervention_type[second_intervention]\n",
    "        if first_intervention_type == second_intervention_type:\n",
    "            continue\n",
    "\n",
    "        compositions = main_results[(main_results[first_intervention_type] == first_intervention) & (main_results[second_intervention_type] == second_intervention)]\n",
    "        if first_intervention in [\"SparseGPT\", \"Wanda\"] or second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "            compositions = compositions[compositions[\"sparsity_ratio\"] == 0.25]\n",
    "        elif first_intervention in [\"GPTQ\", \"AWQ\"] or second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "            compositions = compositions[compositions[\"wbits\"] == 4]\n",
    "        \n",
    "        assert len(compositions) == 2, f\"Expected 2 compositions for {first_intervention} and {second_intervention}, but found {len(compositions)}\"\n",
    "        \n",
    "        # Calculate OIs\n",
    "        mmlu_diff = abs(compositions[\"mmlu accuracy\"].iloc[0] - compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_oi_main_results[first_intervention][second_intervention] = mmlu_diff\n",
    "        \n",
    "        avg_wmdp_diff = abs(((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2) - ((compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2)).round(4)\n",
    "        wmdp_oi_main_results[first_intervention][second_intervention] = avg_wmdp_diff\n",
    "        \n",
    "        edit_diff = abs(compositions[\"Rewrite accuracy\"].iloc[0] - compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_oi_main_results[first_intervention][second_intervention] = edit_diff\n",
    "\n",
    "        generalization_diff = abs(compositions[\"Generalization\"].iloc[0] - compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_oi_main_results[first_intervention][second_intervention] = generalization_diff\n",
    "\n",
    "        locality_diff = abs(compositions[\"Locality\"].iloc[0] - compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_oi_main_results[first_intervention][second_intervention] = locality_diff\n",
    "        \n",
    "        # Calculate MCE values\n",
    "        mmlu_mce = 1 - max(compositions[\"mmlu accuracy\"].iloc[0], compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_mce_main_results[first_intervention][second_intervention] = mmlu_mce\n",
    "        \n",
    "        avg_wmdp_acc = min((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2, (compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2).round(4)\n",
    "        wmdp_mce_main_results[first_intervention][second_intervention] = avg_wmdp_acc\n",
    "        \n",
    "        edit_mce = 1 - max(compositions[\"Rewrite accuracy\"].iloc[0], compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_mce_main_results[first_intervention][second_intervention] = edit_mce\n",
    "\n",
    "        generalization_mce = 1 - max(compositions[\"Generalization\"].iloc[0], compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_mce_main_results[first_intervention][second_intervention] = generalization_mce\n",
    "\n",
    "        locality_mce = 1 - max(compositions[\"Locality\"].iloc[0], compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_mce_main_results[first_intervention][second_intervention] = locality_mce\n",
    "\n",
    "# Display the results\n",
    "print(\"MMLU OI\")\n",
    "display(mmlu_oi_main_results)\n",
    "\n",
    "print(\"MMLU MCE Values\")\n",
    "display(mmlu_mce_main_results)\n",
    "\n",
    "print(\"WMDP OI\")\n",
    "display(wmdp_oi_main_results)\n",
    "\n",
    "print(\"WMDP MCE Values\")\n",
    "display(wmdp_mce_main_results)\n",
    "\n",
    "print(\"Rewrite OI\")\n",
    "display(edit_oi_main_results)\n",
    "\n",
    "print(\"Rewrite MCE Values\")\n",
    "display(edit_mce_main_results)\n",
    "\n",
    "print(\"Generalization OI\")\n",
    "display(generalization_oi_main_results)\n",
    "\n",
    "print(\"Generalization MCE Values\")\n",
    "display(generalization_mce_main_results)\n",
    "\n",
    "print(\"Locality OI\")\n",
    "display(locality_oi_main_results)\n",
    "\n",
    "print(\"Locality MCE Values\")\n",
    "display(locality_mce_main_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_order = [\"Wanda\", \"SparseGPT\", \"AWQ\", \"GPTQ\"]\n",
    "editor_order = [\"Fine-tune\", \"MEMIT\", \"LoRA\"]\n",
    "unlearn_order = [\"GA\", \"GD\", \"RMU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    elif value > .995:\n",
    "        return '1'\n",
    "    else:\n",
    "        return f'{value:.2f}'[1:] if value < 1 else f'{value:.2f}'\n",
    "\n",
    "def latex_bold_if_min(value: str, max_value: float):\n",
    "    return f'\\\\textbf{{{value}}}' if value == format_value(min_value) else value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13} \\cmidrule(lr){14-19}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13} \\cmidrule(lr){14-16} \\cmidrule(lr){17-19}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-19}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = f\"        {compressor}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc(\n",
    "    edit_mce_main_results,\n",
    "    edit_oi_main_results,\n",
    "    generalization_mce_main_results,\n",
    "    generalization_oi_main_results,\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Row Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc_edit_only(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, edit_interventions, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_edit_only(\n",
    "    edit_mce_main_results,\n",
    "    edit_oi_main_results,\n",
    "    generalization_mce_main_results,\n",
    "    generalization_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Row: Locality & MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_locality_and_mmlu(locality_mce_df, locality_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{Locality}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(locality_mce_df, locality_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "\n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "    \n",
    "    print(latex_code)\n",
    "\n",
    "generate_latex_table_ke_locality_and_mmlu(\n",
    "    locality_mce_main_results,\n",
    "    locality_oi_main_results,\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row: MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc_mmlu_only(mmlu_mce_df, mmlu_oi_df, editor_order, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-7}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_mmlu_only(\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MU ←→ MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_mu_mc():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_main_results, wmdp_oi_main_results), (mmlu_mce_main_results, mmlu_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for unlearner in unlearn_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[unlearner][compressor])}\"\n",
    "                    row_values.append(sub_metric[unlearner][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_mu_mc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mu_ke_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(edit_mce_main_results, edit_oi_main_results), (generalization_mce_main_results, generalization_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_ke_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Row: MU Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_ke_mu_mu_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_main_results, wmdp_oi_main_results), (mmlu_mce_main_results, mmlu_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_mu_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Detailed Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None    : Done\n",
    "- KE ←→ MC: Done\n",
    "- MC ←→ KE: Done\n",
    "- KE ←→ MU: Todo\n",
    "- MU ←→ KE: Todo\n",
    "- MU ←→ MC: Todo\n",
    "- MC ←→ MU: Todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_formatting_map = {\n",
    "    \"awq\": \"AWQ\",\n",
    "    \"gptq\": \"GPTQ\",\n",
    "    \"sparsegpt\": \"SparseGPT\",\n",
    "    \"wanda\": \"Wanda\",\n",
    "    \"ft\": \"FT\",\n",
    "    \"memit\": \"MEMIT\",\n",
    "    \"lora\": \"LoRA\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "    \"rmu\": \"RMU\",\n",
    "}\n",
    "appendix_compositions_order = [\n",
    "    [],\n",
    "    [\"compress\"],\n",
    "    [\"edit\"],\n",
    "    [\"edit\", \"compress\"],\n",
    "    [\"compress\", \"edit\"],\n",
    "    [\"unlearn\"],\n",
    "    [\"unlearn\", \"compress\"],\n",
    "    [\"compress\", \"unlearn\"],\n",
    "    [\"edit\", \"unlearn\"],\n",
    "    [\"unlearn\", \"edit\"],\n",
    "]\n",
    "appendix_table_columns_map = {\n",
    "    \"tag\": \"Composition\",\n",
    "    \"Rewrite accuracy\": \"Edit Success\",\n",
    "    \"Generalization\": \"Generalization\",\n",
    "    \"Locality\": \"Locality\",\n",
    "    \"Average bits\": \"Avg. Bits\",\n",
    "    \"Avg WMDP\": \"Avg. WMDP\",\n",
    "    \"mmlu accuracy\": \"MMLU\",\n",
    "    \"PPL\": \"WikiText PPL\",\n",
    "}\n",
    "appendix_technique_ordering = {\n",
    "    \"edit\": [\"Fine-tune\", \"MEMIT\", \"LoRA\"],\n",
    "    \"compress\": [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"],\n",
    "    \"unlearn\": [\"GA\", \"GD\", \"RMU\"],\n",
    "}\n",
    "\n",
    "\n",
    "def get_composition_label(row):\n",
    "    composition = row[\"interventions\"]\n",
    "    if composition == []:\n",
    "        return \"None\"\n",
    "    \n",
    "    first_intervention_type = composition[0] if composition[0] != \"compress\" else \"compression\"\n",
    "    first_intervention = technique_formatting_map.get(row[first_intervention_type], row[first_intervention_type])\n",
    "    if first_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        first_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif first_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        first_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    if len(composition) == 1:\n",
    "        return first_intervention\n",
    "    \n",
    "    second_intervention_type = composition[1] if composition[1] != \"compress\" else \"compression\"\n",
    "    second_intervention = technique_formatting_map.get(row[second_intervention_type], row[second_intervention_type])\n",
    "    if second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        second_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        second_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    return first_intervention + r\"$\\rightarrow$\" + second_intervention\n",
    "\n",
    "\n",
    "appendix_results = main_results.copy()\n",
    "appendix_results[\"interventions\"] = appendix_results[\"interventions\"].apply(lambda x : ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "appendix_results[\"Label\"] = appendix_results.apply(get_composition_label, axis=1)\n",
    "appendix_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendix_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: Single Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(appendix_table_columns_map.keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# None\n",
    "appendix_no_compositons = appendix_results[appendix_results[\"interventions\"].apply(lambda x: len(x) == 0)]\n",
    "latex_code += r\"   {None}\"\n",
    "for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "    latex_code += f\" & {appendix_no_compositons[col].mean():.2f}\"\n",
    "\n",
    "latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Edit Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_edit_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\"])]\n",
    "display(appendix_edit_only.value_counts(\"edit\"))\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    appendix_edit_only_technique = appendix_edit_only[appendix_edit_only[\"edit\"] == edit_technique]\n",
    "    assert len(appendix_edit_only_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    technique_row_label = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\"& {round(appendix_edit_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Compress Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_compress_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_only_technique = appendix_compress_only[appendix_compress_only[\"compression\"] == compress_technique]\n",
    "    assert len(appendix_compress_only_technique) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(appendix_compress_only_technique[compression_strength_column].unique())\n",
    "    for compression_strength in compression_strength_ordering:\n",
    "        technique_row_label = compress_technique\n",
    "        current_compression = appendix_compress_only_technique[appendix_compress_only_technique[compression_strength_column] == compression_strength]\n",
    "        if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "            technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "        elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "            technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "        \n",
    "        latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "        \n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Unlearn Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_unlearn_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    appendix_unlearn_only_technique = appendix_unlearn_only[appendix_unlearn_only[\"unlearn\"] == unlearn_technique]\n",
    "    assert len(appendix_unlearn_only_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    technique_row_label = unlearn_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\" & {round(appendix_unlearn_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_edit_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    appendix_edit_compress_edit_technique = appendix_edit_compress[appendix_edit_compress[\"edit\"] == edit_technique]\n",
    "    assert len(appendix_edit_compress_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        appendix_edit_compress_technique_frame = appendix_edit_compress_edit_technique[appendix_edit_compress_edit_technique[\"compression\"] == compress_technique]\n",
    "        assert len(appendix_edit_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_edit_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_edit_compress_technique_frame[appendix_edit_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_edit_technique_frame = appendix_compress_edit[appendix_compress_edit[\"compression\"] == compress_technique]\n",
    "    assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_edit_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "    print(f\"Technique: {compress_technique}, Strengths: {compression_strength_ordering}\")\n",
    "\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        appendix_compress_edit_edit_technique = appendix_compress_edit_technique_frame[appendix_compress_edit_technique_frame[\"edit\"] == edit_technique]\n",
    "        assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_edit_edit_technique[round(appendix_compress_edit_edit_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: MU ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Compression\n",
    "appendix_unlearn_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    appendix_unlearn_compress_unlearn_technique = appendix_unlearn_compress[appendix_unlearn_compress[\"unlearn\"] == unlearn_technique]\n",
    "    assert len(appendix_unlearn_compress_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        appendix_unlearn_compress_technique_frame = appendix_unlearn_compress_unlearn_technique[appendix_unlearn_compress_unlearn_technique[\"compression\"] == compress_technique]\n",
    "        assert len(appendix_unlearn_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_unlearn_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_unlearn_compress_technique_frame[appendix_unlearn_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Compression -> Unlearn\n",
    "appendix_compress_unlearn = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_unlearn_technique_frame = appendix_compress_unlearn[appendix_compress_unlearn[\"compression\"] == compress_technique.lower()]\n",
    "    assert len(appendix_compress_unlearn_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_unlearn_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_unlearn_unlearn_technique = appendix_compress_unlearn_technique_frame[appendix_compress_unlearn_technique_frame[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_unlearn_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_unlearn_unlearn_technique[round(appendix_compress_unlearn_unlearn_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                assert len(current_compression) == 1, f\"Multiple rows found for {compress_technique} -> {unlearn_technique} -> {compression_strength}\"\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Edit -> Unlearn\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    appendix_compress_edit_edit_technique = appendix_compress_edit[appendix_compress_edit[\"edit\"] == formatted_edit_technique.lower()]\n",
    "    assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_edit_technique_frame = appendix_compress_edit_edit_technique[appendix_compress_edit_edit_technique[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {unlearn_technique}\"\n",
    "\n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = edit_technique\n",
    "        latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_compress_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Edit\n",
    "appendix_unlearn_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    formatted_unlearn_technique = unlearn_technique\n",
    "    appendix_unlearn_edit_unlearn_technique = appendix_unlearn_edit[appendix_unlearn_edit[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "    assert len(appendix_unlearn_edit_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "        appendix_unlearn_edit_technique_frame = appendix_unlearn_edit_unlearn_technique[appendix_unlearn_edit_unlearn_technique[\"edit\"] == formatted_edit_technique.lower()]\n",
    "        assert len(appendix_unlearn_edit_technique_frame) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = unlearn_technique\n",
    "        latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_unlearn_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_label(row):\n",
    "    interventions = row[\"interventions\"]\n",
    "    first_method = \"\"\n",
    "    second_method = \"\"\n",
    "    if interventions[0] == \"edit\":\n",
    "        first_method = row[\"edit\"]\n",
    "    elif interventions[0] == \"compress\":\n",
    "        first_method = row[\"compression\"]\n",
    "    elif interventions[0] == \"unlearn\":\n",
    "        first_method = row[\"unlearn\"]\n",
    "    \n",
    "    if interventions[1] == \"edit\":\n",
    "        second_method = row[\"edit\"]\n",
    "    elif interventions[1] == \"compress\":\n",
    "        second_method = row[\"compression\"]\n",
    "    elif interventions[1] == \"unlearn\":\n",
    "        second_method = row[\"unlearn\"]\n",
    "    \n",
    "    return f\"{first_method}→{second_method}\"\n",
    "\n",
    "def wrap_label(interventions):\n",
    "    first_intervention, second_intervention = interventions[0], interventions[1]\n",
    "    first_letter_upper = first_intervention[0].upper()\n",
    "    second_letter_upper = second_intervention[0].upper()\n",
    "    \n",
    "    # EX: E $\\rightarrow$ C\n",
    "    return f\"{first_letter_upper}$\\\\rightarrow${second_letter_upper}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock records for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want instances where editing has been applied but there is no unlearning or compression. In these cases, set wbits=16 and sparsity=0 \n",
    "baseline_editors = main_results[(main_results[\"edit\"].notnull()) & (main_results[\"unlearn\"].isnull()) & (main_results[\"compression\"].isnull()) & (main_results[\"interventions\"].apply(lambda x: x == [\"edit\"]))].copy()\n",
    "baseline_editors[\"wbits\"] = 16\n",
    "baseline_editors[\"sparsity_ratio\"] = 0\n",
    "news_records = []\n",
    "\n",
    "# Edit and Compress\n",
    "for editing_method in [\"LoRA\", \"MEMIT\", \"Fine-tune\"]:\n",
    "    baseline_record = baseline_editors[baseline_editors[\"edit\"] == editing_method]\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        edit_first_record = baseline_record.copy()\n",
    "        edit_first_record[\"compression\"] = compression_method\n",
    "        edit_first_record[\"interventions\"] = [[\"edit\", \"compress\"]]\n",
    "        edit_first_record[\"sparsity_ratio\"] = 0\n",
    "        edit_first_record[\"wbits\"] = 16\n",
    "        news_records.append(edit_first_record)\n",
    "\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"edit\"]]\n",
    "        compress_first_record[\"sparsity_ratio\"] = 0\n",
    "        compress_first_record[\"wbits\"] = 16\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "baseline_unlearners = main_results[(main_results[\"edit\"].isnull()) & (main_results[\"unlearn\"].notnull()) & (main_results[\"compression\"].isnull()) & (main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"]))].copy()\n",
    "\n",
    "# Compress and Unlearn\n",
    "for unlearn_method in [\"RMU\", \"GA\", \"GD\"]:\n",
    "    baseline_record = baseline_unlearners[baseline_unlearners[\"unlearn\"] == unlearn_method]\n",
    "\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"unlearn\"] = unlearn_method\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"unlearn\"]]\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "        unlearn_first_record = baseline_record.copy()\n",
    "        unlearn_first_record[\"unlearn\"] = unlearn_method\n",
    "        unlearn_first_record[\"compression\"] = compression_method\n",
    "        unlearn_first_record[\"interventions\"] = [[\"unlearn\", \"compress\"]]\n",
    "        news_records.append(unlearn_first_record)\n",
    "\n",
    "baseline_records = pd.concat(news_records)\n",
    "data = pd.concat([main_results, baseline_records])\n",
    "baseline_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing and Compresion Single Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: KE ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "\n",
    "row_metrics = {\n",
    "    0: \"Rewrite accuracy\",\n",
    "    1: \"Generalization\",\n",
    "    2: \"Locality\",\n",
    "    3: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    0: r\"Edit Success$ \\uparrow$\",\n",
    "    1: r\"Generalization$ \\uparrow$\",\n",
    "    2: r\"Locality$ \\uparrow$\",\n",
    "    3: r\"MMLU$ \\uparrow$\"\n",
    "}\n",
    "column_edit_methods = {\n",
    "    0: \"MEMIT\",\n",
    "    1: \"LoRA\",\n",
    "    2: \"Fine-tune\",\n",
    "    3: \"MEMIT\",\n",
    "    4: \"LoRA\",\n",
    "    5: \"Fine-tune\"\n",
    "}\n",
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}\n",
    "final_row_index = len(row_labels) - 1\n",
    "\n",
    "fig, axes = plt.subplots(len(row_labels), 6, figsize=(6 * FIG_SIZE, len(row_labels) * FIG_SIZE))\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"edit\"] == column_edit_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"MEMIT\", \"LoRA\", \"Fine-tune\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index != final_row_index:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        else:\n",
    "            ax.set_ylim(0.2, 0.65)\n",
    "            ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "        if y_metric == \"Locality\":\n",
    "            ax.set_ylim(0, .2)\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_edit_methods[col_index] if column_edit_methods[col_index] != \"Fine-tune\" else \"FT\"\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[row_index], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == len(row_labels) - 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == final_row_index:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_editors_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Unlearning ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "pruning_frame[\"unlearn\"] = pruning_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "quantization_frame[\"unlearn\"] = quantization_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(2, 6, figsize=(6 * FIG_SIZE, 2 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    \"Avg WMDP\": r\"WMDP $\\downarrow$\",\n",
    "    \"mmlu accuracy\": r\"MMLU $\\uparrow$\"\n",
    "}\n",
    "row_label_map = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\"\n",
    "}\n",
    "column_unlearn_methods = {\n",
    "    0: \"GA\",\n",
    "    1: \"GD\",\n",
    "    2: \"RMU\",\n",
    "    3: \"GA\",\n",
    "    4: \"GD\",\n",
    "    5: \"RMU\",\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    \n",
    "    # GA and WANDA + SparseGPT\n",
    "    0: [(\"GA→SparseGPT\", \"SparseGPT→GA\"), (\"GA→Wanda\", \"Wanda→GA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    1: [(\"GD→SparseGPT\", \"SparseGPT→GD\"), (\"GD→Wanda\", \"Wanda→GD\")],\n",
    "    # RMU and WANDA + SparseGPT\n",
    "    2: [(\"RMU→SparseGPT\", \"SparseGPT→RMU\"), (\"RMU→Wanda\", \"Wanda→RMU\")],\n",
    "    # GA and GPTQ + AWQ\n",
    "    3: [(\"GA→GPTQ\", \"GPTQ→GA\"), (\"GA→AWQ\", \"AWQ→GA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    4: [(\"GD→GPTQ\", \"GPTQ→GD\"), (\"GD→AWQ\", \"AWQ→GD\")],\n",
    "    # RMU and GPTQ + AWQ\n",
    "    5: [(\"RMU→GPTQ\", \"GPTQ→RMU\"), (\"RMU→AWQ\", \"AWQ→RMU\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"unlearn\"] == column_unlearn_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"RMU\", \"GA\", \"GD\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "        ax.set_ylim(0.20, 0.65)\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_unlearn_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[list(row_labels.keys())[row_index]], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_unlearn_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
