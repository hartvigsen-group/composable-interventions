{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font family to serif\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# plotting constants\n",
    "TITLE_FONT_SIZE = 18\n",
    "LEGEND_FONT_SIZE = 12\n",
    "WSPACE = 0.3\n",
    "FIGURE_HEIGHT = 3\n",
    "LINE_WIDTH = 2\n",
    "FIG_SIZE = 3\n",
    "MARKER_SIZE = 8\n",
    "X_LABEL_ROTATION = 20\n",
    "\n",
    "# Set colors for compositons with compression\n",
    "colors = {\"Wanda\": \"C1\", \"SparseGPT\": \"C2\", \"AWQ\": \"C3\", \"GPTQ\": \"C4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull and Dedup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:   0%|          | 0/8765 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run 27f8pxs0: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run n0iel6ok: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  26%|██▋       | 2301/8765 [00:17<01:03, 101.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run arid375k: '_timestamp'\n",
      "Error processing run r6kpsu09: '_timestamp'\n",
      "Error processing run sdhehb2z: '_timestamp'\n",
      "Error processing run 2nv88i8v: '_timestamp'\n",
      "Error processing run 31j4yjsr: '_timestamp'\n",
      "Error processing run o1ai36xl: '_timestamp'\n",
      "Error processing run 7t3n8sq1: '_timestamp'\n",
      "Error processing run cc3cmdlj: '_timestamp'\n",
      "Error processing run 1wj0u6cj: '_timestamp'\n",
      "Error processing run 64ed5z4t: '_timestamp'\n",
      "Error processing run 71jdht68: '_timestamp'\n",
      "Error processing run 2do500pc: '_timestamp'\n",
      "Error processing run lrh5z3wp: '_timestamp'\n",
      "Error processing run luhstpn5: '_timestamp'\n",
      "Error processing run isna6rgu: '_timestamp'\n",
      "Error processing run um0dxn3y: '_timestamp'\n",
      "Error processing run mje2wvj7: '_timestamp'\n",
      "Error processing run evuxnltk: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  57%|█████▋    | 5001/8765 [00:39<00:38, 98.72it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run 1tr3e1m4: '_timestamp'\n",
      "Error processing run 1z3gnedp: '_timestamp'\n",
      "Error processing run 54ohzkld: '_timestamp'\n",
      "Error processing run aq2oaxur: '_timestamp'\n",
      "Error processing run 7oaha4p2: '_timestamp'\n",
      "Error processing run a1ri8lbk: '_timestamp'\n",
      "Error processing run bqi05lpe: '_timestamp'\n",
      "Error processing run h512597d: '_timestamp'\n",
      "Error processing run iv5ul1n7: '_timestamp'\n",
      "Error processing run lmaany12: '_timestamp'\n",
      "Error processing run s64e9fxo: '_timestamp'\n",
      "Error processing run wt59w8pr: '_timestamp'\n",
      "Error processing run 117s16id: '_timestamp'\n",
      "Error processing run 2jggmjk7: '_timestamp'\n",
      "Error processing run sblvym9w: '_timestamp'\n",
      "Error processing run u2uaxi9s: '_timestamp'\n",
      "Error processing run x21qup6h: '_timestamp'\n",
      "Error processing run m9q8fawv: '_timestamp'\n",
      "Error processing run n1nj8xq5: '_timestamp'\n",
      "Error processing run j50re1is: '_timestamp'\n",
      "Error processing run 9pywqyfi: '_timestamp'\n",
      "Error processing run n36d9wfy: '_timestamp'\n",
      "Error processing run tsostb8c: '_timestamp'\n",
      "Error processing run kt9u2jjl: '_timestamp'\n",
      "Error processing run trmp0j62: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  71%|███████▏  | 6251/8765 [00:50<00:18, 134.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run ustm079w: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  72%|███████▏  | 6301/8765 [00:50<00:18, 131.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run x4zeo5mn: '_timestamp'\n",
      "Error processing run 4cx23357: '_timestamp'\n",
      "Error processing run pzbmjnlx: '_timestamp'\n",
      "Error processing run sgw1bwq3: '_timestamp'\n",
      "Error processing run w44vemk4: '_timestamp'\n",
      "Error processing run 4u2krnmr: '_timestamp'\n",
      "Error processing run ezsnt0g5: '_timestamp'\n",
      "Error processing run ilvfkzv1: '_timestamp'\n",
      "Error processing run syb2xqv3: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  77%|███████▋  | 6751/8765 [00:54<00:20, 100.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run b9l540xx: '_timestamp'\n",
      "Error processing run choi1k81: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  78%|███████▊  | 6801/8765 [00:54<00:18, 104.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run eqa5mopp: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  78%|███████▊  | 6851/8765 [00:55<00:17, 108.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run 9buz1998: '_timestamp'\n",
      "Error processing run 886uc8iw: '_timestamp'\n",
      "Error processing run r9giysve: '_timestamp'\n",
      "Error processing run mhvullqf: '_timestamp'\n",
      "Error processing run e3h9gw6u: '_timestamp'\n",
      "Error processing run xl827wv8: '_timestamp'\n",
      "Error processing run sj3fikwq: '_timestamp'\n",
      "Error processing run 5iuwtu93: '_timestamp'\n",
      "Error processing run z0zdi9rt: '_timestamp'\n",
      "Error processing run o96r1eri: '_timestamp'\n",
      "Error processing run qpbntab7: '_timestamp'\n",
      "Error processing run 0zajxvii: '_timestamp'\n",
      "Error processing run 70jjkyi8: '_timestamp'\n",
      "Error processing run mr5hepax: '_timestamp'\n",
      "Error processing run tyyr84xe: '_timestamp'\n",
      "Error processing run ubwgkh20: '_timestamp'\n",
      "Error processing run s9y8jjqc: '_timestamp'\n",
      "Error processing run wxhmtvc3: '_timestamp'\n",
      "Error processing run j8q837ii: '_timestamp'\n",
      "Error processing run y6su2u0y: '_timestamp'\n",
      "Error processing run 50u5183e: '_timestamp'\n",
      "Error processing run 1sv3orzy: '_timestamp'\n",
      "Error processing run 4h1svpsz: '_timestamp'\n",
      "Error processing run tng580q6: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 8765/8765 [01:13<00:00, 119.63it/s]\n"
     ]
    }
   ],
   "source": [
    "# Composable_Interventions has all the results\n",
    "project_paths = [\"dri-ice/Composable_Interventions\",]\n",
    "\n",
    "filter_dict = { \"state\": \"finished\" }\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "\n",
    "    # Iterate over eachrun and capture the c        onfig and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-10-29 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "\n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2553952999.py:12: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
      "100%|██████████| 6726/6726 [00:00<00:00, 399242.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping lora-to-SparseGPT0.45% for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.25% for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset mquake\n",
      "Skipping Wanda0.25%-to-lora for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-lora for edit dataset mquake\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset mquake\n",
      "Skipping lora-to-Wanda0.65% for edit dataset mquake\n",
      "Skipping lora-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping lora-to-AWQ2bit for edit dataset mquake\n",
      "Skipping AWQ4bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ8bit-to-lora for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset mquake\n",
      "Skipping ft-to-Wanda0.45% for edit dataset mquake\n",
      "Skipping ft-to-Wanda0.65% for edit dataset mquake\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset mquake\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset mquake\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset mquake\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset mquake\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.45% for edit dataset mquake\n",
      "Skipping Wanda0.45%-to-lora for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-lora for edit dataset mquake\n",
      "Skipping SparseGPT0.25%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-lora for edit dataset mquake\n",
      "Skipping SparseGPT0.45%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-lora for edit dataset mquake\n",
      "Skipping SparseGPT0.65%-to-lora for edit dataset counterfact\n",
      "Skipping lora-to-AWQ2bit for edit dataset mquake\n",
      "Skipping lora-to-AWQ2bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ4bit for edit dataset mquake\n",
      "Skipping lora-to-AWQ4bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ8bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ8bit for edit dataset mquake\n",
      "Skipping AWQ2bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ2bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ4bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ4bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ8bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ8bit-to-lora for edit dataset counterfact\n",
      "Skipping rmu-lora for edit dataset counterfact\n",
      "Skipping lora-rmu for edit dataset counterfact\n",
      "Skipping rmu-ft for edit dataset counterfact\n",
      "Skipping rmu-memit for edit dataset counterfact\n",
      "Skipping ft-rmu for edit dataset counterfact\n",
      "Skipping rmu-ft for edit dataset mquake\n",
      "Skipping rmu-lora for edit dataset mquake\n",
      "Skipping memit-rmu for edit dataset counterfact\n",
      "Skipping rmu-lora for edit dataset counterfact\n",
      "Skipping rmu-memit for edit dataset mquake\n",
      "Skipping rmu-ft for edit dataset counterfact\n",
      "Skipping rmu-memit for edit dataset counterfact\n",
      "Skipping memit-rmu for edit dataset mquake\n",
      "Skipping lora-rmu for edit dataset counterfact\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping lora-gd for edit dataset mquake\n",
      "Skipping gd-memit for edit dataset mquake\n",
      "Skipping gd-ft for edit dataset counterfact\n",
      "Skipping gd-memit for edit dataset counterfact\n",
      "Skipping gd-ft for edit dataset mquake\n",
      "Skipping memit-gd for edit dataset mquake\n",
      "Skipping lora-gd for edit dataset counterfact\n",
      "Skipping ft-gd for edit dataset counterfact\n",
      "Skipping ft-gd for edit dataset mquake\n",
      "Skipping memit-gd for edit dataset counterfact\n",
      "Skipping gd-lora for edit dataset mquake\n",
      "Skipping gd-lora for edit dataset counterfact\n",
      "Skipping ga-lora for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping ga-lora for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping lora-ga for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping lora-ga for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping ga-lora for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping ga-lora for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping lora-ga for edit dataset mquake\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping lora-ga for edit dataset counterfact\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping gd-lora for edit dataset mquake\n",
      "Skipping gd-ft for edit dataset mquake\n",
      "Skipping gd-memit for edit dataset mquake\n",
      "Skipping gd-memit for edit dataset counterfact\n",
      "Skipping gd-ft for edit dataset counterfact\n",
      "Skipping gd-lora for edit dataset counterfact\n",
      "Skipping lora-gd for edit dataset mquake\n",
      "Skipping ft-gd for edit dataset mquake\n",
      "Skipping memit-gd for edit dataset mquake\n",
      "Skipping lora-gd for edit dataset counterfact\n",
      "Skipping ft-gd for edit dataset counterfact\n",
      "Skipping memit-gd for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def should_keep_frame(frame):\n",
    "    if frame[\"edit_dataset\"] == \"zsre\":\n",
    "        return True\n",
    "    \n",
    "    if \"edit\" not in frame[\"interventions\"]:\n",
    "        return True\n",
    "    \n",
    "    print(f\"Skipping {frame['tag']} for edit dataset {frame['edit_dataset']}\")\n",
    "    return False\n",
    "\n",
    "# Sort by \"tag\" and \"_timestamp\" in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# Keep only the current edit dataset\n",
    "all_runs_df = all_runs_df[all_runs_df.progress_apply(lambda x: should_keep_frame(x), axis=1)]\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=[\"tag\", \"_timestamp\"], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit=\"s\")\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=[\"_timestamp\"], ascending=[False])\n",
    "all_runs_df_sorted[\"Avg WMDP\"] = (all_runs_df_sorted[\"wmdp_bio accuracy\"] + all_runs_df_sorted[\"wmdp_cyber accuracy\"]) / 2\n",
    "all_runs_df_sorted = all_runs_df_sorted[all_runs_df_sorted[\"qa_question_count_limit\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: ['_timestamp', 'edit_set', 'number_of_edits', 'rmu_layer_id', 'wbits', 'sparsity_ratio', 'mmlu accuracy', 'wmdp_bio accuracy', 'wmdp_cyber accuracy', 'Generalization', 'Success recall', 'Generalization recall', 'Locality', 'Average bits', 'Rewrite accuracy', 'Local recall', 'Latency', 'Avg WMDP']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>wbits</th>\n",
       "      <th>sparsity_ratio</th>\n",
       "      <th>mmlu accuracy</th>\n",
       "      <th>wmdp_bio accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>compression</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>compression_dataset</th>\n",
       "      <th>qa_question_count_limit</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL edits</th>\n",
       "      <th>PPl QA</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01-ai/Yi-1.5-9B-Chat</td>\n",
       "      <td>AWQ2bit</td>\n",
       "      <td>1.727392e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229454</td>\n",
       "      <td>0.246661</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>8100276.5</td>\n",
       "      <td>8778113</td>\n",
       "      <td>7557045</td>\n",
       "      <td>-1</td>\n",
       "      <td>6354282</td>\n",
       "      <td>2024-09-26 23:14:58.334940910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>01-ai/Yi-1.5-9B-Chat</td>\n",
       "      <td>AWQ2bit_MEMIT</td>\n",
       "      <td>1.727429e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.229454</td>\n",
       "      <td>0.246661</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>8133088.5</td>\n",
       "      <td>8773501</td>\n",
       "      <td>7564110.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>6352639.5</td>\n",
       "      <td>2024-09-27 09:23:35.068500519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01-ai/Yi-1.5-9B-Chat</td>\n",
       "      <td>AWQ3bit</td>\n",
       "      <td>1.727376e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.606110</td>\n",
       "      <td>0.611940</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>7.125771</td>\n",
       "      <td>306.892822</td>\n",
       "      <td>105.87944</td>\n",
       "      <td>-1</td>\n",
       "      <td>125.973007</td>\n",
       "      <td>2024-09-26 18:43:24.532109499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01-ai/Yi-1.5-9B-Chat</td>\n",
       "      <td>AWQ3bit_MEMIT</td>\n",
       "      <td>1.727420e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.603618</td>\n",
       "      <td>0.606441</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>7.163979</td>\n",
       "      <td>682.019836</td>\n",
       "      <td>108.887817</td>\n",
       "      <td>-1</td>\n",
       "      <td>214.402084</td>\n",
       "      <td>2024-09-27 06:52:38.689813137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01-ai/Yi-1.5-9B-Chat</td>\n",
       "      <td>AWQ4bit</td>\n",
       "      <td>1.727392e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.669634</td>\n",
       "      <td>0.662215</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>6.47934</td>\n",
       "      <td>356.460541</td>\n",
       "      <td>84.696404</td>\n",
       "      <td>-1</td>\n",
       "      <td>112.177864</td>\n",
       "      <td>2024-09-26 23:09:41.927449703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-awq8bit</td>\n",
       "      <td>1.726225e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.585743</td>\n",
       "      <td>0.306363</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.734568</td>\n",
       "      <td>90627.210938</td>\n",
       "      <td>300.767761</td>\n",
       "      <td>-1</td>\n",
       "      <td>448.873871</td>\n",
       "      <td>2024-09-13 10:59:33.378082514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-ft</td>\n",
       "      <td>1.726134e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>0.282797</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.805961</td>\n",
       "      <td>56338.621094</td>\n",
       "      <td>857.478333</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>1146.820679</td>\n",
       "      <td>2024-09-12 09:35:43.696657896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-lora</td>\n",
       "      <td>1.726146e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>0.294580</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>10.45087</td>\n",
       "      <td>249094.265625</td>\n",
       "      <td>3847.212158</td>\n",
       "      <td>1.79 TFLOPS</td>\n",
       "      <td>3661.797852</td>\n",
       "      <td>2024-09-12 12:55:28.729677916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-memit</td>\n",
       "      <td>1.726228e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560675</td>\n",
       "      <td>0.293009</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.74005</td>\n",
       "      <td>16454.134766</td>\n",
       "      <td>254.244461</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>629.994202</td>\n",
       "      <td>2024-09-13 11:48:50.830707312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-none</td>\n",
       "      <td>1.726224e+09</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587523</td>\n",
       "      <td>0.306363</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>mquake</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.732034</td>\n",
       "      <td>144880.71875</td>\n",
       "      <td>314.706909</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>563.490967</td>\n",
       "      <td>2024-09-13 10:31:47.380945683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>551 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_name            tag    _timestamp  \\\n",
       "0                  01-ai/Yi-1.5-9B-Chat        AWQ2bit  1.727392e+09   \n",
       "1                  01-ai/Yi-1.5-9B-Chat  AWQ2bit_MEMIT  1.727429e+09   \n",
       "2                  01-ai/Yi-1.5-9B-Chat        AWQ3bit  1.727376e+09   \n",
       "3                  01-ai/Yi-1.5-9B-Chat  AWQ3bit_MEMIT  1.727420e+09   \n",
       "4                  01-ai/Yi-1.5-9B-Chat        AWQ4bit  1.727392e+09   \n",
       "..                                  ...            ...           ...   \n",
       "546  mistralai/Mistral-7B-Instruct-v0.3    rmu-awq8bit  1.726225e+09   \n",
       "547  mistralai/Mistral-7B-Instruct-v0.3         rmu-ft  1.726134e+09   \n",
       "548  mistralai/Mistral-7B-Instruct-v0.3       rmu-lora  1.726146e+09   \n",
       "549  mistralai/Mistral-7B-Instruct-v0.3      rmu-memit  1.726228e+09   \n",
       "550  mistralai/Mistral-7B-Instruct-v0.3       rmu-none  1.726224e+09   \n",
       "\n",
       "     edit_set  number_of_edits  rmu_layer_id  wbits  sparsity_ratio  \\\n",
       "0         1.0             50.0          -1.0    2.0             0.0   \n",
       "1         1.0             50.0          -1.0    2.0             0.0   \n",
       "2         1.0             50.0          -1.0    3.0             0.0   \n",
       "3         1.0             50.0          -1.0    3.0             0.0   \n",
       "4         1.0             50.0          -1.0    4.0             0.0   \n",
       "..        ...              ...           ...    ...             ...   \n",
       "546       1.0             50.0           6.0    8.0             0.0   \n",
       "547       1.0             50.0           6.0   16.0             0.0   \n",
       "548       1.0             50.0           6.0   16.0             0.0   \n",
       "549       1.0             50.0           6.0   16.0             0.0   \n",
       "550       1.0             50.0           6.0   16.0             0.0   \n",
       "\n",
       "     mmlu accuracy  wmdp_bio accuracy  ...  compression  edit_dataset  \\\n",
       "0         0.229454           0.246661  ...          awq          zsre   \n",
       "1         0.229454           0.246661  ...          awq          zsre   \n",
       "2         0.606110           0.611940  ...          awq          zsre   \n",
       "3         0.603618           0.606441  ...          awq          zsre   \n",
       "4         0.669634           0.662215  ...          awq          zsre   \n",
       "..             ...                ...  ...          ...           ...   \n",
       "546       0.585743           0.306363  ...          awq          zsre   \n",
       "547       0.494873           0.282797  ...         none          zsre   \n",
       "548       0.567227           0.294580  ...         none          zsre   \n",
       "549       0.560675           0.293009  ...         none          zsre   \n",
       "550       0.587523           0.306363  ...         none        mquake   \n",
       "\n",
       "     compression_dataset  qa_question_count_limit        PPL      PPL edits  \\\n",
       "0                     c4                     None  8100276.5        8778113   \n",
       "1                     c4                     None  8133088.5        8773501   \n",
       "2                     c4                     None   7.125771     306.892822   \n",
       "3                     c4                     None   7.163979     682.019836   \n",
       "4                     c4                     None    6.47934     356.460541   \n",
       "..                   ...                      ...        ...            ...   \n",
       "546                   c4                     None   4.734568   90627.210938   \n",
       "547                   c4                     None   4.805961   56338.621094   \n",
       "548                   c4                     None   10.45087  249094.265625   \n",
       "549                   c4                     None    4.74005   16454.134766   \n",
       "550                   c4                     None   4.732034   144880.71875   \n",
       "\n",
       "          PPl QA        FLOPs  PPl edits unmasked  \\\n",
       "0        7557045           -1             6354282   \n",
       "1      7564110.5           -1           6352639.5   \n",
       "2      105.87944           -1          125.973007   \n",
       "3     108.887817           -1          214.402084   \n",
       "4      84.696404           -1          112.177864   \n",
       "..           ...          ...                 ...   \n",
       "546   300.767761           -1          448.873871   \n",
       "547   857.478333  1.82 TFLOPS         1146.820679   \n",
       "548  3847.212158  1.79 TFLOPS         3661.797852   \n",
       "549   254.244461  1.82 TFLOPS          629.994202   \n",
       "550   314.706909  1.82 TFLOPS          563.490967   \n",
       "\n",
       "                             date  \n",
       "0   2024-09-26 23:14:58.334940910  \n",
       "1   2024-09-27 09:23:35.068500519  \n",
       "2   2024-09-26 18:43:24.532109499  \n",
       "3   2024-09-27 06:52:38.689813137  \n",
       "4   2024-09-26 23:09:41.927449703  \n",
       "..                            ...  \n",
       "546 2024-09-13 10:59:33.378082514  \n",
       "547 2024-09-12 09:35:43.696657896  \n",
       "548 2024-09-12 12:55:28.729677916  \n",
       "549 2024-09-13 11:48:50.830707312  \n",
       "550 2024-09-13 10:31:47.380945683  \n",
       "\n",
       "[551 rows x 51 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by the recency column, for example, \"date\"\n",
    "all_runs_df_sorted = all_runs_df_sorted.sort_values(by=\"date\")\n",
    "\n",
    "# Drop duplicates, keeping only the most recent occurrence for each \"tag\" and \"edit_set\"\n",
    "latest_runs_df = all_runs_df_sorted.drop_duplicates(subset=[\"model_name\", \"tag\", \"edit_set\"], keep=\"last\")\n",
    "\n",
    "# Define a function to calculate standard error\n",
    "def standard_error(x):\n",
    "    return x.std() / np.sqrt(len(x))\n",
    "\n",
    "# Group by the \"tag\" column and calculate the mean for numerical columns\n",
    "# grouped_df = latest_runs_df.groupby([\"model_name\", \"tag\"]).agg([\"mean\", standard_error])\n",
    "numerical_columns = latest_runs_df.select_dtypes(include=[np.number]).columns\n",
    "print(f\"Numerical columns: {list(numerical_columns)}\")\n",
    "grouped_df = latest_runs_df.groupby([\"model_name\", \"tag\"]).agg({ col: [\"mean\", standard_error] for col in numerical_columns })\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "grouped_df.columns = [f\"{col[0]}_{col[1]}\" for col in grouped_df.columns]\n",
    "\n",
    "# Split the columns into means and standard errors\n",
    "mean_columns = [col for col in grouped_df.columns if col.endswith(\"_mean\")]\n",
    "se_columns = [col for col in grouped_df.columns if col.endswith(\"_standard_error\")]\n",
    "\n",
    "# Create separate DataFrames for means and standard errors\n",
    "mean_df = grouped_df[mean_columns].rename(columns=lambda x: x.replace(\"_mean\", \"\"))\n",
    "se_df = grouped_df[se_columns].rename(columns=lambda x: x.replace(\"_standard_error\", \"_se\"))\n",
    "\n",
    "# Merge the means and standard errors back into one DataFrame\n",
    "all_runs_df_sorted_averaged = pd.concat([mean_df, se_df], axis=1).copy()\n",
    "\n",
    "# Reset index if needed\n",
    "all_runs_df_sorted_averaged.reset_index(inplace=True)\n",
    "\n",
    "# Add non-numerical columns from the latest_runs_df\n",
    "non_numerical_columns = latest_runs_df.select_dtypes(exclude=[np.number]).drop_duplicates(subset=[\"model_name\", \"tag\"])\n",
    "all_runs_df_sorted_averaged = all_runs_df_sorted_averaged.merge(non_numerical_columns, on=[\"model_name\", \"tag\"], how=\"left\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "all_runs_df_sorted_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 551/551 [00:00<00:00, 68601.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag             model_name                        \n",
      "AWQ2bit         mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ2bit_MEMIT   mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ2bit_RMU     mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ3bit         mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ3bit_MEMIT   mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "                                                     ..\n",
      "WANDA65%_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "WANDA65%_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "WANDA75%        mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "WANDA75%_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "WANDA75%_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "Name: count, Length: 78, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The experiment tags can be inconsistent, so we need to manually map them to standard names\n",
    "def set_tag(experiment_row):\n",
    "    if experiment_row[\"interventions\"] in [None, np.nan]:\n",
    "        return \"NONE\"\n",
    "\n",
    "    intervention_categories = None\n",
    "    if isinstance(experiment_row[\"interventions\"], str):\n",
    "        intervention_categories = ast.literal_eval(experiment_row[\"interventions\"])\n",
    "    else:\n",
    "        intervention_categories = experiment_row[\"interventions\"]\n",
    "\n",
    "    interventions = []\n",
    "    for category in intervention_categories:\n",
    "        category = \"compression\" if category == \"compress\" else category\n",
    "        intervention = experiment_row[category].upper()\n",
    "        if intervention in [\"AWQ\", \"GPTQ\"]:\n",
    "            intervention += str(int(experiment_row[\"wbits\"])) + \"bit\"\n",
    "        if intervention in [\"WANDA\", \"SPARSEGPT\"]:\n",
    "            intervention += str(int(experiment_row[\"sparsity_ratio\"] * 100)) + \"%\"\n",
    "\n",
    "        interventions.append(intervention)\n",
    "    \n",
    "    if len(interventions) == 0:\n",
    "        interventions.append(\"NONE\")\n",
    "\n",
    "    return \"_\".join(interventions)\n",
    "\n",
    "all_runs_df_sorted_averaged[\"tag\"] = all_runs_df_sorted_averaged.progress_apply(set_tag, axis=1)\n",
    "print(all_runs_df_sorted_averaged[all_runs_df_sorted_averaged[\"model_name\"] == \"mistralai/Mistral-7B-Instruct-v0.3\"].value_counts([\"tag\", \"model_name\"]).sort_index())\n",
    "# print(all_runs_df_sorted_averaged[[\"tag\", \"model_name\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to None if empty dict\n",
    "all_runs_df_sorted_averaged[\"edit\"] = all_runs_df_sorted_averaged[\"edit\"].apply(lambda x: None if x == {} else x)\n",
    "all_runs_df_sorted_averaged[\"unlearn\"] = all_runs_df_sorted_averaged[\"unlearn\"].apply(lambda x: None if x == {} else x)\n",
    "all_runs_df_sorted_averaged[\"compression\"] = all_runs_df_sorted_averaged[\"compression\"].apply(lambda x: None if x == {} else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/3718562974.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/3718562974.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"model_name\"] = all_runs_df_deduplicated[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/3718562974.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"edit\"] = all_runs_df_deduplicated[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/3718562974.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"compression\"] = all_runs_df_deduplicated[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/3718562974.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"unlearn\"] = all_runs_df_deduplicated[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model_name    tag           \n",
       "Llama-3 (8b)  AWQ2bit           1\n",
       "              AWQ2bit_FT        1\n",
       "              AWQ2bit_GA        1\n",
       "              AWQ2bit_GD        1\n",
       "              AWQ2bit_LORA      1\n",
       "                               ..\n",
       "Yi 1.5 (9b)   WANDA55%_MEMIT    1\n",
       "              WANDA65%          1\n",
       "              WANDA65%_MEMIT    1\n",
       "              WANDA75%          1\n",
       "              WANDA75%_MEMIT    1\n",
       "Name: count, Length: 549, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experiments: 549\n",
      "Experiments by Model: model_name\n",
      "Llama-3 (8b)    311\n",
      "Phi-3 (3.8b)    123\n",
      "Mistral (7b)     78\n",
      "Yi 1.5 (9b)      37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted_averaged.drop_duplicates(subset=[\"model_name\", \"tag\"], keep=\"first\")\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": \"Mistral (7b)\",\n",
    "    \"01-ai/Yi-1.5-9B-Chat\": \"Yi 1.5 (9b)\",\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": \"Phi-3 (3.8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"LoRA\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "}\n",
    "all_runs_df_deduplicated[\"model_name\"] = all_runs_df_deduplicated[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"edit\"] = all_runs_df_deduplicated[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"compression\"] = all_runs_df_deduplicated[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"unlearn\"] = all_runs_df_deduplicated[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = all_runs_df_deduplicated\n",
    "display(all_runs_df_deduplicated.value_counts([\"model_name\", \"tag\"]).sort_index())\n",
    "print(f\"Number of experiments: {len(all_runs_df_deduplicated)}\")\n",
    "print(f\"Experiments by Model: {all_runs_df_deduplicated['model_name'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Ablation Experments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment combinations for Mistral ablation: 38\n",
      "Percent of experiments completed: 97.37%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>first_intervention</th>\n",
       "      <th>second_intervention</th>\n",
       "      <th>completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MEMIT</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_tag first_intervention second_intervention  completed\n",
       "25          MEMIT              MEMIT                None      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlearning_interventions = []\n",
    "editing_interventions = [\"memit\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Unlearning and compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Editing and compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [], \"edit\": None, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just edit\n",
    "for editor in editing_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just unlearn\n",
    "for unlearner in unlearning_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just pruning\n",
    "for pruner in pruning_interventions:\n",
    "    for pruning_level in pruning_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "# Just quantization\n",
    "for quantizer in quant_interventions:\n",
    "    for quant_level in quant_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "print(f\"Total experiment combinations for Mistral ablation: {len(experiment_combinations)}\")\n",
    "# model_name = \"Mistral (7b)\"\n",
    "model_name = \"Yi 1.5 (9b)\"\n",
    "mistral_tags = set(all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == model_name][\"tag\"].unique())\n",
    "experiment_statuses = []\n",
    "for experiment in experiment_combinations:\n",
    "    experiment_tag = set_tag(experiment)\n",
    "    experiment_statuses.append({\n",
    "        \"experiment_tag\": experiment_tag,\n",
    "        \"first_intervention\": experiment_tag.split(\"_\")[0],\n",
    "        \"second_intervention\": experiment_tag.split(\"_\")[1] if len(experiment_tag.split(\"_\")) > 1 else None,\n",
    "        \"completed\": experiment_tag in mistral_tags,\n",
    "    })\n",
    "\n",
    "experiment_statuses_df = pd.DataFrame(experiment_statuses)\n",
    "experiment_statuses_df.to_csv(\"mistral_experiment_statuses.csv\", index=False)\n",
    "\n",
    "# Percent of experiments completed\n",
    "print(f\"Percent of experiments completed: {experiment_statuses_df['completed'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Missing experiments\n",
    "missing_experiments = experiment_statuses_df[experiment_statuses_df[\"completed\"] == False].sort_values(by=\"experiment_tag\")\n",
    "display(missing_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yi Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment combinations for Yi ablation: 38\n",
      "Percent of experiments completed: 97.37%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_tag</th>\n",
       "      <th>first_intervention</th>\n",
       "      <th>second_intervention</th>\n",
       "      <th>completed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MEMIT</td>\n",
       "      <td>MEMIT</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   experiment_tag first_intervention second_intervention  completed\n",
       "25          MEMIT              MEMIT                None      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unlearning_interventions = []\n",
    "editing_interventions = [\"memit\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Unlearning and compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Editing and compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [], \"edit\": None, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just edit\n",
    "for editor in editing_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just unlearn\n",
    "for unlearner in unlearning_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just pruning\n",
    "for pruner in pruning_interventions:\n",
    "    for pruning_level in pruning_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "# Just quantization\n",
    "for quantizer in quant_interventions:\n",
    "    for quant_level in quant_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "print(f\"Total experiment combinations for Yi ablation: {len(experiment_combinations)}\")\n",
    "yi_tags = set(all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == \"Yi 1.5 (9b)\"][\"tag\"].unique())\n",
    "experiment_statuses = []\n",
    "for experiment in experiment_combinations:\n",
    "    experiment_tag = set_tag(experiment)\n",
    "    experiment_statuses.append({\n",
    "        \"experiment_tag\": experiment_tag,\n",
    "        \"first_intervention\": experiment_tag.split(\"_\")[0],\n",
    "        \"second_intervention\": experiment_tag.split(\"_\")[1] if len(experiment_tag.split(\"_\")) > 1 else None,\n",
    "        \"completed\": experiment_tag in yi_tags,\n",
    "    })\n",
    "\n",
    "experiment_statuses_df = pd.DataFrame(experiment_statuses)\n",
    "experiment_statuses_df.to_csv(\"mistral_experiment_statuses.csv\", index=False)\n",
    "\n",
    "# Percent of experiments completed\n",
    "print(f\"Percent of experiments completed: {experiment_statuses_df['completed'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Missing experiments\n",
    "missing_experiments = experiment_statuses_df[experiment_statuses_df[\"completed\"] == False].sort_values(by=\"experiment_tag\")\n",
    "display(missing_experiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Main Results Experiment Status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# Math for determining number of interventions\n",
    "awq_settings = 6\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unlearn\n",
       "RMU    82\n",
       "GD     54\n",
       "GA     51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_deduplicated[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_UNLEARNING = 3\n",
    "NUM_EDITING = 3\n",
    "NUM_COMPRESSION = 4 + 6 + 6 + 6\n",
    "combination_of_unlearning = 2 * NUM_UNLEARNING * NUM_COMPRESSION\n",
    "combination_of_unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>wbits</th>\n",
       "      <th>sparsity_ratio</th>\n",
       "      <th>mmlu accuracy</th>\n",
       "      <th>wmdp_bio accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>compression</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>compression_dataset</th>\n",
       "      <th>qa_question_count_limit</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL edits</th>\n",
       "      <th>PPl QA</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_GA</td>\n",
       "      <td>1.718194e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.240377</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 12:02:27.059515953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.240377</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4496028624899119061335958001549312.0</td>\n",
       "      <td>2617349.75</td>\n",
       "      <td>6866961.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>5905774.5</td>\n",
       "      <td>2024-06-12 14:48:16.610423088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_RMU</td>\n",
       "      <td>1.717570e+09</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.268908</td>\n",
       "      <td>0.240377</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>1749321.75</td>\n",
       "      <td>1055937.75</td>\n",
       "      <td>999726.5</td>\n",
       "      <td>-1</td>\n",
       "      <td>915356.5</td>\n",
       "      <td>2024-05-20 19:19:14.861625671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ3bit_GA</td>\n",
       "      <td>1.718194e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.272896</td>\n",
       "      <td>0.241948</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 12:03:07.964953661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ3bit_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.341832</td>\n",
       "      <td>0.245876</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>166895.90625</td>\n",
       "      <td>83131.453125</td>\n",
       "      <td>20670.785156</td>\n",
       "      <td>-1</td>\n",
       "      <td>3257.42627</td>\n",
       "      <td>2024-06-12 14:47:07.710373163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA65%_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>16268.005859</td>\n",
       "      <td>5423145.5</td>\n",
       "      <td>81961160</td>\n",
       "      <td>447.25 GFLOPS</td>\n",
       "      <td>89329664</td>\n",
       "      <td>2024-06-12 14:53:38.419730186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA65%_RMU</td>\n",
       "      <td>1.716764e+09</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.229360</td>\n",
       "      <td>0.249542</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>45.534767</td>\n",
       "      <td>83373.453125</td>\n",
       "      <td>1477.523804</td>\n",
       "      <td>760 GFLOPS</td>\n",
       "      <td>1549.510742</td>\n",
       "      <td>2024-05-20 19:27:06.522696495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_GA</td>\n",
       "      <td>1.718194e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.229811</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>8125971838094910145582358934348365824.0</td>\n",
       "      <td>176520989218511062933962752.0</td>\n",
       "      <td>31936578699555629957120.0</td>\n",
       "      <td>357.84 GFLOPS</td>\n",
       "      <td>31529243875858664390656.0</td>\n",
       "      <td>2024-06-12 12:09:17.554701090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.246902</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>10226426</td>\n",
       "      <td>743558.8125</td>\n",
       "      <td>145133.09375</td>\n",
       "      <td>357.84 GFLOPS</td>\n",
       "      <td>128967.648438</td>\n",
       "      <td>2024-06-12 14:55:21.376342773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_RMU</td>\n",
       "      <td>1.717030e+09</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.231769</td>\n",
       "      <td>0.250982</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>391.873352</td>\n",
       "      <td>151281.125</td>\n",
       "      <td>3917.281982</td>\n",
       "      <td>581.18 GFLOPS</td>\n",
       "      <td>3727.288574</td>\n",
       "      <td>2024-05-22 05:36:22.919470310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name           tag    _timestamp   edit_set  number_of_edits  \\\n",
       "126  Llama-3 (8b)    AWQ2bit_GA  1.718194e+09   1.000000             50.0   \n",
       "127  Llama-3 (8b)    AWQ2bit_GD  1.718204e+09   1.000000             50.0   \n",
       "128  Llama-3 (8b)   AWQ2bit_RMU  1.717570e+09   9.545455             50.0   \n",
       "129  Llama-3 (8b)    AWQ3bit_GA  1.718194e+09   1.000000             50.0   \n",
       "130  Llama-3 (8b)    AWQ3bit_GD  1.718204e+09   1.000000             50.0   \n",
       "..            ...           ...           ...        ...              ...   \n",
       "343  Llama-3 (8b)   WANDA65%_GD  1.718204e+09   1.000000             50.0   \n",
       "344  Llama-3 (8b)  WANDA65%_RMU  1.716764e+09  18.666667             50.0   \n",
       "345  Llama-3 (8b)   WANDA75%_GA  1.718194e+09   1.000000             50.0   \n",
       "346  Llama-3 (8b)   WANDA75%_GD  1.718204e+09   1.000000             50.0   \n",
       "347  Llama-3 (8b)  WANDA75%_RMU  1.717030e+09   4.500000             50.0   \n",
       "\n",
       "     rmu_layer_id  wbits  sparsity_ratio  mmlu accuracy  wmdp_bio accuracy  \\\n",
       "126     -1.000000    2.0            0.00       0.268908           0.240377   \n",
       "127     -1.000000    2.0            0.00       0.268908           0.240377   \n",
       "128      3.181818    2.0            0.00       0.268908           0.240377   \n",
       "129     -1.000000    3.0            0.00       0.272896           0.241948   \n",
       "130     -1.000000    3.0            0.00       0.341832           0.245876   \n",
       "..            ...    ...             ...            ...                ...   \n",
       "343     -1.000000    4.0            0.65       0.229098           0.249018   \n",
       "344      3.666667    4.0            0.65       0.229360           0.249542   \n",
       "345     -1.000000    4.0            0.75       0.229811           0.249018   \n",
       "346     -1.000000    4.0            0.75       0.246902           0.247447   \n",
       "347      3.000000    4.0            0.75       0.231769           0.250982   \n",
       "\n",
       "     ...  compression  edit_dataset  compression_dataset  \\\n",
       "126  ...          AWQ          zsre                   c4   \n",
       "127  ...          AWQ          zsre                   c4   \n",
       "128  ...          AWQ          zsre                   c4   \n",
       "129  ...          AWQ          zsre                   c4   \n",
       "130  ...          AWQ          zsre                   c4   \n",
       "..   ...          ...           ...                  ...   \n",
       "343  ...        Wanda          zsre                   c4   \n",
       "344  ...        Wanda          zsre                   c4   \n",
       "345  ...        Wanda          zsre                   c4   \n",
       "346  ...        Wanda          zsre                   c4   \n",
       "347  ...        Wanda          zsre                   c4   \n",
       "\n",
       "     qa_question_count_limit                                      PPL  \\\n",
       "126                     None                                 Infinity   \n",
       "127                     None     4496028624899119061335958001549312.0   \n",
       "128                     None                               1749321.75   \n",
       "129                     None                                 Infinity   \n",
       "130                     None                             166895.90625   \n",
       "..                       ...                                      ...   \n",
       "343                     None                             16268.005859   \n",
       "344                     None                                45.534767   \n",
       "345                     None  8125971838094910145582358934348365824.0   \n",
       "346                     None                                 10226426   \n",
       "347                     None                               391.873352   \n",
       "\n",
       "                         PPL edits                     PPl QA          FLOPs  \\\n",
       "126                       Infinity                   Infinity             -1   \n",
       "127                     2617349.75                  6866961.5             -1   \n",
       "128                     1055937.75                   999726.5             -1   \n",
       "129                       Infinity                   Infinity             -1   \n",
       "130                   83131.453125               20670.785156             -1   \n",
       "..                             ...                        ...            ...   \n",
       "343                      5423145.5                   81961160  447.25 GFLOPS   \n",
       "344                   83373.453125                1477.523804     760 GFLOPS   \n",
       "345  176520989218511062933962752.0  31936578699555629957120.0  357.84 GFLOPS   \n",
       "346                    743558.8125               145133.09375  357.84 GFLOPS   \n",
       "347                     151281.125                3917.281982  581.18 GFLOPS   \n",
       "\n",
       "            PPl edits unmasked                          date  \n",
       "126                   Infinity 2024-06-12 12:02:27.059515953  \n",
       "127                  5905774.5 2024-06-12 14:48:16.610423088  \n",
       "128                   915356.5 2024-05-20 19:19:14.861625671  \n",
       "129                   Infinity 2024-06-12 12:03:07.964953661  \n",
       "130                 3257.42627 2024-06-12 14:47:07.710373163  \n",
       "..                         ...                           ...  \n",
       "343                   89329664 2024-06-12 14:53:38.419730186  \n",
       "344                1549.510742 2024-05-20 19:27:06.522696495  \n",
       "345  31529243875858664390656.0 2024-06-12 12:09:17.554701090  \n",
       "346              128967.648438 2024-06-12 14:55:21.376342773  \n",
       "347                3727.288574 2024-05-22 05:36:22.919470310  \n",
       "\n",
       "[66 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>wbits</th>\n",
       "      <th>sparsity_ratio</th>\n",
       "      <th>mmlu accuracy</th>\n",
       "      <th>wmdp_bio accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>compression</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>compression_dataset</th>\n",
       "      <th>qa_question_count_limit</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL edits</th>\n",
       "      <th>PPl QA</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>GA_AWQ2bit</td>\n",
       "      <td>1.718191e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.246546</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>1769133.875</td>\n",
       "      <td>1243236.75</td>\n",
       "      <td>1118986.25</td>\n",
       "      <td>-1</td>\n",
       "      <td>1245522.5</td>\n",
       "      <td>2024-06-12 11:13:37.028556824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>GA_AWQ3bit</td>\n",
       "      <td>1.718191e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.441675</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 11:17:15.184798717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>GA_AWQ4bit</td>\n",
       "      <td>1.718191e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.465318</td>\n",
       "      <td>0.524745</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 11:20:13.570003510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>GA_AWQ5bit</td>\n",
       "      <td>1.718191e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.498576</td>\n",
       "      <td>0.556952</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 11:20:19.390620708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>GA_AWQ6bit</td>\n",
       "      <td>1.718191e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.489389</td>\n",
       "      <td>0.559309</td>\n",
       "      <td>...</td>\n",
       "      <td>AWQ</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>-1</td>\n",
       "      <td>Infinity</td>\n",
       "      <td>2024-06-12 11:21:07.118664503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>RMU_WANDA35%</td>\n",
       "      <td>1.717690e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.532602</td>\n",
       "      <td>0.258759</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>6.360727</td>\n",
       "      <td>58684.835938</td>\n",
       "      <td>459.011627</td>\n",
       "      <td>1.3 TFLOPS</td>\n",
       "      <td>647.534851</td>\n",
       "      <td>2024-06-06 13:50:28.648183107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>RMU_WANDA45%</td>\n",
       "      <td>1.717546e+09</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.478009</td>\n",
       "      <td>0.272270</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>7.707963</td>\n",
       "      <td>25395.089844</td>\n",
       "      <td>538.735168</td>\n",
       "      <td>1.12 TFLOPS</td>\n",
       "      <td>620.10907</td>\n",
       "      <td>2024-05-20 19:02:13.503230572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>RMU_WANDA55%</td>\n",
       "      <td>1.717684e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.350570</td>\n",
       "      <td>0.259309</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>13.729619</td>\n",
       "      <td>46809.050781</td>\n",
       "      <td>728.273926</td>\n",
       "      <td>938.82 GFLOPS</td>\n",
       "      <td>732.329468</td>\n",
       "      <td>2024-06-06 14:15:58.615832090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>RMU_WANDA65%</td>\n",
       "      <td>1.717552e+09</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.181818</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.229500</td>\n",
       "      <td>0.242020</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>52.669495</td>\n",
       "      <td>78055.304688</td>\n",
       "      <td>1446.553223</td>\n",
       "      <td>760 GFLOPS</td>\n",
       "      <td>1535.829468</td>\n",
       "      <td>2024-05-20 19:06:01.385294199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>RMU_WANDA75%</td>\n",
       "      <td>1.717685e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.231342</td>\n",
       "      <td>0.243205</td>\n",
       "      <td>...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>334.445282</td>\n",
       "      <td>195344.125</td>\n",
       "      <td>4011.156738</td>\n",
       "      <td>581.18 GFLOPS</td>\n",
       "      <td>4462.537598</td>\n",
       "      <td>2024-06-06 14:33:10.895355225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name           tag    _timestamp   edit_set  number_of_edits  \\\n",
       "170  Llama-3 (8b)    GA_AWQ2bit  1.718191e+09   1.000000             50.0   \n",
       "171  Llama-3 (8b)    GA_AWQ3bit  1.718191e+09   1.000000             50.0   \n",
       "172  Llama-3 (8b)    GA_AWQ4bit  1.718191e+09   1.000000             50.0   \n",
       "173  Llama-3 (8b)    GA_AWQ5bit  1.718191e+09   1.000000             50.0   \n",
       "174  Llama-3 (8b)    GA_AWQ6bit  1.718191e+09   1.000000             50.0   \n",
       "..            ...           ...           ...        ...              ...   \n",
       "307  Llama-3 (8b)  RMU_WANDA35%  1.717690e+09   5.500000             50.0   \n",
       "308  Llama-3 (8b)  RMU_WANDA45%  1.717546e+09  10.000000             50.0   \n",
       "309  Llama-3 (8b)  RMU_WANDA55%  1.717684e+09   5.500000             50.0   \n",
       "310  Llama-3 (8b)  RMU_WANDA65%  1.717552e+09   9.545455             50.0   \n",
       "311  Llama-3 (8b)  RMU_WANDA75%  1.717685e+09   5.500000             50.0   \n",
       "\n",
       "     rmu_layer_id  wbits  sparsity_ratio  mmlu accuracy  wmdp_bio accuracy  \\\n",
       "170     -1.000000    2.0            0.00       0.246546           0.247447   \n",
       "171     -1.000000    3.0            0.00       0.441675           0.492537   \n",
       "172     -1.000000    4.0            0.00       0.465318           0.524745   \n",
       "173     -1.000000    5.0            0.00       0.498576           0.556952   \n",
       "174     -1.000000    6.0            0.00       0.489389           0.559309   \n",
       "..            ...    ...             ...            ...                ...   \n",
       "307      3.000000    4.0            0.35       0.532602           0.258759   \n",
       "308      3.200000    4.0            0.45       0.478009           0.272270   \n",
       "309      3.000000    4.0            0.55       0.350570           0.259309   \n",
       "310      3.181818    4.0            0.65       0.229500           0.242020   \n",
       "311      3.000000    4.0            0.75       0.231342           0.243205   \n",
       "\n",
       "     ...  compression  edit_dataset  compression_dataset  \\\n",
       "170  ...          AWQ          zsre                   c4   \n",
       "171  ...          AWQ          zsre                   c4   \n",
       "172  ...          AWQ          zsre                   c4   \n",
       "173  ...          AWQ          zsre                   c4   \n",
       "174  ...          AWQ          zsre                   c4   \n",
       "..   ...          ...           ...                  ...   \n",
       "307  ...        Wanda          zsre                   c4   \n",
       "308  ...        Wanda          zsre                   c4   \n",
       "309  ...        Wanda          zsre                   c4   \n",
       "310  ...        Wanda          zsre                   c4   \n",
       "311  ...        Wanda          zsre                   c4   \n",
       "\n",
       "     qa_question_count_limit          PPL     PPL edits       PPl QA  \\\n",
       "170                     None  1769133.875    1243236.75   1118986.25   \n",
       "171                     None     Infinity      Infinity     Infinity   \n",
       "172                     None     Infinity      Infinity     Infinity   \n",
       "173                     None     Infinity      Infinity     Infinity   \n",
       "174                     None     Infinity      Infinity     Infinity   \n",
       "..                       ...          ...           ...          ...   \n",
       "307                     None     6.360727  58684.835938   459.011627   \n",
       "308                     None     7.707963  25395.089844   538.735168   \n",
       "309                     None    13.729619  46809.050781   728.273926   \n",
       "310                     None    52.669495  78055.304688  1446.553223   \n",
       "311                     None   334.445282    195344.125  4011.156738   \n",
       "\n",
       "             FLOPs  PPl edits unmasked                          date  \n",
       "170             -1           1245522.5 2024-06-12 11:13:37.028556824  \n",
       "171             -1            Infinity 2024-06-12 11:17:15.184798717  \n",
       "172             -1            Infinity 2024-06-12 11:20:13.570003510  \n",
       "173             -1            Infinity 2024-06-12 11:20:19.390620708  \n",
       "174             -1            Infinity 2024-06-12 11:21:07.118664503  \n",
       "..             ...                 ...                           ...  \n",
       "307     1.3 TFLOPS          647.534851 2024-06-06 13:50:28.648183107  \n",
       "308    1.12 TFLOPS           620.10907 2024-05-20 19:02:13.503230572  \n",
       "309  938.82 GFLOPS          732.329468 2024-06-06 14:15:58.615832090  \n",
       "310     760 GFLOPS         1535.829468 2024-05-20 19:06:01.385294199  \n",
       "311  581.18 GFLOPS         4462.537598 2024-06-06 14:33:10.895355225  \n",
       "\n",
       "[66 rows x 51 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "main_results = all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == \"Llama-3 (8b)\"]\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": main_results[main_results[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": main_results[main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1, f\"{len(categories['No Intervention'])} != 1\"\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "# assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 ) - 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "assert len(categories[\"Unlearn\"]) == 3, f\"{len(categories['Unlearn'])} != 3\"\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 9, f\"{len(categories['Edit to Unlearn'])} != 9\"\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 9, f\"{len(categories['Unlearn to Edit'])} != 9\"\n",
    "\n",
    "display(categories[\"Compress to Unlearn\"])\n",
    "assert len(categories[\"Compress to Unlearn\"]) == combination_of_unlearning // 2, f\"{len(categories['Compress to Unlearn'])} != {combination_of_unlearning // 2}\"\n",
    "\n",
    "display(categories[\"Unlearn to Compress\"])\n",
    "assert len(categories[\"Unlearn to Compress\"]) == combination_of_unlearning // 2, f\"{len(categories['Unlearn to Compress'])} != {rmucombination_of_unlearning_count // 2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU OI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:49: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mmlu_oi_main_results[first_intervention][second_intervention] = mmlu_diff\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:52: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  wmdp_oi_main_results[first_intervention][second_intervention] = avg_wmdp_diff\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:55: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edit_oi_main_results[first_intervention][second_intervention] = edit_diff\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:58: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  generalization_oi_main_results[first_intervention][second_intervention] = generalization_diff\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:61: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  locality_oi_main_results[first_intervention][second_intervention] = locality_diff\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:65: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  mmlu_mce_main_results[first_intervention][second_intervention] = mmlu_mce\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:68: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  wmdp_mce_main_results[first_intervention][second_intervention] = avg_wmdp_acc\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:71: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  edit_mce_main_results[first_intervention][second_intervention] = edit_mce\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:74: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  generalization_mce_main_results[first_intervention][second_intervention] = generalization_mce\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_55987/2458701388.py:77: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  locality_mce_main_results[first_intervention][second_intervention] = locality_mce\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.0234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.1820</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.0148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0174</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0921</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0037</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0580</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.0071  0.1820  0.0122  0.0174  0.0032   \n",
       "LoRA             NaN     NaN     NaN  0.0706  0.1414  0.0390  0.0023  0.0120   \n",
       "MEMIT            NaN     NaN     NaN  0.0409  0.2225  0.0025  0.0084  0.0139   \n",
       "GA            0.0071  0.0706  0.0409     NaN     NaN     NaN  0.0174  0.0921   \n",
       "GD            0.1820  0.1414  0.2225     NaN     NaN     NaN  0.0700  0.2398   \n",
       "RMU           0.0122  0.0390  0.0025     NaN     NaN     NaN  0.0085  0.0500   \n",
       "AWQ           0.0174  0.0023  0.0084  0.0174  0.0700  0.0085     NaN     NaN   \n",
       "GPTQ          0.0032  0.0120  0.0139  0.0921  0.2398  0.0500     NaN     NaN   \n",
       "SparseGPT     0.0037  0.0001  0.0040  0.0580  0.0927  0.0080     NaN     NaN   \n",
       "Wanda         0.0053  0.0009  0.0034  0.0234  0.0100  0.0148     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0037  0.0053  \n",
       "LoRA          0.0001  0.0009  \n",
       "MEMIT         0.0040  0.0034  \n",
       "GA            0.0580  0.0234  \n",
       "GD            0.0927  0.0100  \n",
       "RMU           0.0080  0.0148  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMLU MCE Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.3976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.4189</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.4036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>0.4381</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.4044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.4745</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.4591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.4100</td>\n",
       "      <td>0.4130</td>\n",
       "      <td>0.4207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5803</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.4200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.4305</td>\n",
       "      <td>0.4443</td>\n",
       "      <td>0.4381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>0.4341</td>\n",
       "      <td>0.4288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.4094</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>0.4142</td>\n",
       "      <td>0.5347</td>\n",
       "      <td>0.5803</td>\n",
       "      <td>0.4383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.4138</td>\n",
       "      <td>0.4189</td>\n",
       "      <td>0.4109</td>\n",
       "      <td>0.5246</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>0.4205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.3978</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>0.4037</td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.4341</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.3976</td>\n",
       "      <td>0.4036</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.4591</td>\n",
       "      <td>0.4200</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.4745  0.4100  0.4305  0.4094  0.4138   \n",
       "LoRA             NaN     NaN     NaN  0.6435  0.4130  0.4443  0.4144  0.4189   \n",
       "MEMIT            NaN     NaN     NaN  0.5074  0.4207  0.4381  0.4142  0.4109   \n",
       "GA            0.4745  0.6435  0.5074     NaN     NaN     NaN  0.5347  0.5246   \n",
       "GD            0.4100  0.4130  0.4207     NaN     NaN     NaN  0.5803  0.4358   \n",
       "RMU           0.4305  0.4443  0.4381     NaN     NaN     NaN  0.4383  0.4205   \n",
       "AWQ           0.4094  0.4144  0.4142  0.5347  0.5803  0.4383     NaN     NaN   \n",
       "GPTQ          0.4138  0.4189  0.4109  0.5246  0.4358  0.4205     NaN     NaN   \n",
       "SparseGPT     0.3978  0.4039  0.4037  0.4917  0.4227  0.4341     NaN     NaN   \n",
       "Wanda         0.3976  0.4036  0.4044  0.4591  0.4200  0.4288     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.3978  0.3976  \n",
       "LoRA          0.4039  0.4036  \n",
       "MEMIT         0.4037  0.4044  \n",
       "GA            0.4917  0.4591  \n",
       "GD            0.4227  0.4200  \n",
       "RMU           0.4341  0.4288  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMDP OI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2437</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.0332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0880</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>0.1801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1733</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.0046  0.0001  0.0450  0.0144  0.0090   \n",
       "LoRA             NaN     NaN     NaN  0.0661  0.2437  0.0022  0.0006  0.0097   \n",
       "MEMIT            NaN     NaN     NaN  0.0508  0.0205  0.0086  0.0023  0.0050   \n",
       "GA            0.0046  0.0661  0.0508     NaN     NaN     NaN  0.0232  0.0880   \n",
       "GD            0.0001  0.2437  0.0205     NaN     NaN     NaN  0.0012  0.0230   \n",
       "RMU           0.0450  0.0022  0.0086     NaN     NaN     NaN  0.0150  0.1801   \n",
       "AWQ           0.0144  0.0006  0.0023  0.0232  0.0012  0.0150     NaN     NaN   \n",
       "GPTQ          0.0090  0.0097  0.0050  0.0880  0.0230  0.1801     NaN     NaN   \n",
       "SparseGPT     0.0026  0.0019  0.0016  0.0300  0.2218  0.0241     NaN     NaN   \n",
       "Wanda         0.0039  0.0008  0.0014  0.0285  0.1733  0.0332     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0026  0.0039  \n",
       "LoRA          0.0019  0.0008  \n",
       "MEMIT         0.0016  0.0014  \n",
       "GA            0.0300  0.0285  \n",
       "GD            0.2218  0.1733  \n",
       "RMU           0.0241  0.0332  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WMDP MCE Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.2751</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.5469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.5573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.4664</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.3966</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.4586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.2993</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.3475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.2751</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>0.2854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.5472</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>0.4257</td>\n",
       "      <td>0.2434</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.5423</td>\n",
       "      <td>0.5341</td>\n",
       "      <td>0.5477</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.2438</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.5525</td>\n",
       "      <td>0.5434</td>\n",
       "      <td>0.5570</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.2850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.5586</td>\n",
       "      <td>0.5469</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>0.4586</td>\n",
       "      <td>0.3475</td>\n",
       "      <td>0.2854</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.4664  0.2937  0.2751  0.5341  0.5423   \n",
       "LoRA             NaN     NaN     NaN  0.2762  0.2993  0.2947  0.5472  0.5341   \n",
       "MEMIT            NaN     NaN     NaN  0.3966  0.2557  0.2928  0.5516  0.5477   \n",
       "GA            0.4664  0.2762  0.3966     NaN     NaN     NaN  0.4257  0.3443   \n",
       "GD            0.2937  0.2993  0.2557     NaN     NaN     NaN  0.2434  0.2438   \n",
       "RMU           0.2751  0.2947  0.2928     NaN     NaN     NaN  0.2733  0.2667   \n",
       "AWQ           0.5341  0.5472  0.5516  0.4257  0.2434  0.2733     NaN     NaN   \n",
       "GPTQ          0.5423  0.5341  0.5477  0.3443  0.2438  0.2667     NaN     NaN   \n",
       "SparseGPT     0.5525  0.5434  0.5570  0.4318  0.2750  0.2850     NaN     NaN   \n",
       "Wanda         0.5586  0.5469  0.5573  0.4586  0.3475  0.2854     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.5525  0.5586  \n",
       "LoRA          0.5434  0.5469  \n",
       "MEMIT         0.5570  0.5573  \n",
       "GA            0.4318  0.4586  \n",
       "GD            0.2750  0.3475  \n",
       "RMU           0.2850  0.2854  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrite OI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.9960</td>\n",
       "      <td>0.4821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.6705</td>\n",
       "      <td>0.5587</td>\n",
       "      <td>0.3992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.3570</td>\n",
       "      <td>0.3706</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.0686  0.6705  0.0090  0.0376  0.3570   \n",
       "LoRA             NaN     NaN     NaN  0.9960  0.5587  0.0004  0.0835  0.3706   \n",
       "MEMIT            NaN     NaN     NaN  0.4821  0.3992  0.0125  0.0099  0.0323   \n",
       "GA            0.0686  0.9960  0.4821     NaN     NaN     NaN  0.0000  0.0000   \n",
       "GD            0.6705  0.5587  0.3992     NaN     NaN     NaN  0.0117  0.0067   \n",
       "RMU           0.0090  0.0004  0.0125     NaN     NaN     NaN  0.0059  0.0162   \n",
       "AWQ           0.0376  0.0835  0.0099  0.0000  0.0117  0.0059     NaN     NaN   \n",
       "GPTQ          0.3570  0.3706  0.0323  0.0000  0.0067  0.0162     NaN     NaN   \n",
       "SparseGPT     0.0345  0.0148  0.0706  0.0000  0.0044  0.0141     NaN     NaN   \n",
       "Wanda         0.0259  0.0798  0.0711  0.0000  0.0000  0.0005     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0345  0.0259  \n",
       "LoRA          0.0148  0.0798  \n",
       "MEMIT         0.0706  0.0711  \n",
       "GA            0.0000  0.0000  \n",
       "GD            0.0044  0.0000  \n",
       "RMU           0.0141  0.0005  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rewrite MCE Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.9314</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.5179</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.4199</td>\n",
       "      <td>0.1554</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9784</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0130</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.9314  0.0050  0.0017  0.0053  0.2061   \n",
       "LoRA             NaN     NaN     NaN  0.0040  0.0040  0.0040  0.0040  0.4199   \n",
       "MEMIT            NaN     NaN     NaN  0.5179  0.0696  0.0313  0.0710  0.1554   \n",
       "GA            0.9314  0.0040  0.5179     NaN     NaN     NaN  1.0000  1.0000   \n",
       "GD            0.0050  0.0040  0.0696     NaN     NaN     NaN  0.9883  0.9933   \n",
       "RMU           0.0017  0.0040  0.0313     NaN     NaN     NaN  0.9759  0.9794   \n",
       "AWQ           0.0053  0.0040  0.0710  1.0000  0.9883  0.9759     NaN     NaN   \n",
       "GPTQ          0.2061  0.4199  0.1554  1.0000  0.9933  0.9794     NaN     NaN   \n",
       "SparseGPT     0.0092  0.1374  0.0590  1.0000  0.9933  0.9784     NaN     NaN   \n",
       "Wanda         0.0130  0.0519  0.0541  1.0000  1.0000  0.9804     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0092  0.0130  \n",
       "LoRA          0.1374  0.0519  \n",
       "MEMIT         0.0590  0.0541  \n",
       "GA            1.0000  1.0000  \n",
       "GD            0.9933  1.0000  \n",
       "RMU           0.9784  0.9804  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization OI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.7835</td>\n",
       "      <td>0.4096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.5607</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>0.4077</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.2672</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0231</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0300</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0549</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.0401  0.5607  0.0285  0.0801  0.3564   \n",
       "LoRA             NaN     NaN     NaN  0.7835  0.4808  0.0393  0.1400  0.2672   \n",
       "MEMIT            NaN     NaN     NaN  0.4096  0.4077  0.0359  0.0033  0.1089   \n",
       "GA            0.0401  0.7835  0.4096     NaN     NaN     NaN  0.0000  0.0000   \n",
       "GD            0.5607  0.4808  0.4077     NaN     NaN     NaN  0.0000  0.0067   \n",
       "RMU           0.0285  0.0393  0.0359     NaN     NaN     NaN  0.0027  0.0023   \n",
       "AWQ           0.0801  0.1400  0.0033  0.0000  0.0000  0.0027     NaN     NaN   \n",
       "GPTQ          0.3564  0.2672  0.1089  0.0000  0.0067  0.0023     NaN     NaN   \n",
       "SparseGPT     0.0231  0.0713  0.0357  0.0000  0.0067  0.0032     NaN     NaN   \n",
       "Wanda         0.0300  0.0059  0.0549  0.0000  0.0067  0.0057     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0231  0.0300  \n",
       "LoRA          0.0713  0.0059  \n",
       "MEMIT         0.0357  0.0549  \n",
       "GA            0.0000  0.0000  \n",
       "GD            0.0067  0.0067  \n",
       "RMU           0.0032  0.0057  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generalization MCE Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.2066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.2915</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.4623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5904</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>0.1039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.9599</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.5904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.1892</td>\n",
       "      <td>0.2915</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.1848</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>0.9765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.1507</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1095</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.4010</td>\n",
       "      <td>0.5944</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4767</td>\n",
       "      <td>0.1349</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.2066</td>\n",
       "      <td>0.4623</td>\n",
       "      <td>0.1039</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.9599  0.1892  0.1848  0.1507  0.4010   \n",
       "LoRA             NaN     NaN     NaN  0.2165  0.2915  0.2852  0.2592  0.5944   \n",
       "MEMIT            NaN     NaN     NaN  0.5904  0.1067  0.0703  0.1095  0.1977   \n",
       "GA            0.9599  0.2165  0.5904     NaN     NaN     NaN  1.0000  1.0000   \n",
       "GD            0.1892  0.2915  0.1067     NaN     NaN     NaN  1.0000  0.9933   \n",
       "RMU           0.1848  0.2852  0.0703     NaN     NaN     NaN  0.9772  0.9801   \n",
       "AWQ           0.1507  0.2592  0.1095  1.0000  1.0000  0.9772     NaN     NaN   \n",
       "GPTQ          0.4010  0.5944  0.1977  1.0000  0.9933  0.9801     NaN     NaN   \n",
       "SparseGPT     0.2210  0.4767  0.1349  1.0000  0.9933  0.9770     NaN     NaN   \n",
       "Wanda         0.2066  0.4623  0.1039  1.0000  0.9933  0.9765     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.2210  0.2066  \n",
       "LoRA          0.4767  0.4623  \n",
       "MEMIT         0.1349  0.1039  \n",
       "GA            1.0000  1.0000  \n",
       "GD            0.9933  0.9933  \n",
       "RMU           0.9770  0.9765  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locality OI\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0020</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.0687</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  0.0000  0.0413  0.0337  0.0369  0.0687   \n",
       "LoRA             NaN     NaN     NaN  0.0255  0.0344  0.0075  0.0271  0.0066   \n",
       "MEMIT            NaN     NaN     NaN  0.0005  0.0119  0.0008  0.0020  0.0008   \n",
       "GA            0.0000  0.0255  0.0005     NaN     NaN     NaN  0.0000  0.0000   \n",
       "GD            0.0413  0.0344  0.0119     NaN     NaN     NaN  0.0384  0.0072   \n",
       "RMU           0.0337  0.0075  0.0008     NaN     NaN     NaN  0.0032  0.0063   \n",
       "AWQ           0.0369  0.0271  0.0020  0.0000  0.0384  0.0032     NaN     NaN   \n",
       "GPTQ          0.0687  0.0066  0.0008  0.0000  0.0072  0.0063     NaN     NaN   \n",
       "SparseGPT     0.0299  0.0010  0.0029  0.0000  0.0059  0.0010     NaN     NaN   \n",
       "Wanda         0.0325  0.0081  0.0014  0.0000  0.0279  0.0005     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.0299  0.0325  \n",
       "LoRA          0.0010  0.0081  \n",
       "MEMIT         0.0029  0.0014  \n",
       "GA            0.0000  0.0000  \n",
       "GD            0.0059  0.0279  \n",
       "RMU           0.0010  0.0005  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Locality MCE Values\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fine-tune</th>\n",
       "      <th>LoRA</th>\n",
       "      <th>MEMIT</th>\n",
       "      <th>GA</th>\n",
       "      <th>GD</th>\n",
       "      <th>RMU</th>\n",
       "      <th>AWQ</th>\n",
       "      <th>GPTQ</th>\n",
       "      <th>SparseGPT</th>\n",
       "      <th>Wanda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fine-tune</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.8952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LoRA</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MEMIT</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>0.9643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GA</th>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>0.9995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GD</th>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.9172</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.9698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RMU</th>\n",
       "      <td>0.8666</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AWQ</th>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.9300</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9616</td>\n",
       "      <td>0.9658</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GPTQ</th>\n",
       "      <td>0.8931</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.9648</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9897</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseGPT</th>\n",
       "      <td>0.8941</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wanda</th>\n",
       "      <td>0.8952</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9698</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Fine-tune    LoRA   MEMIT      GA      GD     RMU     AWQ    GPTQ  \\\n",
       "Fine-tune        NaN     NaN     NaN  1.0000  0.8858  0.8666  0.8545  0.8931   \n",
       "LoRA             NaN     NaN     NaN  0.9745  0.9172  0.9475  0.9300  0.9476   \n",
       "MEMIT            NaN     NaN     NaN  0.9995  0.9537  0.9652  0.9639  0.9648   \n",
       "GA            1.0000  0.9745  0.9995     NaN     NaN     NaN  1.0000  1.0000   \n",
       "GD            0.8858  0.9172  0.9537     NaN     NaN     NaN  0.9616  0.9897   \n",
       "RMU           0.8666  0.9475  0.9652     NaN     NaN     NaN  0.9658  0.9719   \n",
       "AWQ           0.8545  0.9300  0.9639  1.0000  0.9616  0.9658     NaN     NaN   \n",
       "GPTQ          0.8931  0.9476  0.9648  1.0000  0.9897  0.9719     NaN     NaN   \n",
       "SparseGPT     0.8941  0.9583  0.9649  1.0000  0.9789  0.9644     NaN     NaN   \n",
       "Wanda         0.8952  0.9606  0.9643  1.0000  0.9698  0.9623     NaN     NaN   \n",
       "\n",
       "           SparseGPT   Wanda  \n",
       "Fine-tune     0.8941  0.8952  \n",
       "LoRA          0.9583  0.9606  \n",
       "MEMIT         0.9649  0.9643  \n",
       "GA            1.0000  1.0000  \n",
       "GD            0.9789  0.9698  \n",
       "RMU           0.9644  0.9623  \n",
       "AWQ              NaN     NaN  \n",
       "GPTQ             NaN     NaN  \n",
       "SparseGPT        NaN     NaN  \n",
       "Wanda            NaN     NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define intervention names and types\n",
    "intervention_names = [intervention for intervention in list(main_results[\"edit\"].unique()) + list(main_results[\"unlearn\"].unique()) + list(main_results[\"compression\"].unique()) if intervention is not None]\n",
    "intervention_type = {\n",
    "    \"LoRA\": \"edit\",\n",
    "    \"MEMIT\": \"edit\",\n",
    "    \"Fine-tune\": \"edit\",\n",
    "    \"SparseGPT\": \"compression\",\n",
    "    \"Wanda\": \"compression\",\n",
    "    \"GPTQ\": \"compression\",\n",
    "    \"AWQ\": \"compression\",\n",
    "    \"RMU\": \"unlearn\",\n",
    "    \"GA\": \"unlearn\",\n",
    "    \"GD\": \"unlearn\",\n",
    "}\n",
    "\n",
    "# Initialize heatmap main_results frames with default values\n",
    "default_value = None\n",
    "mmlu_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_oi_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Initialize max value main_results frames\n",
    "mmlu_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_mce_main_results = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Populate the heatmap and max value main_results frames\n",
    "for first_intervention in intervention_names:\n",
    "    for second_intervention in intervention_names:\n",
    "        first_intervention_type = intervention_type[first_intervention]\n",
    "        second_intervention_type = intervention_type[second_intervention]\n",
    "        if first_intervention_type == second_intervention_type:\n",
    "            continue\n",
    "\n",
    "        compositions = main_results[(main_results[first_intervention_type] == first_intervention) & (main_results[second_intervention_type] == second_intervention)]\n",
    "        if first_intervention in [\"SparseGPT\", \"Wanda\"] or second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "            compositions = compositions[compositions[\"sparsity_ratio\"] == 0.25]\n",
    "        elif first_intervention in [\"GPTQ\", \"AWQ\"] or second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "            compositions = compositions[compositions[\"wbits\"] == 4]\n",
    "        \n",
    "        assert len(compositions) == 2, f\"Expected 2 compositions for {first_intervention} and {second_intervention}, but found {len(compositions)}\"\n",
    "        \n",
    "        # Calculate OIs\n",
    "        mmlu_diff = abs(compositions[\"mmlu accuracy\"].iloc[0] - compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_oi_main_results[first_intervention][second_intervention] = mmlu_diff\n",
    "        \n",
    "        avg_wmdp_diff = abs(((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2) - ((compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2)).round(4)\n",
    "        wmdp_oi_main_results[first_intervention][second_intervention] = avg_wmdp_diff\n",
    "        \n",
    "        edit_diff = abs(compositions[\"Rewrite accuracy\"].iloc[0] - compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_oi_main_results[first_intervention][second_intervention] = edit_diff\n",
    "\n",
    "        generalization_diff = abs(compositions[\"Generalization\"].iloc[0] - compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_oi_main_results[first_intervention][second_intervention] = generalization_diff\n",
    "\n",
    "        locality_diff = abs(compositions[\"Locality\"].iloc[0] - compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_oi_main_results[first_intervention][second_intervention] = locality_diff\n",
    "        \n",
    "        # Calculate MCE values\n",
    "        mmlu_mce = 1 - max(compositions[\"mmlu accuracy\"].iloc[0], compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_mce_main_results[first_intervention][second_intervention] = mmlu_mce\n",
    "        \n",
    "        avg_wmdp_acc = min((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2, (compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2).round(4)\n",
    "        wmdp_mce_main_results[first_intervention][second_intervention] = avg_wmdp_acc\n",
    "        \n",
    "        edit_mce = 1 - max(compositions[\"Rewrite accuracy\"].iloc[0], compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_mce_main_results[first_intervention][second_intervention] = edit_mce\n",
    "\n",
    "        generalization_mce = 1 - max(compositions[\"Generalization\"].iloc[0], compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_mce_main_results[first_intervention][second_intervention] = generalization_mce\n",
    "\n",
    "        locality_mce = 1 - max(compositions[\"Locality\"].iloc[0], compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_mce_main_results[first_intervention][second_intervention] = locality_mce\n",
    "\n",
    "# Display the results\n",
    "print(\"MMLU OI\")\n",
    "display(mmlu_oi_main_results)\n",
    "\n",
    "print(\"MMLU MCE Values\")\n",
    "display(mmlu_mce_main_results)\n",
    "\n",
    "print(\"WMDP OI\")\n",
    "display(wmdp_oi_main_results)\n",
    "\n",
    "print(\"WMDP MCE Values\")\n",
    "display(wmdp_mce_main_results)\n",
    "\n",
    "print(\"Rewrite OI\")\n",
    "display(edit_oi_main_results)\n",
    "\n",
    "print(\"Rewrite MCE Values\")\n",
    "display(edit_mce_main_results)\n",
    "\n",
    "print(\"Generalization OI\")\n",
    "display(generalization_oi_main_results)\n",
    "\n",
    "print(\"Generalization MCE Values\")\n",
    "display(generalization_mce_main_results)\n",
    "\n",
    "print(\"Locality OI\")\n",
    "display(locality_oi_main_results)\n",
    "\n",
    "print(\"Locality MCE Values\")\n",
    "display(locality_mce_main_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_order = [\"Wanda\", \"SparseGPT\", \"AWQ\", \"GPTQ\"]\n",
    "editor_order = [\"Fine-tune\", \"MEMIT\", \"LoRA\"]\n",
    "unlearn_order = [\"GA\", \"GD\", \"RMU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    elif value > .995:\n",
    "        return '1'\n",
    "    else:\n",
    "        return f'{value:.2f}'[1:] if value < 1 else f'{value:.2f}'\n",
    "\n",
    "def latex_bold_if_min(value: str, max_value: float):\n",
    "    return f'\\\\textbf{{{value}}}' if value == format_value(min_value) else value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccccccccc}\n",
      "        \\toprule\n",
      "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13} \\cmidrule(lr){14-19}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13} \\cmidrule(lr){14-16} \\cmidrule(lr){17-19}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        Wanda & .01 & .05 & .05 & .03 & .07 & .08 & .21 & .10 & .46 & .03 & .05 & .01 & .40 & .40 & .40 & .01 & .00 & .00 \\\\\n",
      "        SparseGPT & .01 & .06 & .14 & .03 & .07 & .01 & .22 & .13 & .48 & .02 & .04 & .07 & .40 & .40 & .40 & .00 & .00 & .00 \\\\\n",
      "        \\cdashlinelr{1-19}\n",
      "        AWQ & .01 & .07 & .00 & .04 & .01 & .08 & .15 & .11 & .26 & .08 & .00 & .14 & .41 & .41 & .41 & .02 & .01 & .00 \\\\\n",
      "        GPTQ & .21 & .16 & .42 & .36 & .03 & .37 & .40 & .20 & .59 & .36 & .11 & .27 & .41 & .41 & .42 & .00 & .01 & .01 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .06 & .08 & .15 & .11 & .05 & .14 & .24 & .14 & .45 & .12 & .05 & .12 & .40 & .41 & .41 & .01 & .01 & .00 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_ke_mc(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13} \\cmidrule(lr){14-19}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13} \\cmidrule(lr){14-16} \\cmidrule(lr){17-19}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-19}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = f\"        {compressor}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc(\n",
    "    edit_mce_main_results,\n",
    "    edit_oi_main_results,\n",
    "    generalization_mce_main_results,\n",
    "    generalization_oi_main_results,\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Row Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccc}\n",
      "        \\toprule\n",
      "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{Wanda} & .01 & .05 & .05 & .03 & .07 & .08 & .21 & .10 & .46 & .03 & .05 & .01 \\\\\n",
      "        \\textbf{SparseGPT} & .01 & .06 & .14 & .03 & .07 & .01 & .22 & .13 & .48 & .02 & .04 & .07 \\\\\n",
      "        \\cdashlinelr{1-13}\n",
      "        \\textbf{AWQ} & .01 & .07 & .00 & .04 & .01 & .08 & .15 & .11 & .26 & .08 & .00 & .14 \\\\\n",
      "        \\textbf{GPTQ} & .21 & .16 & .42 & .36 & .03 & .37 & .40 & .20 & .59 & .36 & .11 & .27 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .06 & .08 & .15 & .11 & .05 & .14 & .24 & .14 & .45 & .12 & .05 & .12 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_ke_mc_edit_only(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, edit_interventions, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_edit_only(\n",
    "    edit_mce_main_results,\n",
    "    edit_oi_main_results,\n",
    "    generalization_mce_main_results,\n",
    "    generalization_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Row: Locality & MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccc}\n",
      "        & \\multicolumn{6}{c}{\\textbf{Locality}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{Wanda} & .90 & .96 & .96 & .03 & .00 & .01 & .40 & .40 & .40 & .01 & .00 & .00 \\\\\n",
      "        \\textbf{SparseGPT} & .89 & .96 & .96 & .03 & .00 & .00 & .40 & .40 & .40 & .00 & .00 & .00 \\\\\n",
      "        \\cdashlinelr{1-13}\n",
      "        \\textbf{AWQ} & .85 & .96 & .93 & .04 & .00 & .03 & .41 & .41 & .41 & .02 & .01 & .00 \\\\\n",
      "        \\textbf{GPTQ} & .89 & .96 & .95 & .07 & .00 & .01 & .41 & .41 & .42 & .00 & .01 & .01 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .88 & .96 & .95 & .04 & .00 & .01 & .40 & .41 & .41 & .01 & .01 & .00 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_ke_locality_and_mmlu(locality_mce_df, locality_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{Locality}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(locality_mce_df, locality_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "\n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "    \n",
    "    print(latex_code)\n",
    "\n",
    "generate_latex_table_ke_locality_and_mmlu(\n",
    "    locality_mce_main_results,\n",
    "    locality_oi_main_results,\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row: MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccc}\n",
      "        & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
      "        \\cmidrule(lr){2-7}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{Wanda} & .40 & .40 & .40 & .01 & .00 & .00 \\\\\n",
      "        \\textbf{SparseGPT} & .40 & .40 & .40 & .00 & .00 & .00 \\\\\n",
      "        \\cdashlinelr{1-7}\n",
      "        \\textbf{AWQ} & .41 & .41 & .41 & .02 & .01 & .00 \\\\\n",
      "        \\textbf{GPTQ} & .41 & .41 & .42 & .00 & .01 & .01 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .40 & .41 & .41 & .01 & .01 & .00 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_ke_mc_mmlu_only(mmlu_mce_df, mmlu_oi_df, editor_order, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-7}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_mmlu_only(\n",
    "    mmlu_mce_main_results,\n",
    "    mmlu_oi_main_results,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MU ←→ MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccc}\n",
      "        \\toprule\n",
      "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
      "        \\textbf{Method} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{Wanda} & .46 & .35 & .29 & .03 & .17 & .03 & .46 & .42 & .43 & .02 & .01 & .01 \\\\\n",
      "        \\textbf{SparseGPT} & .43 & .28 & .28 & .03 & .22 & .02 & .49 & .42 & .43 & .06 & .09 & .01 \\\\\n",
      "        \\cdashlinelr{1-13}\n",
      "        \\textbf{AWQ} & .43 & .24 & .27 & .02 & .00 & .01 & .53 & .58 & .44 & .02 & .07 & .01 \\\\\n",
      "        \\textbf{GPTQ} & .34 & .24 & .27 & .09 & .02 & .18 & .52 & .44 & .42 & .09 & .24 & .05 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .42 & .28 & .28 & .04 & .10 & .06 & .50 & .46 & .43 & .05 & .10 & .02 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_mu_mc():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_main_results, wmdp_oi_main_results), (mmlu_mce_main_results, mmlu_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for unlearner in unlearn_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[unlearner][compressor])}\"\n",
    "                    row_values.append(sub_metric[unlearner][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_mu_mc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccc}\n",
      "        \\toprule\n",
      "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{GA} & .93 & .52 & .00 & .07 & .48 & 1 & .96 & .59 & .22 & .04 & .41 & .78 \\\\\n",
      "        \\textbf{GD} & .01 & .07 & .00 & .67 & .40 & .56 & .19 & .11 & .29 & .56 & .41 & .48 \\\\\n",
      "        \\textbf{RMU} & .00 & .03 & .00 & .01 & .01 & .00 & .18 & .07 & .29 & .03 & .04 & .04 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .31 & .21 & .00 & .25 & .30 & .52 & .44 & .26 & .26 & .21 & .28 & .43 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def generate_latex_table_ke_mu_ke_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(edit_mce_main_results, edit_oi_main_results), (generalization_mce_main_results, generalization_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_ke_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Row: MU Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    \\begin{tabular}{lcccccccccccc}\n",
      "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
      "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
      "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
      "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
      "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
      "        \\midrule\n",
      "        \\textbf{GA} & .47 & .40 & .28 & .00 & .05 & .07 & .47 & .51 & .64 & .01 & .04 & .07 \\\\\n",
      "        \\textbf{GD} & .29 & .26 & .30 & .00 & .02 & .24 & .41 & .42 & .41 & .18 & .22 & .14 \\\\\n",
      "        \\textbf{RMU} & .28 & .29 & .29 & .04 & .01 & .00 & .43 & .44 & .44 & .01 & .00 & .04 \\\\\n",
      "        \\midrule\n",
      "        \\textit{Average} & .35 & .32 & .29 & .02 & .03 & .10 & .44 & .46 & .50 & .07 & .09 & .08 \\\\\n",
      "        \\bottomrule \\\\\n",
      "    \\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_ke_mu_mu_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_main_results, wmdp_oi_main_results), (mmlu_mce_main_results, mmlu_oi_main_results)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_mu_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Detailed Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None    : Done\n",
    "- KE ←→ MC: Done\n",
    "- MC ←→ KE: Done\n",
    "- KE ←→ MU: Todo\n",
    "- MU ←→ KE: Todo\n",
    "- MU ←→ MC: Todo\n",
    "- MC ←→ MU: Todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>wbits</th>\n",
       "      <th>sparsity_ratio</th>\n",
       "      <th>mmlu accuracy</th>\n",
       "      <th>wmdp_bio accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>compression_dataset</th>\n",
       "      <th>qa_question_count_limit</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL edits</th>\n",
       "      <th>PPl QA</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>date</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_FT</td>\n",
       "      <td>1.719118e+09</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.258743</td>\n",
       "      <td>0.243591</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>33638.4375</td>\n",
       "      <td>338052.34375</td>\n",
       "      <td>102475.617188</td>\n",
       "      <td>-1</td>\n",
       "      <td>78554.226562</td>\n",
       "      <td>2024-05-20 17:38:54.680141449</td>\n",
       "      <td>AWQ (2bit) $\\rightarrow$Fine-tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_LORA</td>\n",
       "      <td>1.718724e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.262028</td>\n",
       "      <td>0.242419</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>127311.320312</td>\n",
       "      <td>52947.800781</td>\n",
       "      <td>352363.28125</td>\n",
       "      <td>-1</td>\n",
       "      <td>96682.617188</td>\n",
       "      <td>2024-06-14 09:58:55.207093239</td>\n",
       "      <td>AWQ (2bit) $\\rightarrow$LoRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ2bit_MEMIT</td>\n",
       "      <td>1.721601e+09</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.264049</td>\n",
       "      <td>0.241424</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>1735678.75</td>\n",
       "      <td>996271.5625</td>\n",
       "      <td>1198751.125</td>\n",
       "      <td>-1</td>\n",
       "      <td>1074956.375</td>\n",
       "      <td>2024-05-20 17:01:28.464071751</td>\n",
       "      <td>AWQ (2bit) $\\rightarrow$MEMIT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ3bit_FT</td>\n",
       "      <td>1.720819e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.508567</td>\n",
       "      <td>0.596465</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>7.562892</td>\n",
       "      <td>16993.777344</td>\n",
       "      <td>648.620483</td>\n",
       "      <td>-1</td>\n",
       "      <td>822.444336</td>\n",
       "      <td>2024-06-17 08:37:54.834238052</td>\n",
       "      <td>AWQ (3bit) $\\rightarrow$Fine-tune</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>AWQ3bit_LORA</td>\n",
       "      <td>1.719290e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.510034</td>\n",
       "      <td>0.604242</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>55.692047</td>\n",
       "      <td>751300.5625</td>\n",
       "      <td>7932.938477</td>\n",
       "      <td>-1</td>\n",
       "      <td>16216.796875</td>\n",
       "      <td>2024-06-17 07:55:40.395966053</td>\n",
       "      <td>AWQ (3bit) $\\rightarrow$LoRA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA65%_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.229098</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>16268.005859</td>\n",
       "      <td>5423145.5</td>\n",
       "      <td>81961160</td>\n",
       "      <td>447.25 GFLOPS</td>\n",
       "      <td>89329664</td>\n",
       "      <td>2024-06-12 14:53:38.419730186</td>\n",
       "      <td>Wanda 0.65$\\rightarrow$GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA65%_RMU</td>\n",
       "      <td>1.716764e+09</td>\n",
       "      <td>18.666667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.229360</td>\n",
       "      <td>0.249542</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>45.534767</td>\n",
       "      <td>83373.453125</td>\n",
       "      <td>1477.523804</td>\n",
       "      <td>760 GFLOPS</td>\n",
       "      <td>1549.510742</td>\n",
       "      <td>2024-05-20 19:27:06.522696495</td>\n",
       "      <td>Wanda 0.65$\\rightarrow$RMU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_GA</td>\n",
       "      <td>1.718194e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.229811</td>\n",
       "      <td>0.249018</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>8125971838094910145582358934348365824.0</td>\n",
       "      <td>176520989218511062933962752.0</td>\n",
       "      <td>31936578699555629957120.0</td>\n",
       "      <td>357.84 GFLOPS</td>\n",
       "      <td>31529243875858664390656.0</td>\n",
       "      <td>2024-06-12 12:09:17.554701090</td>\n",
       "      <td>Wanda 0.75$\\rightarrow$GA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_GD</td>\n",
       "      <td>1.718204e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.246902</td>\n",
       "      <td>0.247447</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>10226426</td>\n",
       "      <td>743558.8125</td>\n",
       "      <td>145133.09375</td>\n",
       "      <td>357.84 GFLOPS</td>\n",
       "      <td>128967.648438</td>\n",
       "      <td>2024-06-12 14:55:21.376342773</td>\n",
       "      <td>Wanda 0.75$\\rightarrow$GD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>Llama-3 (8b)</td>\n",
       "      <td>WANDA75%_RMU</td>\n",
       "      <td>1.717030e+09</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.231769</td>\n",
       "      <td>0.250982</td>\n",
       "      <td>...</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>391.873352</td>\n",
       "      <td>151281.125</td>\n",
       "      <td>3917.281982</td>\n",
       "      <td>581.18 GFLOPS</td>\n",
       "      <td>3727.288574</td>\n",
       "      <td>2024-05-22 05:36:22.919470310</td>\n",
       "      <td>Wanda 0.75$\\rightarrow$RMU</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       model_name            tag    _timestamp   edit_set  number_of_edits  \\\n",
       "37   Llama-3 (8b)     AWQ2bit_FT  1.719118e+09   9.545455             50.0   \n",
       "38   Llama-3 (8b)   AWQ2bit_LORA  1.718724e+09   5.500000             50.0   \n",
       "39   Llama-3 (8b)  AWQ2bit_MEMIT  1.721601e+09  10.666667             50.0   \n",
       "40   Llama-3 (8b)     AWQ3bit_FT  1.720819e+09   5.500000             50.0   \n",
       "41   Llama-3 (8b)   AWQ3bit_LORA  1.719290e+09   5.500000             50.0   \n",
       "..            ...            ...           ...        ...              ...   \n",
       "343  Llama-3 (8b)    WANDA65%_GD  1.718204e+09   1.000000             50.0   \n",
       "344  Llama-3 (8b)   WANDA65%_RMU  1.716764e+09  18.666667             50.0   \n",
       "345  Llama-3 (8b)    WANDA75%_GA  1.718194e+09   1.000000             50.0   \n",
       "346  Llama-3 (8b)    WANDA75%_GD  1.718204e+09   1.000000             50.0   \n",
       "347  Llama-3 (8b)   WANDA75%_RMU  1.717030e+09   4.500000             50.0   \n",
       "\n",
       "     rmu_layer_id  wbits  sparsity_ratio  mmlu accuracy  wmdp_bio accuracy  \\\n",
       "37      -1.000000    2.0            0.00       0.258743           0.243591   \n",
       "38      -1.000000    2.0            0.00       0.262028           0.242419   \n",
       "39      -1.000000    2.0            0.00       0.264049           0.241424   \n",
       "40      -1.000000    3.0            0.00       0.508567           0.596465   \n",
       "41      -1.000000    3.0            0.00       0.510034           0.604242   \n",
       "..            ...    ...             ...            ...                ...   \n",
       "343     -1.000000    4.0            0.65       0.229098           0.249018   \n",
       "344      3.666667    4.0            0.65       0.229360           0.249542   \n",
       "345     -1.000000    4.0            0.75       0.229811           0.249018   \n",
       "346     -1.000000    4.0            0.75       0.246902           0.247447   \n",
       "347      3.000000    4.0            0.75       0.231769           0.250982   \n",
       "\n",
       "     ...  edit_dataset  compression_dataset  qa_question_count_limit  \\\n",
       "37   ...          zsre                   c4                     None   \n",
       "38   ...          zsre                   c4                     None   \n",
       "39   ...          zsre                   c4                     None   \n",
       "40   ...          zsre                   c4                     None   \n",
       "41   ...          zsre                   c4                     None   \n",
       "..   ...           ...                  ...                      ...   \n",
       "343  ...          zsre                   c4                     None   \n",
       "344  ...          zsre                   c4                     None   \n",
       "345  ...          zsre                   c4                     None   \n",
       "346  ...          zsre                   c4                     None   \n",
       "347  ...          zsre                   c4                     None   \n",
       "\n",
       "                                         PPL                      PPL edits  \\\n",
       "37                                33638.4375                   338052.34375   \n",
       "38                             127311.320312                   52947.800781   \n",
       "39                                1735678.75                    996271.5625   \n",
       "40                                  7.562892                   16993.777344   \n",
       "41                                 55.692047                    751300.5625   \n",
       "..                                       ...                            ...   \n",
       "343                             16268.005859                      5423145.5   \n",
       "344                                45.534767                   83373.453125   \n",
       "345  8125971838094910145582358934348365824.0  176520989218511062933962752.0   \n",
       "346                                 10226426                    743558.8125   \n",
       "347                               391.873352                     151281.125   \n",
       "\n",
       "                        PPl QA          FLOPs         PPl edits unmasked  \\\n",
       "37               102475.617188             -1               78554.226562   \n",
       "38                352363.28125             -1               96682.617188   \n",
       "39                 1198751.125             -1                1074956.375   \n",
       "40                  648.620483             -1                 822.444336   \n",
       "41                 7932.938477             -1               16216.796875   \n",
       "..                         ...            ...                        ...   \n",
       "343                   81961160  447.25 GFLOPS                   89329664   \n",
       "344                1477.523804     760 GFLOPS                1549.510742   \n",
       "345  31936578699555629957120.0  357.84 GFLOPS  31529243875858664390656.0   \n",
       "346               145133.09375  357.84 GFLOPS              128967.648438   \n",
       "347                3917.281982  581.18 GFLOPS                3727.288574   \n",
       "\n",
       "                             date                              Label  \n",
       "37  2024-05-20 17:38:54.680141449  AWQ (2bit) $\\rightarrow$Fine-tune  \n",
       "38  2024-06-14 09:58:55.207093239       AWQ (2bit) $\\rightarrow$LoRA  \n",
       "39  2024-05-20 17:01:28.464071751      AWQ (2bit) $\\rightarrow$MEMIT  \n",
       "40  2024-06-17 08:37:54.834238052  AWQ (3bit) $\\rightarrow$Fine-tune  \n",
       "41  2024-06-17 07:55:40.395966053       AWQ (3bit) $\\rightarrow$LoRA  \n",
       "..                            ...                                ...  \n",
       "343 2024-06-12 14:53:38.419730186          Wanda 0.65$\\rightarrow$GD  \n",
       "344 2024-05-20 19:27:06.522696495         Wanda 0.65$\\rightarrow$RMU  \n",
       "345 2024-06-12 12:09:17.554701090          Wanda 0.75$\\rightarrow$GA  \n",
       "346 2024-06-12 14:55:21.376342773          Wanda 0.75$\\rightarrow$GD  \n",
       "347 2024-05-22 05:36:22.919470310         Wanda 0.75$\\rightarrow$RMU  \n",
       "\n",
       "[311 rows x 52 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "technique_formatting_map = {\n",
    "    \"awq\": \"AWQ\",\n",
    "    \"gptq\": \"GPTQ\",\n",
    "    \"sparsegpt\": \"SparseGPT\",\n",
    "    \"wanda\": \"Wanda\",\n",
    "    \"ft\": \"FT\",\n",
    "    \"memit\": \"MEMIT\",\n",
    "    \"lora\": \"LoRA\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "    \"rmu\": \"RMU\",\n",
    "}\n",
    "appendix_compositions_order = [\n",
    "    [],\n",
    "    [\"compress\"],\n",
    "    [\"edit\"],\n",
    "    [\"edit\", \"compress\"],\n",
    "    [\"compress\", \"edit\"],\n",
    "    [\"unlearn\"],\n",
    "    [\"unlearn\", \"compress\"],\n",
    "    [\"compress\", \"unlearn\"],\n",
    "    [\"edit\", \"unlearn\"],\n",
    "    [\"unlearn\", \"edit\"],\n",
    "]\n",
    "appendix_table_columns_map = {\n",
    "    \"tag\": \"Composition\",\n",
    "    \"Rewrite accuracy\": \"Edit Success\",\n",
    "    \"Generalization\": \"Generalization\",\n",
    "    \"Locality\": \"Locality\",\n",
    "    \"Average bits\": \"Avg. Bits\",\n",
    "    \"Avg WMDP\": \"Avg. WMDP\",\n",
    "    \"mmlu accuracy\": \"MMLU\",\n",
    "    \"PPL\": \"WikiText PPL\",\n",
    "}\n",
    "appendix_technique_ordering = {\n",
    "    \"edit\": [\"Fine-tune\", \"MEMIT\", \"LoRA\"],\n",
    "    \"compress\": [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"],\n",
    "    \"unlearn\": [\"GA\", \"GD\", \"RMU\"],\n",
    "}\n",
    "\n",
    "\n",
    "def get_composition_label(row):\n",
    "    composition = row[\"interventions\"]\n",
    "    if composition == []:\n",
    "        return \"None\"\n",
    "    \n",
    "    first_intervention_type = composition[0] if composition[0] != \"compress\" else \"compression\"\n",
    "    first_intervention = technique_formatting_map.get(row[first_intervention_type], row[first_intervention_type])\n",
    "    if first_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        first_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif first_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        first_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    if len(composition) == 1:\n",
    "        return first_intervention\n",
    "    \n",
    "    second_intervention_type = composition[1] if composition[1] != \"compress\" else \"compression\"\n",
    "    second_intervention = technique_formatting_map.get(row[second_intervention_type], row[second_intervention_type])\n",
    "    if second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        second_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        second_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    return first_intervention + r\"$\\rightarrow$\" + second_intervention\n",
    "\n",
    "\n",
    "appendix_results = main_results.copy()\n",
    "appendix_results[\"interventions\"] = appendix_results[\"interventions\"].apply(lambda x : ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "appendix_results[\"Label\"] = appendix_results.apply(get_composition_label, axis=1)\n",
    "appendix_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['model_name', 'tag', '_timestamp', 'edit_set', 'number_of_edits',\n",
       "       'rmu_layer_id', 'wbits', 'sparsity_ratio', 'mmlu accuracy',\n",
       "       'wmdp_bio accuracy', 'wmdp_cyber accuracy', 'Generalization',\n",
       "       'Success recall', 'Generalization recall', 'Locality', 'Average bits',\n",
       "       'Rewrite accuracy', 'Local recall', 'Latency', 'Avg WMDP',\n",
       "       '_timestamp_se', 'edit_set_se', 'number_of_edits_se', 'rmu_layer_id_se',\n",
       "       'wbits_se', 'sparsity_ratio_se', 'mmlu accuracy_se',\n",
       "       'wmdp_bio accuracy_se', 'wmdp_cyber accuracy_se', 'Generalization_se',\n",
       "       'Success recall_se', 'Generalization recall_se', 'Locality_se',\n",
       "       'Average bits_se', 'Rewrite accuracy_se', 'Local recall_se',\n",
       "       'Latency_se', 'Avg WMDP_se', 'interventions', 'edit', 'unlearn',\n",
       "       'compression', 'edit_dataset', 'compression_dataset',\n",
       "       'qa_question_count_limit', 'PPL', 'PPL edits', 'PPl QA', 'FLOPs',\n",
       "       'PPl edits unmasked', 'date', 'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "appendix_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: Single Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rewrite accuracy',\n",
       " 'Generalization',\n",
       " 'Locality',\n",
       " 'Average bits',\n",
       " 'Avg WMDP',\n",
       " 'mmlu accuracy',\n",
       " 'PPL']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(appendix_table_columns_map.keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "edit\n",
       "Fine-tune    1\n",
       "LoRA         1\n",
       "MEMIT        1\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Could not convert string 'Infinity' to numeric",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 67\u001b[0m\n\u001b[1;32m     65\u001b[0m     latex_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;130;01m{{\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtechnique_row_label\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m}}\u001b[39;00m\u001b[38;5;124m$\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mrightarrow$None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(appendix_table_columns_map\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 67\u001b[0m         latex_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m & \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(\u001b[43mappendix_unlearn_only_technique\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\u001b[38;5;250m \u001b[39m\u001b[38;5;241m2\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m     latex_code \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# end of table\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/series.py:6549\u001b[0m, in \u001b[0;36mSeries.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m   6541\u001b[0m \u001b[38;5;129m@doc\u001b[39m(make_doc(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m\"\u001b[39m, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m   6542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m   6543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6547\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   6548\u001b[0m ):\n\u001b[0;32m-> 6549\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/generic.py:12420\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12413\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmean\u001b[39m(\n\u001b[1;32m  12414\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  12415\u001b[0m     axis: Axis \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  12418\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m  12419\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[0;32m> 12420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stat_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12421\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmean\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnanops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnanmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m  12422\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/generic.py:12377\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  12373\u001b[0m nv\u001b[38;5;241m.\u001b[39mvalidate_func(name, (), kwargs)\n\u001b[1;32m  12375\u001b[0m validate_bool_kwarg(skipna, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskipna\u001b[39m\u001b[38;5;124m\"\u001b[39m, none_allowed\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m> 12377\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reduce\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m  12378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumeric_only\u001b[49m\n\u001b[1;32m  12379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/series.py:6457\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   6452\u001b[0m     \u001b[38;5;66;03m# GH#47500 - change to TypeError to match other methods\u001b[39;00m\n\u001b[1;32m   6453\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   6454\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSeries.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not allow \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwd_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnumeric_only\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6455\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith non-numeric dtypes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6456\u001b[0m     )\n\u001b[0;32m-> 6457\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdelegate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/nanops.py:147\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    145\u001b[0m         result \u001b[38;5;241m=\u001b[39m alt(values, axis\u001b[38;5;241m=\u001b[39maxis, skipna\u001b[38;5;241m=\u001b[39mskipna, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 147\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43malt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/nanops.py:404\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike \u001b[38;5;129;01mand\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    402\u001b[0m     mask \u001b[38;5;241m=\u001b[39m isna(values)\n\u001b[0;32m--> 404\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskipna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskipna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m datetimelike:\n\u001b[1;32m    407\u001b[0m     result \u001b[38;5;241m=\u001b[39m _wrap_results(result, orig_values\u001b[38;5;241m.\u001b[39mdtype, fill_value\u001b[38;5;241m=\u001b[39miNaT)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/nanops.py:720\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    718\u001b[0m count \u001b[38;5;241m=\u001b[39m _get_counts(values\u001b[38;5;241m.\u001b[39mshape, mask, axis, dtype\u001b[38;5;241m=\u001b[39mdtype_count)\n\u001b[1;32m    719\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39msum(axis, dtype\u001b[38;5;241m=\u001b[39mdtype_sum)\n\u001b[0;32m--> 720\u001b[0m the_sum \u001b[38;5;241m=\u001b[39m \u001b[43m_ensure_numeric\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthe_sum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(the_sum, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    723\u001b[0m     count \u001b[38;5;241m=\u001b[39m cast(np\u001b[38;5;241m.\u001b[39mndarray, count)\n",
      "File \u001b[0;32m~/miniconda3/envs/lm-compose/lib/python3.11/site-packages/pandas/core/nanops.py:1701\u001b[0m, in \u001b[0;36m_ensure_numeric\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1698\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (is_float(x) \u001b[38;5;129;01mor\u001b[39;00m is_integer(x) \u001b[38;5;129;01mor\u001b[39;00m is_complex(x)):\n\u001b[1;32m   1699\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1700\u001b[0m         \u001b[38;5;66;03m# GH#44008, GH#36703 avoid casting e.g. strings to numeric\u001b[39;00m\n\u001b[0;32m-> 1701\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not convert string \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m to numeric\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1702\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1703\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(x)\n",
      "\u001b[0;31mTypeError\u001b[0m: Could not convert string 'Infinity' to numeric"
     ]
    }
   ],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# None\n",
    "appendix_no_compositons = appendix_results[appendix_results[\"interventions\"].apply(lambda x: len(x) == 0)]\n",
    "latex_code += r\"   {None}\"\n",
    "for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "    latex_code += f\" & {appendix_no_compositons[col].mean():.2f}\"\n",
    "\n",
    "latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Edit Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_edit_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\"])]\n",
    "display(appendix_edit_only.value_counts(\"edit\"))\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    appendix_edit_only_technique = appendix_edit_only[appendix_edit_only[\"edit\"] == edit_technique]\n",
    "    assert len(appendix_edit_only_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    technique_row_label = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\"& {round(appendix_edit_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Compress Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_compress_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_only_technique = appendix_compress_only[appendix_compress_only[\"compression\"] == compress_technique]\n",
    "    assert len(appendix_compress_only_technique) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(appendix_compress_only_technique[compression_strength_column].unique())\n",
    "    for compression_strength in compression_strength_ordering:\n",
    "        technique_row_label = compress_technique\n",
    "        current_compression = appendix_compress_only_technique[appendix_compress_only_technique[compression_strength_column] == compression_strength]\n",
    "        if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "            technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "        elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "            technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "        \n",
    "        latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "        \n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Unlearn Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_unlearn_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    appendix_unlearn_only_technique = appendix_unlearn_only[appendix_unlearn_only[\"unlearn\"] == unlearn_technique]\n",
    "    assert len(appendix_unlearn_only_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    technique_row_label = unlearn_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\" & {round(appendix_unlearn_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_edit_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    appendix_edit_compress_edit_technique = appendix_edit_compress[appendix_edit_compress[\"edit\"] == edit_technique]\n",
    "    assert len(appendix_edit_compress_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        appendix_edit_compress_technique_frame = appendix_edit_compress_edit_technique[appendix_edit_compress_edit_technique[\"compression\"] == compress_technique]\n",
    "        assert len(appendix_edit_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_edit_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_edit_compress_technique_frame[appendix_edit_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_edit_technique_frame = appendix_compress_edit[appendix_compress_edit[\"compression\"] == compress_technique]\n",
    "    assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_edit_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "    print(f\"Technique: {compress_technique}, Strengths: {compression_strength_ordering}\")\n",
    "\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        appendix_compress_edit_edit_technique = appendix_compress_edit_technique_frame[appendix_compress_edit_technique_frame[\"edit\"] == edit_technique]\n",
    "        assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_edit_edit_technique[round(appendix_compress_edit_edit_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: MU ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Compression\n",
    "appendix_unlearn_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    appendix_unlearn_compress_unlearn_technique = appendix_unlearn_compress[appendix_unlearn_compress[\"unlearn\"] == unlearn_technique]\n",
    "    assert len(appendix_unlearn_compress_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        appendix_unlearn_compress_technique_frame = appendix_unlearn_compress_unlearn_technique[appendix_unlearn_compress_unlearn_technique[\"compression\"] == compress_technique]\n",
    "        assert len(appendix_unlearn_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_unlearn_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_unlearn_compress_technique_frame[appendix_unlearn_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Compression -> Unlearn\n",
    "appendix_compress_unlearn = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_unlearn_technique_frame = appendix_compress_unlearn[appendix_compress_unlearn[\"compression\"] == compress_technique.lower()]\n",
    "    assert len(appendix_compress_unlearn_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_unlearn_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_unlearn_unlearn_technique = appendix_compress_unlearn_technique_frame[appendix_compress_unlearn_technique_frame[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_unlearn_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_unlearn_unlearn_technique[round(appendix_compress_unlearn_unlearn_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                assert len(current_compression) == 1, f\"Multiple rows found for {compress_technique} -> {unlearn_technique} -> {compression_strength}\"\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Edit -> Unlearn\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    appendix_compress_edit_edit_technique = appendix_compress_edit[appendix_compress_edit[\"edit\"] == formatted_edit_technique.lower()]\n",
    "    assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_edit_technique_frame = appendix_compress_edit_edit_technique[appendix_compress_edit_edit_technique[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {unlearn_technique}\"\n",
    "\n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = edit_technique\n",
    "        latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_compress_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Edit\n",
    "appendix_unlearn_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    formatted_unlearn_technique = unlearn_technique\n",
    "    appendix_unlearn_edit_unlearn_technique = appendix_unlearn_edit[appendix_unlearn_edit[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "    assert len(appendix_unlearn_edit_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "        appendix_unlearn_edit_technique_frame = appendix_unlearn_edit_unlearn_technique[appendix_unlearn_edit_unlearn_technique[\"edit\"] == formatted_edit_technique.lower()]\n",
    "        assert len(appendix_unlearn_edit_technique_frame) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = unlearn_technique\n",
    "        latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_unlearn_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_label(row):\n",
    "    interventions = row[\"interventions\"]\n",
    "    first_method = \"\"\n",
    "    second_method = \"\"\n",
    "    if interventions[0] == \"edit\":\n",
    "        first_method = row[\"edit\"]\n",
    "    elif interventions[0] == \"compress\":\n",
    "        first_method = row[\"compression\"]\n",
    "    elif interventions[0] == \"unlearn\":\n",
    "        first_method = row[\"unlearn\"]\n",
    "    \n",
    "    if interventions[1] == \"edit\":\n",
    "        second_method = row[\"edit\"]\n",
    "    elif interventions[1] == \"compress\":\n",
    "        second_method = row[\"compression\"]\n",
    "    elif interventions[1] == \"unlearn\":\n",
    "        second_method = row[\"unlearn\"]\n",
    "    \n",
    "    return f\"{first_method}→{second_method}\"\n",
    "\n",
    "def wrap_label(interventions):\n",
    "    first_intervention, second_intervention = interventions[0], interventions[1]\n",
    "    first_letter_upper = first_intervention[0].upper()\n",
    "    second_letter_upper = second_intervention[0].upper()\n",
    "    \n",
    "    # EX: E $\\rightarrow$ C\n",
    "    return f\"{first_letter_upper}$\\\\rightarrow${second_letter_upper}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock records for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want instances where editing has been applied but there is no unlearning or compression. In these cases, set wbits=16 and sparsity=0 \n",
    "baseline_editors = main_results[(main_results[\"edit\"].notnull()) & (main_results[\"unlearn\"].isnull()) & (main_results[\"compression\"].isnull()) & (main_results[\"interventions\"].apply(lambda x: x == [\"edit\"]))].copy()\n",
    "baseline_editors[\"wbits\"] = 16\n",
    "baseline_editors[\"sparsity_ratio\"] = 0\n",
    "news_records = []\n",
    "\n",
    "# Edit and Compress\n",
    "for editing_method in [\"LoRA\", \"MEMIT\", \"Fine-tune\"]:\n",
    "    baseline_record = baseline_editors[baseline_editors[\"edit\"] == editing_method]\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        edit_first_record = baseline_record.copy()\n",
    "        edit_first_record[\"compression\"] = compression_method\n",
    "        edit_first_record[\"interventions\"] = [[\"edit\", \"compress\"]]\n",
    "        edit_first_record[\"sparsity_ratio\"] = 0\n",
    "        edit_first_record[\"wbits\"] = 16\n",
    "        news_records.append(edit_first_record)\n",
    "\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"edit\"]]\n",
    "        compress_first_record[\"sparsity_ratio\"] = 0\n",
    "        compress_first_record[\"wbits\"] = 16\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "baseline_unlearners = main_results[(main_results[\"edit\"].isnull()) & (main_results[\"unlearn\"].notnull()) & (main_results[\"compression\"].isnull()) & (main_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"]))].copy()\n",
    "\n",
    "# Compress and Unlearn\n",
    "for unlearn_method in [\"RMU\", \"GA\", \"GD\"]:\n",
    "    baseline_record = baseline_unlearners[baseline_unlearners[\"unlearn\"] == unlearn_method]\n",
    "\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"unlearn\"] = unlearn_method\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"unlearn\"]]\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "        unlearn_first_record = baseline_record.copy()\n",
    "        unlearn_first_record[\"unlearn\"] = unlearn_method\n",
    "        unlearn_first_record[\"compression\"] = compression_method\n",
    "        unlearn_first_record[\"interventions\"] = [[\"unlearn\", \"compress\"]]\n",
    "        news_records.append(unlearn_first_record)\n",
    "\n",
    "baseline_records = pd.concat(news_records)\n",
    "data = pd.concat([main_results, baseline_records])\n",
    "baseline_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing and Compresion Single Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: KE ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "\n",
    "row_metrics = {\n",
    "    0: \"Rewrite accuracy\",\n",
    "    1: \"Generalization\",\n",
    "    2: \"Locality\",\n",
    "    3: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    0: r\"Edit Success$ \\uparrow$\",\n",
    "    1: r\"Generalization$ \\uparrow$\",\n",
    "    2: r\"Locality$ \\uparrow$\",\n",
    "    3: r\"MMLU$ \\uparrow$\"\n",
    "}\n",
    "column_edit_methods = {\n",
    "    0: \"MEMIT\",\n",
    "    1: \"LoRA\",\n",
    "    2: \"Fine-tune\",\n",
    "    3: \"MEMIT\",\n",
    "    4: \"LoRA\",\n",
    "    5: \"Fine-tune\"\n",
    "}\n",
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}\n",
    "final_row_index = len(row_labels) - 1\n",
    "\n",
    "fig, axes = plt.subplots(len(row_labels), 6, figsize=(6 * FIG_SIZE, len(row_labels) * FIG_SIZE))\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"edit\"] == column_edit_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"MEMIT\", \"LoRA\", \"Fine-tune\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index != final_row_index:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        else:\n",
    "            ax.set_ylim(0.2, 0.65)\n",
    "            ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "        if y_metric == \"Locality\":\n",
    "            ax.set_ylim(0, .2)\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_edit_methods[col_index] if column_edit_methods[col_index] != \"Fine-tune\" else \"FT\"\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[row_index], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == len(row_labels) - 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == final_row_index:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_editors_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Unlearning ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "pruning_frame[\"unlearn\"] = pruning_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "quantization_frame[\"unlearn\"] = quantization_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(2, 6, figsize=(6 * FIG_SIZE, 2 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    \"Avg WMDP\": r\"WMDP $\\downarrow$\",\n",
    "    \"mmlu accuracy\": r\"MMLU $\\uparrow$\"\n",
    "}\n",
    "row_label_map = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\"\n",
    "}\n",
    "column_unlearn_methods = {\n",
    "    0: \"GA\",\n",
    "    1: \"GD\",\n",
    "    2: \"RMU\",\n",
    "    3: \"GA\",\n",
    "    4: \"GD\",\n",
    "    5: \"RMU\",\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    \n",
    "    # GA and WANDA + SparseGPT\n",
    "    0: [(\"GA→SparseGPT\", \"SparseGPT→GA\"), (\"GA→Wanda\", \"Wanda→GA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    1: [(\"GD→SparseGPT\", \"SparseGPT→GD\"), (\"GD→Wanda\", \"Wanda→GD\")],\n",
    "    # RMU and WANDA + SparseGPT\n",
    "    2: [(\"RMU→SparseGPT\", \"SparseGPT→RMU\"), (\"RMU→Wanda\", \"Wanda→RMU\")],\n",
    "    # GA and GPTQ + AWQ\n",
    "    3: [(\"GA→GPTQ\", \"GPTQ→GA\"), (\"GA→AWQ\", \"AWQ→GA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    4: [(\"GD→GPTQ\", \"GPTQ→GD\"), (\"GD→AWQ\", \"AWQ→GD\")],\n",
    "    # RMU and GPTQ + AWQ\n",
    "    5: [(\"RMU→GPTQ\", \"GPTQ→RMU\"), (\"RMU→AWQ\", \"AWQ→RMU\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"unlearn\"] == column_unlearn_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"RMU\", \"GA\", \"GD\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "        ax.set_ylim(0.20, 0.65)\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_unlearn_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[list(row_labels.keys())[row_index]], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_unlearn_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-compose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
