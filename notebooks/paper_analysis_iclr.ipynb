{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the font family to serif\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# plotting constants\n",
    "TITLE_FONT_SIZE = 18\n",
    "LEGEND_FONT_SIZE = 12\n",
    "WSPACE = 0.3\n",
    "FIGURE_HEIGHT = 3\n",
    "LINE_WIDTH = 2\n",
    "FIG_SIZE = 3\n",
    "MARKER_SIZE = 8\n",
    "X_LABEL_ROTATION = 20\n",
    "\n",
    "# Set colors for compositons with compression\n",
    "colors = {\"Wanda\": \"C1\", \"SparseGPT\": \"C2\", \"AWQ\": \"C3\", \"GPTQ\": \"C4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull and Dedup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  20%|██        | 1728/8638 [00:09<00:58, 117.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run tng580q6: '_timestamp'\n",
      "Error processing run 4h1svpsz: '_timestamp'\n",
      "Error processing run 1sv3orzy: '_timestamp'\n",
      "Error processing run 50u5183e: '_timestamp'\n",
      "Error processing run y6su2u0y: '_timestamp'\n",
      "Error processing run j8q837ii: '_timestamp'\n",
      "Error processing run wxhmtvc3: '_timestamp'\n",
      "Error processing run s9y8jjqc: '_timestamp'\n",
      "Error processing run ubwgkh20: '_timestamp'\n",
      "Error processing run tyyr84xe: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  20%|██        | 1751/8638 [00:09<01:01, 111.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run mr5hepax: '_timestamp'\n",
      "Error processing run 70jjkyi8: '_timestamp'\n",
      "Error processing run 0zajxvii: '_timestamp'\n",
      "Error processing run qpbntab7: '_timestamp'\n",
      "Error processing run o96r1eri: '_timestamp'\n",
      "Error processing run z0zdi9rt: '_timestamp'\n",
      "Error processing run 5iuwtu93: '_timestamp'\n",
      "Error processing run sj3fikwq: '_timestamp'\n",
      "Error processing run xl827wv8: '_timestamp'\n",
      "Error processing run e3h9gw6u: '_timestamp'\n",
      "Error processing run mhvullqf: '_timestamp'\n",
      "Error processing run r9giysve: '_timestamp'\n",
      "Error processing run 886uc8iw: '_timestamp'\n",
      "Error processing run 9buz1998: '_timestamp'\n",
      "Error processing run eqa5mopp: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  22%|██▏       | 1866/8638 [00:09<00:48, 140.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run choi1k81: '_timestamp'\n",
      "Error processing run b9l540xx: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  27%|██▋       | 2301/8638 [00:13<00:52, 121.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run syb2xqv3: '_timestamp'\n",
      "Error processing run ilvfkzv1: '_timestamp'\n",
      "Error processing run ezsnt0g5: '_timestamp'\n",
      "Error processing run 4u2krnmr: '_timestamp'\n",
      "Error processing run w44vemk4: '_timestamp'\n",
      "Error processing run sgw1bwq3: '_timestamp'\n",
      "Error processing run pzbmjnlx: '_timestamp'\n",
      "Error processing run 4cx23357: '_timestamp'\n",
      "Error processing run x4zeo5mn: '_timestamp'\n",
      "Error processing run ustm079w: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  42%|████▏     | 3619/8638 [00:22<00:36, 136.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run trmp0j62: '_timestamp'\n",
      "Error processing run kt9u2jjl: '_timestamp'\n",
      "Error processing run tsostb8c: '_timestamp'\n",
      "Error processing run n36d9wfy: '_timestamp'\n",
      "Error processing run 9pywqyfi: '_timestamp'\n",
      "Error processing run j50re1is: '_timestamp'\n",
      "Error processing run n1nj8xq5: '_timestamp'\n",
      "Error processing run m9q8fawv: '_timestamp'\n",
      "Error processing run x21qup6h: '_timestamp'\n",
      "Error processing run u2uaxi9s: '_timestamp'\n",
      "Error processing run sblvym9w: '_timestamp'\n",
      "Error processing run 2jggmjk7: '_timestamp'\n",
      "Error processing run 117s16id: '_timestamp'\n",
      "Error processing run wt59w8pr: '_timestamp'\n",
      "Error processing run s64e9fxo: '_timestamp'\n",
      "Error processing run lmaany12: '_timestamp'\n",
      "Error processing run iv5ul1n7: '_timestamp'\n",
      "Error processing run h512597d: '_timestamp'\n",
      "Error processing run bqi05lpe: '_timestamp'\n",
      "Error processing run a1ri8lbk: '_timestamp'\n",
      "Error processing run 7oaha4p2: '_timestamp'\n",
      "Error processing run aq2oaxur: '_timestamp'\n",
      "Error processing run 54ohzkld: '_timestamp'\n",
      "Error processing run 1z3gnedp: '_timestamp'\n",
      "Error processing run 1tr3e1m4: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  73%|███████▎  | 6301/8638 [00:43<00:15, 151.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run evuxnltk: '_timestamp'\n",
      "Error processing run mje2wvj7: '_timestamp'\n",
      "Error processing run um0dxn3y: '_timestamp'\n",
      "Error processing run isna6rgu: '_timestamp'\n",
      "Error processing run luhstpn5: '_timestamp'\n",
      "Error processing run lrh5z3wp: '_timestamp'\n",
      "Error processing run 2do500pc: '_timestamp'\n",
      "Error processing run 71jdht68: '_timestamp'\n",
      "Error processing run 64ed5z4t: '_timestamp'\n",
      "Error processing run 1wj0u6cj: '_timestamp'\n",
      "Error processing run cc3cmdlj: '_timestamp'\n",
      "Error processing run 7t3n8sq1: '_timestamp'\n",
      "Error processing run o1ai36xl: '_timestamp'\n",
      "Error processing run 31j4yjsr: '_timestamp'\n",
      "Error processing run 2nv88i8v: '_timestamp'\n",
      "Error processing run sdhehb2z: '_timestamp'\n",
      "Error processing run r6kpsu09: '_timestamp'\n",
      "Error processing run arid375k: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|█████████▉| 8596/8638 [01:03<00:00, 136.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 8638/8638 [01:03<00:00, 135.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# Composable_Interventions has all the results\n",
    "project_paths = [\"dri-ice/Composable_Interventions\",]\n",
    "\n",
    "filter_dict = { \"state\": \"finished\" }\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the c        onfig and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-09-19 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6612/6612 [00:00<00:00, 142048.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.75%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.55%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.35%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.75%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.55%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.35%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.75% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.55% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.35% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.75% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.55% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.45% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.35% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping ft-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping memit-gd for edit dataset counterfact\n",
      "Skipping ft-gd for edit dataset counterfact\n",
      "Skipping lora-gd for edit dataset counterfact\n",
      "Skipping memit-gd for edit dataset mquake\n",
      "Skipping ft-gd for edit dataset mquake\n",
      "Skipping lora-gd for edit dataset mquake\n",
      "Skipping gd-lora for edit dataset counterfact\n",
      "Skipping gd-ft for edit dataset counterfact\n",
      "Skipping gd-memit for edit dataset counterfact\n",
      "Skipping gd-memit for edit dataset mquake\n",
      "Skipping gd-ft for edit dataset mquake\n",
      "Skipping gd-lora for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping lora-ga for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping lora-ga for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping ga-lora for edit dataset counterfact\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping ga-lora for edit dataset mquake\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping lora-ga for edit dataset counterfact\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping lora-ga for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping ga-lora for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping ga-lora for edit dataset counterfact\n",
      "Skipping gd-lora for edit dataset counterfact\n",
      "Skipping gd-lora for edit dataset mquake\n",
      "Skipping memit-gd for edit dataset counterfact\n",
      "Skipping ft-gd for edit dataset mquake\n",
      "Skipping ft-gd for edit dataset counterfact\n",
      "Skipping lora-gd for edit dataset counterfact\n",
      "Skipping memit-gd for edit dataset mquake\n",
      "Skipping gd-ft for edit dataset mquake\n",
      "Skipping gd-memit for edit dataset counterfact\n",
      "Skipping gd-ft for edit dataset counterfact\n",
      "Skipping gd-memit for edit dataset mquake\n",
      "Skipping lora-gd for edit dataset mquake\n",
      "Skipping memit-ga for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset counterfact\n",
      "Skipping ga-memit for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset mquake\n",
      "Skipping memit-ga for edit dataset mquake\n",
      "Skipping ga-memit for edit dataset counterfact\n",
      "Skipping ga-ft for edit dataset mquake\n",
      "Skipping ft-ga for edit dataset counterfact\n",
      "Skipping lora-rmu for edit dataset counterfact\n",
      "Skipping memit-rmu for edit dataset mquake\n",
      "Skipping rmu-memit for edit dataset counterfact\n",
      "Skipping rmu-ft for edit dataset counterfact\n",
      "Skipping rmu-memit for edit dataset mquake\n",
      "Skipping rmu-lora for edit dataset counterfact\n",
      "Skipping memit-rmu for edit dataset counterfact\n",
      "Skipping rmu-lora for edit dataset mquake\n",
      "Skipping rmu-ft for edit dataset mquake\n",
      "Skipping ft-rmu for edit dataset counterfact\n",
      "Skipping rmu-memit for edit dataset counterfact\n",
      "Skipping rmu-ft for edit dataset counterfact\n",
      "Skipping lora-rmu for edit dataset counterfact\n",
      "Skipping rmu-lora for edit dataset counterfact\n",
      "Skipping AWQ8bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ8bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ4bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ4bit-to-lora for edit dataset mquake\n",
      "Skipping AWQ2bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ2bit-to-lora for edit dataset mquake\n",
      "Skipping lora-to-AWQ8bit for edit dataset mquake\n",
      "Skipping lora-to-AWQ8bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ4bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ4bit for edit dataset mquake\n",
      "Skipping lora-to-AWQ2bit for edit dataset counterfact\n",
      "Skipping lora-to-AWQ2bit for edit dataset mquake\n",
      "Skipping SparseGPT0.65%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.65%-to-lora for edit dataset mquake\n",
      "Skipping SparseGPT0.45%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.45%-to-lora for edit dataset mquake\n",
      "Skipping SparseGPT0.25%-to-lora for edit dataset counterfact\n",
      "Skipping SparseGPT0.25%-to-lora for edit dataset mquake\n",
      "Skipping Wanda0.45%-to-lora for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-lora for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.45% for edit dataset mquake\n",
      "Skipping Wanda0.65%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.45%-to-ft for edit dataset mquake\n",
      "Skipping Wanda0.25%-to-ft for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-ft for edit dataset mquake\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.65% for edit dataset mquake\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping ft-to-SparseGPT0.25% for edit dataset mquake\n",
      "Skipping ft-to-Wanda0.65% for edit dataset mquake\n",
      "Skipping ft-to-Wanda0.45% for edit dataset mquake\n",
      "Skipping ft-to-Wanda0.25% for edit dataset mquake\n",
      "Skipping ft_Edit for edit dataset counterfact\n",
      "Skipping AWQ8bit-to-lora for edit dataset counterfact\n",
      "Skipping AWQ4bit-to-lora for edit dataset mquake\n",
      "Skipping lora-to-AWQ2bit for edit dataset mquake\n",
      "Skipping lora-to-Wanda0.65% for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.65% for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.65% for edit dataset counterfact\n",
      "Skipping lora_Edit for edit dataset counterfact\n",
      "Skipping Wanda0.25%-to-lora for edit dataset mquake\n",
      "Skipping Wanda0.25%-to-lora for edit dataset counterfact\n",
      "Skipping lora-to-Wanda0.25% for edit dataset mquake\n",
      "Skipping lora-to-Wanda0.25% for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.25% for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.25% for edit dataset mquake\n",
      "Skipping lora_Edit for edit dataset mquake\n",
      "Skipping lora-to-SparseGPT0.45% for edit dataset counterfact\n",
      "Skipping lora-to-SparseGPT0.45% for edit dataset mquake\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def should_keep_frame(frame):\n",
    "    if frame[\"edit_dataset\"] == \"zsre\":\n",
    "        return True\n",
    "    \n",
    "    if \"edit\" not in frame[\"interventions\"]:\n",
    "        return True\n",
    "    \n",
    "    print(f\"Skipping {frame['tag']} for edit dataset {frame['edit_dataset']}\")\n",
    "    return False\n",
    "\n",
    "# Sort by \"tag\" and \"_timestamp\" in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# Keep only the current edit dataset\n",
    "all_runs_df = all_runs_df[all_runs_df.progress_apply(lambda x: should_keep_frame(x), axis=1)]\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=[\"tag\", \"_timestamp\"], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit=\"s\")\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=[\"_timestamp\"], ascending=[False])\n",
    "all_runs_df_sorted[\"Avg WMDP\"] = (all_runs_df_sorted[\"wmdp_bio accuracy\"] + all_runs_df_sorted[\"wmdp_cyber accuracy\"]) / 2\n",
    "all_runs_df_sorted = all_runs_df_sorted[all_runs_df_sorted[\"qa_question_count_limit\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548918/1719655782.py:12: FutureWarning: ['interventions', 'edit', 'unlearn', 'compression', 'edit_dataset', 'compression_dataset', 'PPL', 'PPL edits', 'PPl QA', 'FLOPs', 'PPl edits unmasked'] did not aggregate successfully. If any error is raised this will raise in a future version of pandas. Drop these columns/ops to avoid this warning.\n",
      "  grouped_df = latest_runs_df.groupby([\"model_name\", \"tag\"]).agg([\"mean\", standard_error])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>tag</th>\n",
       "      <th>_timestamp</th>\n",
       "      <th>edit_set</th>\n",
       "      <th>number_of_edits</th>\n",
       "      <th>rmu_layer_id</th>\n",
       "      <th>wbits</th>\n",
       "      <th>sparsity_ratio</th>\n",
       "      <th>qa_question_count_limit_x</th>\n",
       "      <th>mmlu accuracy</th>\n",
       "      <th>...</th>\n",
       "      <th>compression</th>\n",
       "      <th>edit_dataset</th>\n",
       "      <th>compression_dataset</th>\n",
       "      <th>qa_question_count_limit_y</th>\n",
       "      <th>PPL</th>\n",
       "      <th>PPL edits</th>\n",
       "      <th>PPl QA</th>\n",
       "      <th>FLOPs</th>\n",
       "      <th>PPl edits unmasked</th>\n",
       "      <th>date_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>AWQ2bit-to-ft</td>\n",
       "      <td>1.719118e+09</td>\n",
       "      <td>9.545455</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.258743</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>33638.4375</td>\n",
       "      <td>338052.34375</td>\n",
       "      <td>102475.617188</td>\n",
       "      <td>-1</td>\n",
       "      <td>78554.226562</td>\n",
       "      <td>2024-05-20 17:38:54.680141568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>AWQ2bit-to-lora</td>\n",
       "      <td>1.718724e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.262028</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>127311.320312</td>\n",
       "      <td>52947.800781</td>\n",
       "      <td>352363.28125</td>\n",
       "      <td>-1</td>\n",
       "      <td>96682.617188</td>\n",
       "      <td>2024-06-14 09:58:55.207093248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>AWQ2bit-to-memit</td>\n",
       "      <td>1.721601e+09</td>\n",
       "      <td>10.666667</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264049</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>1735678.75</td>\n",
       "      <td>996271.5625</td>\n",
       "      <td>1198751.125</td>\n",
       "      <td>-1</td>\n",
       "      <td>1074956.375</td>\n",
       "      <td>2024-05-20 17:01:28.464071680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>AWQ3bit-to-ft</td>\n",
       "      <td>1.720819e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.508567</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>7.562892</td>\n",
       "      <td>16993.777344</td>\n",
       "      <td>648.620483</td>\n",
       "      <td>-1</td>\n",
       "      <td>822.444336</td>\n",
       "      <td>2024-06-17 08:37:54.834237952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>meta-llama/Meta-Llama-3-8B</td>\n",
       "      <td>AWQ3bit-to-lora</td>\n",
       "      <td>1.719290e+09</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.510034</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>55.692047</td>\n",
       "      <td>751300.5625</td>\n",
       "      <td>7932.938477</td>\n",
       "      <td>-1</td>\n",
       "      <td>16216.796875</td>\n",
       "      <td>2024-06-17 07:55:40.395965952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-awq8bit</td>\n",
       "      <td>1.726225e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.585743</td>\n",
       "      <td>...</td>\n",
       "      <td>awq</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.734568</td>\n",
       "      <td>90627.210938</td>\n",
       "      <td>300.767761</td>\n",
       "      <td>-1</td>\n",
       "      <td>448.873871</td>\n",
       "      <td>2024-09-13 10:59:33.378082560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-ft</td>\n",
       "      <td>1.726134e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.494873</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.805961</td>\n",
       "      <td>56338.621094</td>\n",
       "      <td>857.478333</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>1146.820679</td>\n",
       "      <td>2024-09-12 09:35:43.696657920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-lora</td>\n",
       "      <td>1.726146e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.567227</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>10.45087</td>\n",
       "      <td>249094.265625</td>\n",
       "      <td>3847.212158</td>\n",
       "      <td>1.79 TFLOPS</td>\n",
       "      <td>3661.797852</td>\n",
       "      <td>2024-09-12 12:55:28.729677824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-memit</td>\n",
       "      <td>1.726228e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.560675</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>zsre</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.74005</td>\n",
       "      <td>16454.134766</td>\n",
       "      <td>254.244461</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>629.994202</td>\n",
       "      <td>2024-09-13 11:48:50.830707200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>mistralai/Mistral-7B-Instruct-v0.3</td>\n",
       "      <td>rmu-none</td>\n",
       "      <td>1.726224e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.587523</td>\n",
       "      <td>...</td>\n",
       "      <td>none</td>\n",
       "      <td>mquake</td>\n",
       "      <td>c4</td>\n",
       "      <td>None</td>\n",
       "      <td>4.732034</td>\n",
       "      <td>144880.71875</td>\n",
       "      <td>314.706909</td>\n",
       "      <td>1.82 TFLOPS</td>\n",
       "      <td>563.490967</td>\n",
       "      <td>2024-09-13 10:31:47.380945664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>476 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             model_name               tag    _timestamp  \\\n",
       "0            meta-llama/Meta-Llama-3-8B     AWQ2bit-to-ft  1.719118e+09   \n",
       "1            meta-llama/Meta-Llama-3-8B   AWQ2bit-to-lora  1.718724e+09   \n",
       "2            meta-llama/Meta-Llama-3-8B  AWQ2bit-to-memit  1.721601e+09   \n",
       "3            meta-llama/Meta-Llama-3-8B     AWQ3bit-to-ft  1.720819e+09   \n",
       "4            meta-llama/Meta-Llama-3-8B   AWQ3bit-to-lora  1.719290e+09   \n",
       "..                                  ...               ...           ...   \n",
       "471  mistralai/Mistral-7B-Instruct-v0.3       rmu-awq8bit  1.726225e+09   \n",
       "472  mistralai/Mistral-7B-Instruct-v0.3            rmu-ft  1.726134e+09   \n",
       "473  mistralai/Mistral-7B-Instruct-v0.3          rmu-lora  1.726146e+09   \n",
       "474  mistralai/Mistral-7B-Instruct-v0.3         rmu-memit  1.726228e+09   \n",
       "475  mistralai/Mistral-7B-Instruct-v0.3          rmu-none  1.726224e+09   \n",
       "\n",
       "      edit_set  number_of_edits  rmu_layer_id  wbits  sparsity_ratio  \\\n",
       "0     9.545455             50.0          -1.0    2.0             0.0   \n",
       "1     5.500000             50.0          -1.0    2.0             0.0   \n",
       "2    10.666667             50.0          -1.0    2.0             0.0   \n",
       "3     5.500000             50.0          -1.0    3.0             0.0   \n",
       "4     5.500000             50.0          -1.0    3.0             0.0   \n",
       "..         ...              ...           ...    ...             ...   \n",
       "471   1.000000             50.0           6.0    8.0             0.0   \n",
       "472   1.000000             50.0           6.0   16.0             0.0   \n",
       "473   1.000000             50.0           6.0   16.0             0.0   \n",
       "474   1.000000             50.0           6.0   16.0             0.0   \n",
       "475   1.000000             50.0           6.0   16.0             0.0   \n",
       "\n",
       "     qa_question_count_limit_x  mmlu accuracy  ...  compression  edit_dataset  \\\n",
       "0                          NaN       0.258743  ...          awq          zsre   \n",
       "1                          NaN       0.262028  ...          awq          zsre   \n",
       "2                          NaN       0.264049  ...          awq          zsre   \n",
       "3                          NaN       0.508567  ...          awq          zsre   \n",
       "4                          NaN       0.510034  ...          awq          zsre   \n",
       "..                         ...            ...  ...          ...           ...   \n",
       "471                        NaN       0.585743  ...          awq          zsre   \n",
       "472                        NaN       0.494873  ...         none          zsre   \n",
       "473                        NaN       0.567227  ...         none          zsre   \n",
       "474                        NaN       0.560675  ...         none          zsre   \n",
       "475                        NaN       0.587523  ...         none        mquake   \n",
       "\n",
       "     compression_dataset  qa_question_count_limit_y            PPL  \\\n",
       "0                     c4                       None     33638.4375   \n",
       "1                     c4                       None  127311.320312   \n",
       "2                     c4                       None     1735678.75   \n",
       "3                     c4                       None       7.562892   \n",
       "4                     c4                       None      55.692047   \n",
       "..                   ...                        ...            ...   \n",
       "471                   c4                       None       4.734568   \n",
       "472                   c4                       None       4.805961   \n",
       "473                   c4                       None       10.45087   \n",
       "474                   c4                       None        4.74005   \n",
       "475                   c4                       None       4.732034   \n",
       "\n",
       "         PPL edits         PPl QA        FLOPs  PPl edits unmasked  \\\n",
       "0     338052.34375  102475.617188           -1        78554.226562   \n",
       "1     52947.800781   352363.28125           -1        96682.617188   \n",
       "2      996271.5625    1198751.125           -1         1074956.375   \n",
       "3     16993.777344     648.620483           -1          822.444336   \n",
       "4      751300.5625    7932.938477           -1        16216.796875   \n",
       "..             ...            ...          ...                 ...   \n",
       "471   90627.210938     300.767761           -1          448.873871   \n",
       "472   56338.621094     857.478333  1.82 TFLOPS         1146.820679   \n",
       "473  249094.265625    3847.212158  1.79 TFLOPS         3661.797852   \n",
       "474   16454.134766     254.244461  1.82 TFLOPS          629.994202   \n",
       "475   144880.71875     314.706909  1.82 TFLOPS          563.490967   \n",
       "\n",
       "                           date_y  \n",
       "0   2024-05-20 17:38:54.680141568  \n",
       "1   2024-06-14 09:58:55.207093248  \n",
       "2   2024-05-20 17:01:28.464071680  \n",
       "3   2024-06-17 08:37:54.834237952  \n",
       "4   2024-06-17 07:55:40.395965952  \n",
       "..                            ...  \n",
       "471 2024-09-13 10:59:33.378082560  \n",
       "472 2024-09-12 09:35:43.696657920  \n",
       "473 2024-09-12 12:55:28.729677824  \n",
       "474 2024-09-13 11:48:50.830707200  \n",
       "475 2024-09-13 10:31:47.380945664  \n",
       "\n",
       "[476 rows x 55 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sort by the recency column, for example, \"date\"\n",
    "all_runs_df_sorted = all_runs_df_sorted.sort_values(by=\"date\")\n",
    "\n",
    "# Drop duplicates, keeping only the most recent occurrence for each \"tag\" and \"edit_set\"\n",
    "latest_runs_df = all_runs_df_sorted.drop_duplicates(subset=[\"model_name\", \"tag\", \"edit_set\"], keep=\"last\")\n",
    "\n",
    "# Define a function to calculate standard error\n",
    "def standard_error(x):\n",
    "    return x.std() / np.sqrt(len(x))\n",
    "\n",
    "# Group by the \"tag\" column and calculate the mean for numerical columns\n",
    "grouped_df = latest_runs_df.groupby([\"model_name\", \"tag\"]).agg([\"mean\", standard_error])\n",
    "\n",
    "# Flatten the multi-level columns\n",
    "grouped_df.columns = [f\"{col[0]}_{col[1]}\" for col in grouped_df.columns]\n",
    "\n",
    "# Split the columns into means and standard errors\n",
    "mean_columns = [col for col in grouped_df.columns if col.endswith(\"_mean\")]\n",
    "se_columns = [col for col in grouped_df.columns if col.endswith(\"_standard_error\")]\n",
    "\n",
    "# Create separate DataFrames for means and standard errors\n",
    "mean_df = grouped_df[mean_columns].rename(columns=lambda x: x.replace(\"_mean\", \"\"))\n",
    "se_df = grouped_df[se_columns].rename(columns=lambda x: x.replace(\"_standard_error\", \"_se\"))\n",
    "\n",
    "# Merge the means and standard errors back into one DataFrame\n",
    "all_runs_df_sorted_averaged = pd.concat([mean_df, se_df], axis=1).copy()\n",
    "\n",
    "# Reset index if needed\n",
    "all_runs_df_sorted_averaged.reset_index(inplace=True)\n",
    "\n",
    "# Add non-numerical columns from the latest_runs_df\n",
    "non_numerical_columns = latest_runs_df.select_dtypes(exclude=[np.number]).drop_duplicates(subset=[\"model_name\", \"tag\"])\n",
    "all_runs_df_sorted_averaged = all_runs_df_sorted_averaged.merge(non_numerical_columns, on=[\"model_name\", \"tag\"], how=\"left\")\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "all_runs_df_sorted_averaged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 476/476 [00:00<00:00, 28675.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag            model_name                        \n",
      "AWQ2bit_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ2bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ3bit        mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ3bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ4bit        mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ4bit_FT     mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ4bit_LORA   mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ4bit_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ4bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ5bit_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ5bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ6bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ8bit_MEMIT  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "AWQ8bit_RMU    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "FT             mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "FT_AWQ4bit     mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "FT_RMU         mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "GD             mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "GD_LORA        mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "LORA           mistralai/Mistral-7B-Instruct-v0.3    2\n",
      "LORA_AWQ4bit   mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "LORA_GD        mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "LORA_RMU       mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT          mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT_AWQ3bit  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT_AWQ4bit  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT_AWQ5bit  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT_AWQ6bit  mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "MEMIT_RMU      mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "NONE           mistralai/Mistral-7B-Instruct-v0.3    2\n",
      "RMU            mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ2bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ3bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ4bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ5bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ6bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_AWQ8bit    mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_FT         mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_LORA       mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "RMU_MEMIT      mistralai/Mistral-7B-Instruct-v0.3    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# The experiment tags can be inconsistent, so we need to manually map them to standard names\n",
    "def set_tag(experiment_row):\n",
    "    if experiment_row[\"interventions\"] in [None, np.nan]:\n",
    "        return \"NONE\"\n",
    "\n",
    "    intervention_categories = None\n",
    "    if isinstance(experiment_row[\"interventions\"], str):\n",
    "        intervention_categories = ast.literal_eval(experiment_row[\"interventions\"])\n",
    "    else:\n",
    "        intervention_categories = experiment_row[\"interventions\"]\n",
    "\n",
    "    interventions = []\n",
    "    for category in intervention_categories:\n",
    "        category = \"compression\" if category == \"compress\" else category\n",
    "        intervention = experiment_row[category].upper()\n",
    "        if intervention in [\"AWQ\", \"GPTQ\"]:\n",
    "            intervention += str(int(experiment_row[\"wbits\"])) + \"bit\"\n",
    "        if intervention in [\"WANDA\", \"SPARSEGPT\"]:\n",
    "            intervention += str(int(experiment_row[\"sparsity_ratio\"] * 100)) + \"%\"\n",
    "\n",
    "        interventions.append(intervention)\n",
    "    \n",
    "    if len(interventions) == 0:\n",
    "        interventions.append(\"NONE\")\n",
    "\n",
    "    return \"_\".join(interventions)\n",
    "\n",
    "all_runs_df_sorted_averaged[\"tag\"] = all_runs_df_sorted_averaged.progress_apply(set_tag, axis=1)\n",
    "print(all_runs_df_sorted_averaged[all_runs_df_sorted_averaged[\"model_name\"] == \"mistralai/Mistral-7B-Instruct-v0.3\"].value_counts([\"tag\", \"model_name\"]).sort_index())\n",
    "# print(all_runs_df_sorted_averaged[[\"tag\", \"model_name\"]].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_548918/881733886.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/tmp/ipykernel_548918/881733886.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"model_name\"] = all_runs_df_deduplicated[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m\n\u001b[1;32m      6\u001b[0m rename_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlama-3 (8b)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMistral (7b)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgd\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 22\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mall_runs_df_deduplicated\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43medit\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrename_dict\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     24\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/series.py:4430\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4321\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4322\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4325\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4327\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4328\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4329\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4428\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4429\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4430\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/apply.py:1082\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;66;03m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m-> 1082\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/core/apply.py:1137\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1132\u001b[0m         \u001b[38;5;66;03m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1133\u001b[0m         \u001b[38;5;66;03m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1134\u001b[0m         \u001b[38;5;66;03m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1135\u001b[0m         \u001b[38;5;66;03m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1136\u001b[0m         \u001b[38;5;66;03m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1137\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1138\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1139\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1140\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1144\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      6\u001b[0m rename_dict \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta-llama/Meta-Llama-3-8B\u001b[39m\u001b[38;5;124m\"\u001b[39m : \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLlama-3 (8b)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.3\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMistral (7b)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgd\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGD\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m }\n\u001b[1;32m     21\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 22\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     23\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m     24\u001b[0m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m all_runs_df_deduplicated[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlearn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x : rename_dict\u001b[38;5;241m.\u001b[39mget(x, \u001b[38;5;28;01mNone\u001b[39;00m))\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted_averaged.drop_duplicates(subset=[\"model_name\", \"tag\"], keep=\"first\")\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"mistralai/Mistral-7B-Instruct-v0.3\": \"Mistral (7b)\",\n",
    "    \"microsoft/Phi-3-mini-4k-instruct\": \"Phi-3 (3.8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"LoRA\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "}\n",
    "all_runs_df_deduplicated[\"model_name\"] = all_runs_df_deduplicated[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"edit\"] = all_runs_df_deduplicated[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"compression\"] = all_runs_df_deduplicated[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated[\"unlearn\"] = all_runs_df_deduplicated[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = all_runs_df_deduplicated\n",
    "display(all_runs_df_deduplicated.value_counts([\"model_name\", \"tag\"]).sort_index())\n",
    "print(f\"Number of experiments: {len(all_runs_df_deduplicated)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check for Missing Experments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_df_deduplicated.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mistral Ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlearning_interventions = [\"rmu\"]\n",
    "editing_interventions = [\"memit\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"], \"edit\": editor, \"unlearn\": unlearner, \"wbits\": None, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Unlearning and compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# Editing and compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [], \"edit\": None, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just edit\n",
    "for editor in editing_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"edit\"], \"edit\": editor, \"unlearn\": None, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just unlearn\n",
    "for unlearner in unlearning_interventions:\n",
    "    experiment_combinations.append({\n",
    "        \"interventions\": [\"unlearn\"], \"edit\": None, \"unlearn\": unlearner, \"compression\": None, \"wbits\": None, \"sparsity_ratio\": None })\n",
    "\n",
    "# Just pruning\n",
    "for pruner in pruning_interventions:\n",
    "    for pruning_level in pruning_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": pruner, \"sparsity_ratio\": pruning_level, })\n",
    "\n",
    "# Just quantization\n",
    "for quantizer in quant_interventions:\n",
    "    for quant_level in quant_levels:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"compression\"], \"edit\": None, \"unlearn\": None, \"compression\": quantizer, \"wbits\": quant_level, \"sparsity_ratio\": None, })\n",
    "\n",
    "print(f\"Total experiment combinations for Mistral ablation: {len(experiment_combinations)}\")\n",
    "mistral_tags = set(all_runs_df_deduplicated[all_runs_df_deduplicated[\"model_name\"] == \"Mistral (7b)\"][\"tag\"].unique())\n",
    "experiment_statuses = []\n",
    "for experiment in experiment_combinations:\n",
    "    experiment_tag = set_tag(experiment)\n",
    "    experiment_statuses.append({\n",
    "        \"experiment_tag\": experiment_tag,\n",
    "        \"first_intervention\": experiment_tag.split(\"_\")[0],\n",
    "        \"second_intervention\": experiment_tag.split(\"_\")[1] if len(experiment_tag.split(\"_\")) > 1 else None,\n",
    "        \"completed\": experiment_tag in mistral_tags,\n",
    "    })\n",
    "\n",
    "experiment_statuses_df = pd.DataFrame(experiment_statuses)\n",
    "experiment_statuses_df.to_csv(\"mistral_experiment_statuses.csv\", index=False)\n",
    "\n",
    "# Percent of experiments completed\n",
    "print(f\"Percent of experiments completed: {experiment_statuses_df['completed'].mean() * 100:.2f}%\")\n",
    "\n",
    "# Missing experiments\n",
    "missing_experiments = experiment_statuses_df[experiment_statuses_df[\"completed\"] == False].sort_values(by=\"experiment_tag\")\n",
    "display(missing_experiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Get a second pair of eyes on this this math\n",
    "\n",
    "# Math for determining number of interventions\n",
    "awq_settings = 6\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs_df_deduplicated[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_UNLEARNING = 3\n",
    "NUM_EDITING = 3\n",
    "NUM_COMPRESSION = 4 + 6 + 6 + 6\n",
    "combination_of_unlearning = 2 * NUM_UNLEARNING * NUM_COMPRESSION\n",
    "combination_of_unlearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = all_runs_df_deduplicated\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1, f\"{len(categories['No Intervention'])} != 1\"\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "# assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 ) - 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "assert len(categories[\"Unlearn\"]) == 3, f\"{len(categories['Unlearn'])} != 3\"\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 9, f\"{len(categories['Edit to Unlearn'])} != 9\"\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 9, f\"{len(categories['Unlearn to Edit'])} != 9\"\n",
    "\n",
    "display(categories[\"Compress to Unlearn\"])\n",
    "assert len(categories[\"Compress to Unlearn\"]) == combination_of_unlearning // 2, f\"{len(categories['Compress to Unlearn'])} != {combination_of_unlearning // 2}\"\n",
    "\n",
    "display(categories[\"Unlearn to Compress\"])\n",
    "assert len(categories[\"Unlearn to Compress\"]) == combination_of_unlearning // 2, f\"{len(categories['Unlearn to Compress'])} != {rmucombination_of_unlearning_count // 2}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define intervention names and types\n",
    "intervention_names = [intervention for intervention in list(data[\"edit\"].unique()) + list(data[\"unlearn\"].unique()) + list(data[\"compression\"].unique()) if intervention is not None]\n",
    "intervention_type = {\n",
    "    \"LoRA\": \"edit\",\n",
    "    \"MEMIT\": \"edit\",\n",
    "    \"Fine-tune\": \"edit\",\n",
    "    \"SparseGPT\": \"compression\",\n",
    "    \"Wanda\": \"compression\",\n",
    "    \"GPTQ\": \"compression\",\n",
    "    \"AWQ\": \"compression\",\n",
    "    \"RMU\": \"unlearn\",\n",
    "    \"GA\": \"unlearn\",\n",
    "    \"GD\": \"unlearn\",\n",
    "}\n",
    "\n",
    "# Initialize heatmap data frames with default values\n",
    "default_value = None\n",
    "mmlu_oi_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_oi_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_oi_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_oi_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_oi_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Initialize max value data frames\n",
    "mmlu_mce_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_mce_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "edit_mce_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "generalization_mce_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "locality_mce_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "\n",
    "# Populate the heatmap and max value data frames\n",
    "for first_intervention in intervention_names:\n",
    "    for second_intervention in intervention_names:\n",
    "        first_intervention_type = intervention_type[first_intervention]\n",
    "        second_intervention_type = intervention_type[second_intervention]\n",
    "        if first_intervention_type == second_intervention_type:\n",
    "            continue\n",
    "\n",
    "        compositions = data[(data[first_intervention_type] == first_intervention) & (data[second_intervention_type] == second_intervention)]\n",
    "        if first_intervention in [\"SparseGPT\", \"Wanda\"] or second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "            compositions = compositions[compositions[\"sparsity_ratio\"] == 0.25]\n",
    "        elif first_intervention in [\"GPTQ\", \"AWQ\"] or second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "            compositions = compositions[compositions[\"wbits\"] == 4]\n",
    "        \n",
    "        assert len(compositions) == 2, f\"Expected 2 compositions for {first_intervention} and {second_intervention}, but found {len(compositions)}\"\n",
    "        \n",
    "        # Calculate OIs\n",
    "        mmlu_diff = abs(compositions[\"mmlu accuracy\"].iloc[0] - compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_oi_data[first_intervention][second_intervention] = mmlu_diff\n",
    "        \n",
    "        avg_wmdp_diff = abs(((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2) - ((compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2)).round(4)\n",
    "        wmdp_oi_data[first_intervention][second_intervention] = avg_wmdp_diff\n",
    "        \n",
    "        edit_diff = abs(compositions[\"Rewrite accuracy\"].iloc[0] - compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_oi_data[first_intervention][second_intervention] = edit_diff\n",
    "\n",
    "        generalization_diff = abs(compositions[\"Generalization\"].iloc[0] - compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_oi_data[first_intervention][second_intervention] = generalization_diff\n",
    "\n",
    "        locality_diff = abs(compositions[\"Locality\"].iloc[0] - compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_oi_data[first_intervention][second_intervention] = locality_diff\n",
    "        \n",
    "        # Calculate MCE values\n",
    "        mmlu_mce = 1 - max(compositions[\"mmlu accuracy\"].iloc[0], compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_mce_data[first_intervention][second_intervention] = mmlu_mce\n",
    "        \n",
    "        avg_wmdp_acc = min((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2, (compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2).round(4)\n",
    "        wmdp_mce_data[first_intervention][second_intervention] = avg_wmdp_acc\n",
    "        \n",
    "        edit_mce = 1 - max(compositions[\"Rewrite accuracy\"].iloc[0], compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        edit_mce_data[first_intervention][second_intervention] = edit_mce\n",
    "\n",
    "        generalization_mce = 1 - max(compositions[\"Generalization\"].iloc[0], compositions[\"Generalization\"].iloc[1]).round(4)\n",
    "        generalization_mce_data[first_intervention][second_intervention] = generalization_mce\n",
    "\n",
    "        locality_mce = 1 - max(compositions[\"Locality\"].iloc[0], compositions[\"Locality\"].iloc[1]).round(4)\n",
    "        locality_mce_data[first_intervention][second_intervention] = locality_mce\n",
    "\n",
    "# Display the results\n",
    "print(\"MMLU OI\")\n",
    "display(mmlu_oi_data)\n",
    "\n",
    "print(\"MMLU MCE Values\")\n",
    "display(mmlu_mce_data)\n",
    "\n",
    "print(\"WMDP OI\")\n",
    "display(wmdp_oi_data)\n",
    "\n",
    "print(\"WMDP MCE Values\")\n",
    "display(wmdp_mce_data)\n",
    "\n",
    "print(\"Rewrite OI\")\n",
    "display(edit_oi_data)\n",
    "\n",
    "print(\"Rewrite MCE Values\")\n",
    "display(edit_mce_data)\n",
    "\n",
    "print(\"Generalization OI\")\n",
    "display(generalization_oi_data)\n",
    "\n",
    "print(\"Generalization MCE Values\")\n",
    "display(generalization_mce_data)\n",
    "\n",
    "print(\"Locality OI\")\n",
    "display(locality_oi_data)\n",
    "\n",
    "print(\"Locality MCE Values\")\n",
    "display(locality_mce_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_order = [\"Wanda\", \"SparseGPT\", \"AWQ\", \"GPTQ\"]\n",
    "editor_order = [\"Fine-tune\", \"MEMIT\", \"LoRA\"]\n",
    "unlearn_order = [\"GA\", \"GD\", \"RMU\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_value(value):\n",
    "    if pd.isnull(value):\n",
    "        return ''\n",
    "    elif value > .995:\n",
    "        return '1'\n",
    "    else:\n",
    "        return f'{value:.2f}'[1:] if value < 1 else f'{value:.2f}'\n",
    "\n",
    "def latex_bold_if_min(value: str, max_value: float):\n",
    "    return f'\\\\textbf{{{value}}}' if value == format_value(min_value) else value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ Compression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13} \\cmidrule(lr){14-19}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13} \\cmidrule(lr){14-16} \\cmidrule(lr){17-19}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-19}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = f\"        {compressor}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc(\n",
    "    edit_mce_data,\n",
    "    edit_oi_data,\n",
    "    generalization_mce_data,\n",
    "    generalization_oi_data,\n",
    "    mmlu_mce_data,\n",
    "    mmlu_oi_data,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Row Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc_edit_only(edit_mce_df, edit_oi_df, gen_mce_df, gen_oi_df, edit_interventions, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(edit_mce_df, edit_oi_df), (gen_mce_df, gen_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_edit_only(\n",
    "    edit_mce_data,\n",
    "    edit_oi_data,\n",
    "    generalization_mce_data,\n",
    "    generalization_oi_data,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second Row: Locality & MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_locality_and_mmlu(locality_mce_df, locality_oi_df, mmlu_mce_df, mmlu_oi_df, edit_interventions, mmlu_interventions):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{Locality}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(locality_mce_df, locality_oi_df), (mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "\n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "    \n",
    "    print(latex_code)\n",
    "\n",
    "generate_latex_table_ke_locality_and_mmlu(\n",
    "    locality_mce_data,\n",
    "    locality_oi_data,\n",
    "    mmlu_mce_data,\n",
    "    mmlu_oi_data,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Row: MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mc_mmlu_only(mmlu_mce_df, mmlu_oi_df, editor_order, compression_order):\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-7}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(mmlu_mce_df, mmlu_oi_df)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][compressor])}\"\n",
    "                    row_values.append(sub_metric[editor][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mc_mmlu_only(\n",
    "    mmlu_mce_data,\n",
    "    mmlu_oi_data,\n",
    "    editor_order,\n",
    "    compression_order,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MU ←→ MC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_mu_mc():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} & \\textbf{GA} & \\textbf{GD} & \\textbf{RMU} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for compressor in compression_order:\n",
    "        if compressor == \"AWQ\":\n",
    "            latex_code += r\"        \\cdashlinelr{1-13}\" + \"\\n\"\n",
    "\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + compressor + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_data, wmdp_oi_data), (mmlu_mce_data, mmlu_oi_data)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for unlearner in unlearn_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[unlearner][compressor])}\"\n",
    "                    row_values.append(sub_metric[unlearner][compressor])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_mu_mc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First Row: KE Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_table_ke_mu_ke_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        \\toprule\n",
    "        & \\multicolumn{6}{c}{\\textbf{Edit Success}} & \\multicolumn{6}{c}{\\textbf{Generalization}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(edit_mce_data, edit_oi_data), (generalization_mce_data, generalization_oi_data)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "    \n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_ke_metrics()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second Row: MU Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have WMDP and MMLU in the same table\n",
    "def generate_latex_table_ke_mu_mu_metrics():\n",
    "    latex_code = r\"\"\"\n",
    "    \\begin{tabular}{lcccccccccccc}\n",
    "        & \\multicolumn{6}{c}{\\textbf{WMDP}} & \\multicolumn{6}{c}{\\textbf{MMLU}} \\\\\n",
    "        \\cmidrule(lr){2-7} \\cmidrule(lr){8-13}\n",
    "        & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{MCE ($\\downarrow$)}} & \\multicolumn{3}{c}{\\textbf{OI ($\\downarrow$)}} \\\\\n",
    "        \\cmidrule(lr){2-4} \\cmidrule(lr){5-7} \\cmidrule(lr){8-10} \\cmidrule(lr){11-13}\n",
    "        \\textbf{Method} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} & \\textbf{FT} & \\textbf{MEMIT} & \\textbf{LoRA} \\\\\n",
    "        \\midrule\n",
    "\"\"\"\n",
    "    table_values = []\n",
    "\n",
    "    for unlearner in unlearn_order:\n",
    "        row_values = []\n",
    "        table_row = r\"        \\textbf{\" + unlearner + \"}\"\n",
    "        for metrics_category in [(wmdp_mce_data, wmdp_oi_data), (mmlu_mce_data, mmlu_oi_data)]:\n",
    "            for sub_metric in metrics_category:\n",
    "                for editor in editor_order:\n",
    "                    table_row += f\" & {format_value(sub_metric[editor][unlearner])}\"\n",
    "                    row_values.append(sub_metric[editor][unlearner])\n",
    "        \n",
    "        table_row += r\" \\\\\"\n",
    "        latex_code += table_row + \"\\n\"\n",
    "        table_values.append(row_values)\n",
    "    \n",
    "    latex_code += r\"        \\midrule\" + \"\\n\"\n",
    "    avg_row = r\"        \\textit{Average}\"\n",
    "    for col_avg in np.array(table_values).mean(0).tolist():\n",
    "        avg_row += f\" & {format_value(col_avg)}\"\n",
    "\n",
    "    latex_code += avg_row + r\" \\\\\" + \"\\n\"\n",
    "    latex_code += r'''        \\bottomrule \\\\\n",
    "    \\end{tabular}\n",
    "'''\n",
    "\n",
    "    print(latex_code)\n",
    "\n",
    "\n",
    "generate_latex_table_ke_mu_mu_metrics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Detailed Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- None    : Done\n",
    "- KE ←→ MC: Done\n",
    "- MC ←→ KE: Done\n",
    "- KE ←→ MU: Todo\n",
    "- MU ←→ KE: Todo\n",
    "- MU ←→ MC: Todo\n",
    "- MC ←→ MU: Todo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "technique_formatting_map = {\n",
    "    \"awq\": \"AWQ\",\n",
    "    \"gptq\": \"GPTQ\",\n",
    "    \"sparsegpt\": \"SparseGPT\",\n",
    "    \"wanda\": \"Wanda\",\n",
    "    \"ft\": \"FT\",\n",
    "    \"memit\": \"MEMIT\",\n",
    "    \"lora\": \"LoRA\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "    \"rmu\": \"RMU\",\n",
    "}\n",
    "appendix_compositions_order = [\n",
    "    [],\n",
    "    [\"compress\"],\n",
    "    [\"edit\"],\n",
    "    [\"edit\", \"compress\"],\n",
    "    [\"compress\", \"edit\"],\n",
    "    [\"unlearn\"],\n",
    "    [\"unlearn\", \"compress\"],\n",
    "    [\"compress\", \"unlearn\"],\n",
    "    [\"edit\", \"unlearn\"],\n",
    "    [\"unlearn\", \"edit\"],\n",
    "]\n",
    "appendix_table_columns_map = {\n",
    "    \"tag\": \"Composition\",\n",
    "    \"Rewrite accuracy\": \"Edit Success\",\n",
    "    \"Generalization\": \"Generalization\",\n",
    "    \"Locality\": \"Locality\",\n",
    "    \"Average bits\": \"Avg. Bits\",\n",
    "    \"Avg WMDP\": \"Avg. WMDP\",\n",
    "    \"mmlu accuracy\": \"MMLU\",\n",
    "    \"PPL\": \"WikiText PPL\",\n",
    "}\n",
    "appendix_technique_ordering = {\n",
    "    \"edit\": [\"Fine-tune\", \"MEMIT\", \"LoRA\"],\n",
    "    \"compress\": [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"],\n",
    "    \"unlearn\": [\"GA\", \"GD\", \"RMU\"],\n",
    "}\n",
    "\n",
    "\n",
    "def get_composition_label(row):\n",
    "    composition = row[\"interventions\"]\n",
    "    if composition == []:\n",
    "        return \"None\"\n",
    "    \n",
    "    first_intervention_type = composition[0] if composition[0] != \"compress\" else \"compression\"\n",
    "    first_intervention = technique_formatting_map[row[first_intervention_type]]\n",
    "    if first_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        first_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif first_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        first_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    if len(composition) == 1:\n",
    "        return first_intervention\n",
    "    \n",
    "    second_intervention_type = composition[1] if composition[1] != \"compress\" else \"compression\"\n",
    "    second_intervention = technique_formatting_map[row[second_intervention_type]]\n",
    "    if second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "        second_intervention += \" \" + str(row[\"sparsity_ratio\"])\n",
    "    elif second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "        second_intervention += \" (\" + str(int(row[\"wbits\"])) + \"bit) \"\n",
    "    \n",
    "    return first_intervention + r\"$\\rightarrow$\" + second_intervention\n",
    "\n",
    "\n",
    "appendix_results = all_runs_df_sorted_averaged.copy()\n",
    "appendix_results[\"interventions\"] = appendix_results[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "appendix_results[\"Label\"] = appendix_results.apply(get_composition_label, axis=1)\n",
    "appendix_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "appendix_results.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: Single Intervention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(appendix_table_columns_map.keys())[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# None\n",
    "appendix_no_compositons = appendix_results[appendix_results[\"interventions\"].apply(lambda x: len(x) == 0)]\n",
    "latex_code += r\"   {None}\"\n",
    "for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "    latex_code += f\" & {appendix_no_compositons[col].mean():.2f}\"\n",
    "\n",
    "latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Edit Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_edit_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    appendix_edit_only_technique = appendix_edit_only[appendix_edit_only[\"edit\"] == formatted_edit_technique.lower()]\n",
    "    assert len(appendix_edit_only_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    technique_row_label = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\"& {round(appendix_edit_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Compress Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_compress_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    formatted_compress_technique = compress_technique\n",
    "    appendix_compress_only_technique = appendix_compress_only[appendix_compress_only[\"compression\"] == formatted_compress_technique.lower()]\n",
    "    assert len(appendix_compress_only_technique) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(appendix_compress_only_technique[compression_strength_column].unique())\n",
    "    for compression_strength in compression_strength_ordering:\n",
    "        technique_row_label = compress_technique\n",
    "        current_compression = appendix_compress_only_technique[appendix_compress_only_technique[compression_strength_column] == compression_strength]\n",
    "        if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "            technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "        elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "            technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "        \n",
    "        latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "        \n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# Unlearn Only\n",
    "latex_code += r\"    \\cdashlinelr{1-9}\" + \"\\n\"\n",
    "\n",
    "appendix_unlearn_only = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    formatted_unlearn_technique = unlearn_technique\n",
    "    appendix_unlearn_only_technique = appendix_unlearn_only[appendix_unlearn_only[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "    assert len(appendix_unlearn_only_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    technique_row_label = unlearn_technique\n",
    "    latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow$None\"\n",
    "    for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "        latex_code += f\" & {round(appendix_unlearn_only_technique[col].mean(), 2)}\"\n",
    "    \n",
    "    latex_code += r\" \\\\\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_edit_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    appendix_edit_compress_edit_technique = appendix_edit_compress[appendix_edit_compress[\"edit\"] == formatted_edit_technique.lower()]\n",
    "    assert len(appendix_edit_compress_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        formatted_compress_technique = compress_technique\n",
    "        appendix_edit_compress_technique_frame = appendix_edit_compress_edit_technique[appendix_edit_compress_edit_technique[\"compression\"] == formatted_compress_technique.lower()]\n",
    "        assert len(appendix_edit_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_edit_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_edit_compress_technique_frame[appendix_edit_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Editing -> Compression\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_edit_technique_frame = appendix_compress_edit[appendix_compress_edit[\"compression\"] == compress_technique.lower()]\n",
    "    assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_edit_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "    print(f\"Technique: {compress_technique}, Strengths: {compression_strength_ordering}\")\n",
    "\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "        appendix_compress_edit_edit_technique = appendix_compress_edit_technique_frame[appendix_compress_edit_technique_frame[\"edit\"] == formatted_edit_technique.lower()]\n",
    "        assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_edit_edit_technique[round(appendix_compress_edit_edit_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: MU ←→ MC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Compression\n",
    "appendix_unlearn_compress = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    formatted_unlearn_technique = unlearn_technique\n",
    "    appendix_unlearn_compress_unlearn_technique = appendix_unlearn_compress[appendix_unlearn_compress[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "    assert len(appendix_unlearn_compress_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "        formatted_compress_technique = compress_technique\n",
    "        appendix_unlearn_compress_technique_frame = appendix_unlearn_compress_unlearn_technique[appendix_unlearn_compress_unlearn_technique[\"compression\"] == formatted_compress_technique.lower()]\n",
    "        assert len(appendix_unlearn_compress_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "        compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "        compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_unlearn_compress_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_unlearn_compress_technique_frame[appendix_unlearn_compress_technique_frame[compression_strength_column] == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(current_compression[\"sparsity_ratio\"].iloc[0]) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(current_compression[\"wbits\"].iloc[0])) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{technique_row_label}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compression First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Compression -> Unlearn\n",
    "appendix_compress_unlearn = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])]\n",
    "for compress_technique in appendix_technique_ordering[\"compress\"]:\n",
    "    appendix_compress_unlearn_technique_frame = appendix_compress_unlearn[appendix_compress_unlearn[\"compression\"] == compress_technique.lower()]\n",
    "    assert len(appendix_compress_unlearn_technique_frame) > 0, f\"No data found for {compress_technique}\"\n",
    "\n",
    "    compression_strength_column = \"sparsity_ratio\" if compress_technique in [\"SparseGPT\", \"Wanda\"] else \"wbits\"\n",
    "    compression_strength_ordering = sorted(set([round(strength, 2) for strength in appendix_compress_unlearn_technique_frame[compression_strength_column] if strength not in [0, 16]]))\n",
    "\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_unlearn_unlearn_technique = appendix_compress_unlearn_technique_frame[appendix_compress_unlearn_technique_frame[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_unlearn_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "        \n",
    "        for compression_strength in compression_strength_ordering:\n",
    "            technique_row_label = compress_technique\n",
    "            current_compression = appendix_compress_unlearn_unlearn_technique[round(appendix_compress_unlearn_unlearn_technique[compression_strength_column], 2) == compression_strength]\n",
    "            if compress_technique in [\"SparseGPT\", \"Wanda\"]:\n",
    "                technique_row_label += \" (\" + str(compression_strength) + \") \"\n",
    "            elif compress_technique in [\"GPTQ\", \"AWQ\"]:\n",
    "                technique_row_label += \" (\" + str(int(compression_strength)) + \"-Bit) \"\n",
    "            \n",
    "            latex_code += f\"    {{{technique_row_label}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "            for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "                assert len(current_compression) == 1, f\"Multiple rows found for {compress_technique} -> {unlearn_technique} -> {compression_strength}\"\n",
    "                latex_code += f\" & {round(current_compression[col].mean(), 2)}\"\n",
    "            \n",
    "            latex_code += r\" \\\\\" + \"\\n\"\n",
    "    \n",
    "    if compress_technique != appendix_technique_ordering[\"compress\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "    \n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appendix Table: KE ←→ MU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Edit First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Edit -> Unlearn\n",
    "appendix_compress_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])]\n",
    "for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "    formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "    appendix_compress_edit_edit_technique = appendix_compress_edit[appendix_compress_edit[\"edit\"] == formatted_edit_technique.lower()]\n",
    "    assert len(appendix_compress_edit_edit_technique) > 0, f\"No data found for {edit_technique}\"\n",
    "    for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "        formatted_unlearn_technique = unlearn_technique\n",
    "        appendix_compress_edit_technique_frame = appendix_compress_edit_edit_technique[appendix_compress_edit_edit_technique[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "        assert len(appendix_compress_edit_technique_frame) > 0, f\"No data found for {unlearn_technique}\"\n",
    "\n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = edit_technique\n",
    "        latex_code += f\"    {{{formatted_edit_technique}}}$\\\\rightarrow${{{formatted_unlearn_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_compress_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if edit_technique != appendix_technique_ordering[\"edit\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unlearn First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex_code = r\"\"\"\n",
    "\\begin{tabular}{lcccccccc}\n",
    "    \\toprule\n",
    "    & \\multicolumn{3}{c}{Editing} & \\multicolumn{1}{c}{Compression} & \\multicolumn{1}{c}{Unlearning} & \\multicolumn{2}{c}{Utility} \\\\\n",
    "    \\cmidrule(lr){2-4} \\cmidrule(lr){5-5} \\cmidrule(lr){6-6} \\cmidrule(lr){7-8}\n",
    "    & Edit Success & Generalization & Locality & Avg. Bits & Avg. WMDP & MMLU & WikiText PPL \\\\\n",
    "    \\midrule\n",
    "\"\"\"\n",
    "\n",
    "# Unlearn -> Edit\n",
    "appendix_unlearn_edit = appendix_results[appendix_results[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])]\n",
    "for unlearn_technique in appendix_technique_ordering[\"unlearn\"]:\n",
    "    formatted_unlearn_technique = unlearn_technique\n",
    "    appendix_unlearn_edit_unlearn_technique = appendix_unlearn_edit[appendix_unlearn_edit[\"unlearn\"] == formatted_unlearn_technique.lower()]\n",
    "    assert len(appendix_unlearn_edit_unlearn_technique) > 0, f\"No data found for {unlearn_technique}\"\n",
    "    for edit_technique in appendix_technique_ordering[\"edit\"]:\n",
    "        formatted_edit_technique = \"FT\" if edit_technique == \"Fine-tune\" else edit_technique\n",
    "        appendix_unlearn_edit_technique_frame = appendix_unlearn_edit_unlearn_technique[appendix_unlearn_edit_unlearn_technique[\"edit\"] == formatted_edit_technique.lower()]\n",
    "        assert len(appendix_unlearn_edit_technique_frame) > 0, f\"No data found for {edit_technique}\"\n",
    "        \n",
    "        # No compression strength for this composition\n",
    "        technique_row_label = unlearn_technique\n",
    "        latex_code += f\"    {{{formatted_unlearn_technique}}}$\\\\rightarrow${{{formatted_edit_technique}}}\"\n",
    "        for col in list(appendix_table_columns_map.keys())[1:]:\n",
    "            latex_code += f\" & {round(appendix_unlearn_edit_technique_frame[col].mean(), 2)}\"\n",
    "\n",
    "        latex_code += r\" \\\\\" + \"\\n\"\n",
    "        \n",
    "    if unlearn_technique != appendix_technique_ordering[\"unlearn\"][-1]:\n",
    "        latex_code += r\"    \\cdashlinelr{1-8}\" + \"\\n\"\n",
    "\n",
    "# end of table\n",
    "latex_code += r\"    \\bottomrule \\\\\" + \"\\n\"\n",
    "latex_code += r\"\\end{tabular}\"\n",
    "\n",
    "# Pring the table\n",
    "print(latex_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_label(row):\n",
    "    interventions = row[\"interventions\"]\n",
    "    first_method = \"\"\n",
    "    second_method = \"\"\n",
    "    if interventions[0] == \"edit\":\n",
    "        first_method = row[\"edit\"]\n",
    "    elif interventions[0] == \"compress\":\n",
    "        first_method = row[\"compression\"]\n",
    "    elif interventions[0] == \"unlearn\":\n",
    "        first_method = row[\"unlearn\"]\n",
    "    \n",
    "    if interventions[1] == \"edit\":\n",
    "        second_method = row[\"edit\"]\n",
    "    elif interventions[1] == \"compress\":\n",
    "        second_method = row[\"compression\"]\n",
    "    elif interventions[1] == \"unlearn\":\n",
    "        second_method = row[\"unlearn\"]\n",
    "    \n",
    "    return f\"{first_method}→{second_method}\"\n",
    "\n",
    "def wrap_label(interventions):\n",
    "    first_intervention, second_intervention = interventions[0], interventions[1]\n",
    "    first_letter_upper = first_intervention[0].upper()\n",
    "    second_letter_upper = second_intervention[0].upper()\n",
    "    \n",
    "    # EX: E $\\rightarrow$ C\n",
    "    return f\"{first_letter_upper}$\\\\rightarrow${second_letter_upper}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock records for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want instances where editing has been applied but there is no unlearning or compression. In these cases, set wbits=16 and sparsity=0 \n",
    "baseline_editors = data[(data[\"edit\"].notnull()) & (data[\"unlearn\"].isnull()) & (data[\"compression\"].isnull()) & (data[\"interventions\"].apply(lambda x: x == [\"edit\"]))].copy()\n",
    "baseline_editors[\"wbits\"] = 16\n",
    "baseline_editors[\"sparsity_ratio\"] = 0\n",
    "news_records = []\n",
    "\n",
    "# Edit and Compress\n",
    "for editing_method in [\"LoRA\", \"MEMIT\", \"Fine-tune\"]:\n",
    "    baseline_record = baseline_editors[baseline_editors[\"edit\"] == editing_method]\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        edit_first_record = baseline_record.copy()\n",
    "        edit_first_record[\"compression\"] = compression_method\n",
    "        edit_first_record[\"interventions\"] = [[\"edit\", \"compress\"]]\n",
    "        edit_first_record[\"sparsity_ratio\"] = 0\n",
    "        edit_first_record[\"wbits\"] = 16\n",
    "        news_records.append(edit_first_record)\n",
    "\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"edit\"]]\n",
    "        compress_first_record[\"sparsity_ratio\"] = 0\n",
    "        compress_first_record[\"wbits\"] = 16\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "baseline_unlearners = data[(data[\"edit\"].isnull()) & (data[\"unlearn\"].notnull()) & (data[\"compression\"].isnull()) & (data[\"interventions\"].apply(lambda x: x == [\"unlearn\"]))].copy()\n",
    "\n",
    "# Compress and Unlearn\n",
    "for unlearn_method in [\"RMU\", \"GA\", \"GD\"]:\n",
    "    baseline_record = baseline_unlearners[baseline_unlearners[\"unlearn\"] == unlearn_method]\n",
    "\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"unlearn\"] = unlearn_method\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"unlearn\"]]\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "        unlearn_first_record = baseline_record.copy()\n",
    "        unlearn_first_record[\"unlearn\"] = unlearn_method\n",
    "        unlearn_first_record[\"compression\"] = compression_method\n",
    "        unlearn_first_record[\"interventions\"] = [[\"unlearn\", \"compress\"]]\n",
    "        news_records.append(unlearn_first_record)\n",
    "\n",
    "baseline_records = pd.concat(news_records)\n",
    "data = pd.concat([data, baseline_records])\n",
    "baseline_records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Editing and Compresion Single Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: KE ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "\n",
    "row_metrics = {\n",
    "    0: \"Rewrite accuracy\",\n",
    "    1: \"Generalization\",\n",
    "    2: \"Locality\",\n",
    "    3: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    0: r\"Edit Success$ \\uparrow$\",\n",
    "    1: r\"Generalization$ \\uparrow$\",\n",
    "    2: r\"Locality$ \\uparrow$\",\n",
    "    3: r\"MMLU$ \\uparrow$\"\n",
    "}\n",
    "column_edit_methods = {\n",
    "    0: \"MEMIT\",\n",
    "    1: \"LoRA\",\n",
    "    2: \"Fine-tune\",\n",
    "    3: \"MEMIT\",\n",
    "    4: \"LoRA\",\n",
    "    5: \"Fine-tune\"\n",
    "}\n",
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}\n",
    "final_row_index = len(row_labels) - 1\n",
    "\n",
    "fig, axes = plt.subplots(len(row_labels), 6, figsize=(6 * FIG_SIZE, len(row_labels) * FIG_SIZE))\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"edit\"] == column_edit_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"MEMIT\", \"LoRA\", \"Fine-tune\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index != final_row_index:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        else:\n",
    "            ax.set_ylim(0.2, 0.65)\n",
    "            ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "        if y_metric == \"Locality\":\n",
    "            ax.set_ylim(0, .2)\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_edit_methods[col_index] if column_edit_methods[col_index] != \"Fine-tune\" else \"FT\"\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[row_index], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == len(row_labels) - 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == final_row_index:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_editors_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Unlearning ←→ Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "pruning_frame[\"unlearn\"] = pruning_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "quantization_frame[\"unlearn\"] = quantization_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(2, 6, figsize=(6 * FIG_SIZE, 2 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    \"Avg WMDP\": r\"WMDP $\\downarrow$\",\n",
    "    \"mmlu accuracy\": r\"MMLU $\\uparrow$\"\n",
    "}\n",
    "row_label_map = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\"\n",
    "}\n",
    "column_unlearn_methods = {\n",
    "    0: \"GA\",\n",
    "    1: \"GD\",\n",
    "    2: \"RMU\",\n",
    "    3: \"GA\",\n",
    "    4: \"GD\",\n",
    "    5: \"RMU\",\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    \n",
    "    # GA and WANDA + SparseGPT\n",
    "    0: [(\"GA→SparseGPT\", \"SparseGPT→GA\"), (\"GA→Wanda\", \"Wanda→GA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    1: [(\"GD→SparseGPT\", \"SparseGPT→GD\"), (\"GD→Wanda\", \"Wanda→GD\")],\n",
    "    # RMU and WANDA + SparseGPT\n",
    "    2: [(\"RMU→SparseGPT\", \"SparseGPT→RMU\"), (\"RMU→Wanda\", \"Wanda→RMU\")],\n",
    "    # GA and GPTQ + AWQ\n",
    "    3: [(\"GA→GPTQ\", \"GPTQ→GA\"), (\"GA→AWQ\", \"AWQ→GA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    4: [(\"GD→GPTQ\", \"GPTQ→GD\"), (\"GD→AWQ\", \"AWQ→GD\")],\n",
    "    # RMU and GPTQ + AWQ\n",
    "    5: [(\"RMU→GPTQ\", \"GPTQ→RMU\"), (\"RMU→AWQ\", \"AWQ→RMU\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"unlearn\"] == column_unlearn_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"RMU\", \"GA\", \"GD\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "        ax.set_ylim(0.20, 0.65)\n",
    "\n",
    "        if x_metric == \"wbits\":\n",
    "            ax.set_xscale(\"log\", base=2)\n",
    "            ax.set_xticks([2, 4, 8, 16], [\"2\", \"4\", \"8\", \"16\"])\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_unlearn_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[list(row_labels.keys())[row_index]], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_unlearn_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
