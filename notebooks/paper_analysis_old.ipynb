{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull and Dedup Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    # \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  47%|████▋     | 2101/4471 [00:11<00:11, 206.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run evuxnltk: '_timestamp'\n",
      "Error processing run mje2wvj7: '_timestamp'\n",
      "Error processing run um0dxn3y: '_timestamp'\n",
      "Error processing run isna6rgu: '_timestamp'\n",
      "Error processing run luhstpn5: '_timestamp'\n",
      "Error processing run lrh5z3wp: '_timestamp'\n",
      "Error processing run 2do500pc: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions:  48%|████▊     | 2151/4471 [00:11<00:11, 206.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run 71jdht68: '_timestamp'\n",
      "Error processing run 64ed5z4t: '_timestamp'\n",
      "Error processing run 1wj0u6cj: '_timestamp'\n",
      "Error processing run cc3cmdlj: '_timestamp'\n",
      "Error processing run 7t3n8sq1: '_timestamp'\n",
      "Error processing run o1ai36xl: '_timestamp'\n",
      "Error processing run 31j4yjsr: '_timestamp'\n",
      "Error processing run 2nv88i8v: '_timestamp'\n",
      "Error processing run sdhehb2z: '_timestamp'\n",
      "Error processing run r6kpsu09: '_timestamp'\n",
      "Error processing run arid375k: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|█████████▉| 4451/4471 [00:26<00:00, 167.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing run n0iel6ok: '_timestamp'\n",
      "Error processing run xr5mede5: '_timestamp'\n",
      "Error processing run 27f8pxs0: '_timestamp'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dri-ice/Composable_Interventions: 100%|██████████| 4471/4471 [00:26<00:00, 171.12it/s]\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/2829184290.py:38: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n"
     ]
    }
   ],
   "source": [
    "# Composable_Interventions has all the results\n",
    "project_paths = [\n",
    "    'dri-ice/Composable_Interventions',\n",
    "    # 'dri-ice/AK_Tests'\n",
    "]\n",
    "\n",
    "filter_dict = { \"state\": \"finished\" }\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the c        onfig and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-07-30 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing run {run.id}: {e}\")\n",
    "\n",
    "# Sort by 'tag' and '_timestamp' in descending order to have the most recent run first\n",
    "all_runs_df = pd.concat(data_frames, ignore_index=True)[relevant_columns]\n",
    "all_runs_df[\"interventions\"] = all_runs_df[\"interventions\"].astype(str)\n",
    "\n",
    "# WARNING: WHAT DOES EDIT SET 50 MEAN COMPARED TO EDIT SET 1?\n",
    "# all_runs_df = all_runs_df[all_runs_df[\"edit_set\"] == 50]\n",
    "# all_runs_df_sorted = all_runs_df.sort_values(by=['tag', '_timestamp'], ascending=[True, False])\n",
    "all_runs_df[\"date\"] = pd.to_datetime(all_runs_df[\"_timestamp\"], unit='s')\n",
    "all_runs_df_sorted = all_runs_df.sort_values(by=['_timestamp'], ascending=[False])\n",
    "all_runs_df_sorted = all_runs_df_sorted[all_runs_df_sorted[\"qa_question_count_limit\"].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unlearn\n",
       "none    2434\n",
       "rmu      577\n",
       "ga       249\n",
       "gd       190\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_sorted[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Ensure that rmu_layer_id is 3. This was originaly set to 5, but decided to rerun the evals last minute with a better hyperparameter.\n",
    "# Use older RMU experiments\n",
    "# all_runs_df_sorted = all_runs_df_sorted[all_runs_df_sorted[\"rmu_layer_id\"] != 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/923748476.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/923748476.py:20: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/923748476.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/923748476.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
      "/var/folders/_m/m_v8tmqs05lf3_0frmhh2tkc0000gn/T/ipykernel_45663/923748476.py:23: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tag\n",
       "AWQ2bit-to-ft             1\n",
       "lora-to-AWQ8bit           1\n",
       "lora-to-SparseGPT0.45%    1\n",
       "lora-to-SparseGPT0.35%    1\n",
       "lora-to-SparseGPT0.25%    1\n",
       "                         ..\n",
       "awq6bit-rmu               1\n",
       "awq6bit-gd                1\n",
       "awq6bit-ga                1\n",
       "awq5bit-rmu               1\n",
       "wanda0.75\\%-rmu           1\n",
       "Name: count, Length: 311, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of experiments: 311\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicates, keeping only the first occurrence (which is the most recent due to sorting)\n",
    "# all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=[col for col in setting_columns if col not in [\"_timestamp\", \"tag\", \"date\"]], keep=\"first\")\n",
    "all_runs_df_deduplicated = all_runs_df_sorted.drop_duplicates(subset=\"tag\", keep=\"first\")\n",
    "all_runs_df_deduplicated[\"interventions\"] = all_runs_df_deduplicated[\"interventions\"].apply(lambda x : ast.literal_eval(x))\n",
    "\n",
    "rename_dict = {\n",
    "    \"meta-llama/Meta-Llama-3-8B\" : \"Llama-3 (8b)\",\n",
    "    \"ft\" : \"Fine-tune\",\n",
    "    \"memit\" : \"MEMIT\",\n",
    "    \"lora\" : \"LoRA\",\n",
    "    \"wanda\" : \"Wanda\",\n",
    "    \"sparsegpt\" : \"SparseGPT\",\n",
    "    \"gptq\" : \"GPTQ\",\n",
    "    \"awq\" : \"AWQ\",\n",
    "    \"rmu\" : \"RMU\",\n",
    "    \"ga\": \"GA\",\n",
    "    \"gd\": \"GD\",\n",
    "}\n",
    "metrics = all_runs_df_deduplicated\n",
    "metrics[\"model_name\"] = metrics[\"model_name\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"edit\"] = metrics[\"edit\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"compression\"] = metrics[\"compression\"].apply(lambda x : rename_dict.get(x, None))\n",
    "metrics[\"unlearn\"] = metrics[\"unlearn\"].apply(lambda x : rename_dict.get(x, None))\n",
    "all_runs_df_deduplicated = metrics\n",
    "display(all_runs_df_deduplicated.value_counts(\"tag\"))\n",
    "print(f\"Number of experiments: {len(all_runs_df_deduplicated)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "69\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get a second pair of eyes on this this math\n",
    "\n",
    "# Math for determining number of interventions\n",
    "awq_settings = 6\n",
    "gptq_settings = 4 # only support quantize to [2, 3, 4, 8] bits.\n",
    "wanda_count = 6\n",
    "sparsegpt_count = 6\n",
    "editor_settings = 3\n",
    "composition_factor = 2\n",
    "\n",
    "editor_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + 1) * editor_settings\n",
    "print(editor_count // 2)\n",
    "\n",
    "rmu_count = composition_factor * (awq_settings + gptq_settings + wanda_count + sparsegpt_count + editor_settings)\n",
    "print(rmu_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unlearn\n",
       "GA     51\n",
       "GD     51\n",
       "RMU    51\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_runs_df_deduplicated[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_runs_df_deduplicated\n",
    "\n",
    "categories = {\n",
    "    \"No Intervention\": data[data[\"interventions\"].apply(lambda x: x == [])].copy(),\n",
    "    \"Editing\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\"])].copy(),\n",
    "    \"Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\"])].copy(),\n",
    "    \"Edit to Compression\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"compress\"])].copy(),\n",
    "    \"Compression to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"edit\"])].copy(),\n",
    "    \"Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\"])].copy(),\n",
    "    \"Edit to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"edit\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Edit\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"edit\"])].copy(),\n",
    "    \"Compress to Unlearn\": data[data[\"interventions\"].apply(lambda x: x == [\"compress\", \"unlearn\"])].copy(),\n",
    "    \"Unlearn to Compress\": data[data[\"interventions\"].apply(lambda x: x == [\"unlearn\", \"compress\"])].copy()\n",
    "}\n",
    "\n",
    "assert len(categories[\"No Intervention\"]) == 1, f\"{len(categories['No Intervention'])} != 1\"\n",
    "assert len(categories[\"Editing\"]) == 3, f\"{len(categories['Editing'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compression\"])\n",
    "assert len(categories[\"Compression\"]) == (awq_settings + gptq_settings + wanda_count + sparsegpt_count), f\"{len(categories['Compression'])} != {awq_settings + gptq_settings + wanda_count + sparsegpt_count}\"\n",
    "\n",
    "# assert len(categories[\"Edit to Compression\"]) == editor_count // 2, f\"{len(categories['Edit to Compression'])} != {editor_count // 2}\"\n",
    "\n",
    "assert len(categories[\"Compression to Edit\"]) == (editor_count // 2 )- 3, f\"{len(categories['Compression to Edit'])} != {editor_count // 2}\" # TODO: Fix this by getting the latest results\n",
    "assert len(categories[\"Unlearn\"]) == 3, f\"{len(categories['Unlearn'])} != 3\"\n",
    "assert len(categories[\"Edit to Unlearn\"]) == 9, f\"{len(categories['Edit to Unlearn'])} != 3\"\n",
    "assert len(categories[\"Unlearn to Edit\"]) == 9, f\"{len(categories['Unlearn to Edit'])} != 3\"\n",
    "\n",
    "# display(categories[\"Compress to Unlearn\"])\n",
    "# assert len(categories[\"Compress to Unlearn\"]) == rmu_count // 2, f\"{len(categories['Compress to Unlearn'])} != {rmu_count // 2}\"\n",
    "\n",
    "# display(categories[\"Unlearn to Compress\"])\n",
    "# assert len(categories[\"Unlearn to Compress\"]) == rmu_count // 2, f\"{len(categories['Unlearn to Compress'])} != {rmu_count // 2}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Results Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set the font family to serif\n",
    "plt.rcParams[\"font.family\"] = \"serif\"\n",
    "\n",
    "# Seaborn settings\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette(\"colorblind\")\n",
    "sns.color_palette(\"pastel\")\n",
    "\n",
    "# plotting constants\n",
    "TITLE_FONT_SIZE = 18\n",
    "LEGEND_FONT_SIZE = 12\n",
    "WSPACE = 0.3\n",
    "FIGURE_HEIGHT = 3\n",
    "LINE_WIDTH = 2\n",
    "FIG_SIZE = 3\n",
    "MARKER_SIZE = 8\n",
    "X_LABEL_ROTATION = 20\n",
    "\n",
    "# Set colors for compositons with compression\n",
    "colors = {\"Wanda\": \"C1\", \"SparseGPT\": \"C2\", \"AWQ\": \"C3\", \"GPTQ\": \"C4\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Composability Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'GA'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m second_intervention \u001b[38;5;129;01min\u001b[39;00m intervention_names:\n\u001b[1;32m     19\u001b[0m     first_intervention_type \u001b[38;5;241m=\u001b[39m intervention_type[first_intervention]\n\u001b[0;32m---> 20\u001b[0m     second_intervention_type \u001b[38;5;241m=\u001b[39m \u001b[43mintervention_type\u001b[49m\u001b[43m[\u001b[49m\u001b[43msecond_intervention\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m first_intervention_type \u001b[38;5;241m==\u001b[39m second_intervention_type:\n\u001b[1;32m     22\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'GA'"
     ]
    }
   ],
   "source": [
    "intervention_names = [intervention for intervention in list(data[\"edit\"].unique()) + list(data[\"unlearn\"].unique()) + list(data[\"compression\"].unique()) if intervention is not None]\n",
    "intervention_type = {\n",
    "    \"LoRA\": \"edit\",\n",
    "    \"MEMIT\": \"edit\",\n",
    "    \"Fine-tune\": \"edit\",\n",
    "    \"SparseGPT\": \"compression\",\n",
    "    \"Wanda\": \"compression\",\n",
    "    \"GPTQ\": \"compression\",\n",
    "    \"AWQ\": \"compression\",\n",
    "    \"RMU\": \"unlearn\"\n",
    "}\n",
    "default_value = None\n",
    "\n",
    "mmlu_heatmap_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "wmdp_heatmap_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "rewrite_heatmap_data = pd.DataFrame(index=intervention_names, columns=intervention_names, dtype=float, data=default_value)\n",
    "for first_intervention in intervention_names:\n",
    "    for second_intervention in intervention_names:\n",
    "        first_intervention_type = intervention_type[first_intervention]\n",
    "        second_intervention_type = intervention_type[second_intervention]\n",
    "        if first_intervention_type == second_intervention_type:\n",
    "            continue\n",
    "\n",
    "        compositions = data[(data[first_intervention_type] == first_intervention) & (data[second_intervention_type] == second_intervention)]\n",
    "        if first_intervention in [\"SparseGPT\", \"Wanda\"] or second_intervention in [\"SparseGPT\", \"Wanda\"]:\n",
    "            compositions = compositions[compositions[\"sparsity_ratio\"] == 0.25]\n",
    "        elif first_intervention in [\"GPTQ\", \"AWQ\"] or second_intervention in [\"GPTQ\", \"AWQ\"]:\n",
    "            compositions = compositions[compositions[\"wbits\"] == 4]\n",
    "        \n",
    "        assert len(compositions) == 2, f\"Expected 2 compositions for {first_intervention} and {second_intervention}, but found {len(compositions)}\"\n",
    "        \n",
    "        mmlu_diff = abs(compositions[\"mmlu accuracy\"].iloc[0] - compositions[\"mmlu accuracy\"].iloc[1]).round(4)\n",
    "        mmlu_heatmap_data[first_intervention][second_intervention] = mmlu_diff\n",
    "        \n",
    "        avg_wmdp_diff = abs(((compositions.iloc[0][\"wmdp_cyber accuracy\"] + compositions.iloc[0][\"wmdp_bio accuracy\"]) / 2) - ((compositions.iloc[1][\"wmdp_cyber accuracy\"] + compositions.iloc[1][\"wmdp_bio accuracy\"]) / 2)).round(4)\n",
    "        wmdp_heatmap_data[first_intervention][second_intervention] = avg_wmdp_diff\n",
    "        \n",
    "        rewrite_diff = abs(compositions[\"Rewrite accuracy\"].iloc[0] - compositions[\"Rewrite accuracy\"].iloc[1]).round(4)\n",
    "        rewrite_heatmap_data[first_intervention][second_intervention] = rewrite_diff\n",
    "        \n",
    "# print(\"MMLU\")\n",
    "# display(mmlu_heatmap_data)\n",
    "\n",
    "# print(\"WMDP\")\n",
    "# display(wmdp_heatmap_data)\n",
    "\n",
    "# print(\"Rewrite\")\n",
    "# display(rewrite_heatmap_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three heatmaps next two eachother, one for each frame\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6 * FIG_SIZE, 2 * FIG_SIZE))\n",
    "y_labels = {\n",
    "    0: \"MMLU Acc\",\n",
    "    1: \"WMDP Acc\",\n",
    "    2: \"Edit Success\"\n",
    "}\n",
    "\n",
    "sns.heatmap(mmlu_heatmap_data, annot=True, fmt=\".1%\", cmap=\"coolwarm\", ax=axes[0], cbar=False)\n",
    "sns.heatmap(wmdp_heatmap_data, annot=True, fmt=\".1%\", cmap=\"coolwarm\", ax=axes[1], cbar=False)\n",
    "sns.heatmap(rewrite_heatmap_data, annot=True, fmt=\".1%\", cmap=\"coolwarm\", ax=axes[2], cbar=False)\n",
    "\n",
    "# roate x labels\n",
    "for ax in axes:\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation=X_LABEL_ROTATION)\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    ax.set_ylabel(y_labels[i], fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "# add padding for labels\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")\n",
    "\n",
    "plt.savefig(\"figures/delta_heatmaps.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Editing under Compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_order_label(row):\n",
    "    interventions = row[\"interventions\"]\n",
    "    first_method = \"\"\n",
    "    second_method = \"\"\n",
    "    if interventions[0] == \"edit\":\n",
    "        first_method = row[\"edit\"]\n",
    "    elif interventions[0] == \"compress\":\n",
    "        first_method = row[\"compression\"]\n",
    "    elif interventions[0] == \"unlearn\":\n",
    "        first_method = row[\"unlearn\"]\n",
    "    \n",
    "    if interventions[1] == \"edit\":\n",
    "        second_method = row[\"edit\"]\n",
    "    elif interventions[1] == \"compress\":\n",
    "        second_method = row[\"compression\"]\n",
    "    elif interventions[1] == \"unlearn\":\n",
    "        second_method = row[\"unlearn\"]\n",
    "    \n",
    "    return f\"{first_method}→{second_method}\"\n",
    "\n",
    "def wrap_label(interventions):\n",
    "    first_intervention, second_intervention = interventions[0], interventions[1]\n",
    "    first_letter_upper = first_intervention[0].upper()\n",
    "    second_letter_upper = second_intervention[0].upper()\n",
    "    \n",
    "    # EX: E $\\rightarrow$ C\n",
    "    return f\"{first_letter_upper}$\\\\rightarrow${second_letter_upper}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create mock records for baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want instances where editing has been applied but there is no unlearning or compression. In these cases, set wbits=16 and sparsity=0 \n",
    "baseline_editors = data[(data[\"edit\"].notnull()) & (data[\"unlearn\"].isnull()) & (data[\"compression\"].isnull()) & (data[\"interventions\"].apply(lambda x: x == [\"edit\"]))].copy()\n",
    "baseline_editors[\"wbits\"] = 16\n",
    "baseline_editors[\"sparsity_ratio\"] = 0\n",
    "news_records = []\n",
    "\n",
    "# Edit and Compress\n",
    "for editing_method in [\"LoRA\", \"MEMIT\", \"Fine-tune\"]:\n",
    "    baseline_record = baseline_editors[baseline_editors[\"edit\"] == editing_method]\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        edit_first_record = baseline_record.copy()\n",
    "        edit_first_record[\"compression\"] = compression_method\n",
    "        edit_first_record[\"interventions\"] = [[\"edit\", \"compress\"]]\n",
    "        news_records.append(edit_first_record)\n",
    "\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"edit\"]]\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "baseline_unlearners = data[(data[\"edit\"].isnull()) & (data[\"unlearn\"].notnull()) & (data[\"compression\"].isnull()) & (data[\"interventions\"].apply(lambda x: x == [\"unlearn\"]))].copy()\n",
    "\n",
    "# Compress and Unlearn\n",
    "for unlearn_method in [\"RMU\", \"GA\", \"GD\"]:\n",
    "    baseline_record = baseline_unlearners[baseline_unlearners[\"unlearn\"] == unlearn_method]\n",
    "\n",
    "    for compression_method in [\"SparseGPT\", \"Wanda\", \"GPTQ\", \"AWQ\"]:\n",
    "        compress_first_record = baseline_record.copy()\n",
    "        compress_first_record[\"unlearn\"] = unlearn_method\n",
    "        compress_first_record[\"compression\"] = compression_method\n",
    "        compress_first_record[\"interventions\"] = [[\"compress\", \"unlearn\"]]\n",
    "        news_records.append(compress_first_record)\n",
    "\n",
    "        unlearn_first_record = baseline_record.copy()\n",
    "        unlearn_first_record[\"unlearn\"] = unlearn_method\n",
    "        unlearn_first_record[\"compression\"] = compression_method\n",
    "        unlearn_first_record[\"interventions\"] = [[\"unlearn\", \"compress\"]]\n",
    "        news_records.append(unlearn_first_record)\n",
    "\n",
    "baseline_records = pd.concat(news_records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined Pruning and Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add mock baseline records to the frame used for plotting\n",
    "data = pd.concat([data, baseline_records])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "# pruning_frame = pruning_frame[pruning_frame[\"edit\"] != \"Fine-tune\"]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame = quantization_frame[quantization_frame[\"edit\"] != \"Fine-tune\"]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(3, 4, figsize=(5 * FIG_SIZE, 3 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Rewrite accuracy\",\n",
    "    1: \"Generalization\",\n",
    "    2: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    0: r\"Edit Success$ \\uparrow$\",\n",
    "    1: r\"Generalization$ \\uparrow$\",\n",
    "    2: r\"MMLU$ \\uparrow$\"\n",
    "}\n",
    "column_edit_methods = {\n",
    "    0: \"MEMIT\",\n",
    "    1: \"LoRA\",\n",
    "    2: \"MEMIT\",\n",
    "    3: \"LoRA\",\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    2: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    3: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 2 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"edit\"] == column_edit_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"MEMIT\", \"LoRA\", \"Fine-tune\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        if row_index != 2:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        else:\n",
    "            ax.set_ylim(0.2, 0.65)\n",
    "            ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "            if col_index < 2:\n",
    "                ax.text(0.35, 0.28, \"Random\", color=\"darkgray\", ha=\"center\")\n",
    "            else:\n",
    "                ax.text(8, 0.28, \"Random\", color=\"darkgray\", ha=\"right\")\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_edit_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[row_index], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 2:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 2 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 2:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_editors_compression.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 X 3 for Pruning and Quantization (Two Plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame[\"edit\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"edit\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(3, 6, figsize=(6 * FIG_SIZE, 3 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Rewrite accuracy\",\n",
    "    1: \"Generalization\",\n",
    "    2: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    0: r\"Edit Success$ \\uparrow$\",\n",
    "    1: r\"Generalization$ \\uparrow$\",\n",
    "    2: r\"MMLU$ \\uparrow$\"\n",
    "}\n",
    "column_edit_methods = {\n",
    "    0: \"MEMIT\",\n",
    "    1: \"LoRA\",\n",
    "    2: \"Fine-tune\",\n",
    "    3: \"MEMIT\",\n",
    "    4: \"LoRA\",\n",
    "    5: \"Fine-tune\"\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    # MEMIT and WANDA + SparseGPT\n",
    "    0: [(\"MEMIT→SparseGPT\", \"SparseGPT→MEMIT\"), (\"MEMIT→Wanda\", \"Wanda→MEMIT\")],\n",
    "    # LoRA and WANDA + SparseGPT\n",
    "    1: [(\"LoRA→SparseGPT\", \"SparseGPT→LoRA\"), (\"LoRA→Wanda\", \"Wanda→LoRA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"Fine-tune→SparseGPT\", \"SparseGPT→Fine-tune\"), (\"Fine-tune→Wanda\", \"Wanda→Fine-tune\")],\n",
    "    # MEMIT and GPTQ + AWQ\n",
    "    3: [(\"MEMIT→GPTQ\", \"GPTQ→MEMIT\"), (\"MEMIT→AWQ\", \"AWQ→MEMIT\")],\n",
    "    # LoRA and GPTQ + AWQ\n",
    "    4: [(\"LoRA→GPTQ\", \"GPTQ→LoRA\"), (\"LoRA→AWQ\", \"AWQ→LoRA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"Fine-tune→GPTQ\", \"GPTQ→Fine-tune\"), (\"Fine-tune→AWQ\", \"AWQ→Fine-tune\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"edit\"] == column_edit_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"MEMIT\", \"LoRA\", \"Fine-tune\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        if row_index != 2:\n",
    "            ax.set_ylim(0, 1.05)\n",
    "        else:\n",
    "            ax.set_ylim(0.2, 0.65)\n",
    "            ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "            if col_index < 3:\n",
    "                ax.text(0.35, 0.28, \"Random\", color=\"darkgray\", ha=\"center\")\n",
    "            else:\n",
    "                ax.text(8, 0.28, \"Random\", color=\"darkgray\", ha=\"center\")\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_edit_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[row_index], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 2:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 2:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE)\n",
    "plt.savefig(\"figures/main_results_editors_compression_with_ft.pdf\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot: Unlearning under Compression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"unlearn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_frame = data[((data[\"compression\"] == \"SparseGPT\") | (data[\"compression\"] == \"Wanda\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "pruning_frame[\"Avg WMDP\"] = (pruning_frame[\"wmdp_bio accuracy\"] + pruning_frame[\"wmdp_cyber accuracy\"]) / 2\n",
    "pruning_frame[\"order\"] = pruning_frame.apply(get_order_label, axis=1)\n",
    "pruning_frame = pruning_frame.sort_values(by=\"order\")\n",
    "pruning_frame[\"unlearn\"] = pruning_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "quantization_frame = data[((data[\"compression\"] == \"GPTQ\") | (data[\"compression\"] == \"AWQ\")) & (data[\"unlearn\"] != None) & (data[\"interventions\"].apply(lambda x: len(x) > 1))]\n",
    "quantization_frame[\"Avg WMDP\"] = (quantization_frame[\"wmdp_bio accuracy\"] + quantization_frame[\"wmdp_cyber accuracy\"]) / 2\n",
    "quantization_frame[\"order\"] = quantization_frame.apply(get_order_label, axis=1)\n",
    "quantization_frame = quantization_frame.sort_values(by=\"order\")\n",
    "quantization_frame[\"unlearn\"] = quantization_frame[\"unlearn\"].apply(lambda x: x.upper() if x is not None else None)\n",
    "\n",
    "# 4 columns and 3 rows\n",
    "fig, axes = plt.subplots(2, 6, figsize=(6 * FIG_SIZE, 2 * FIG_SIZE))\n",
    "row_metrics = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\",\n",
    "}\n",
    "row_labels = {\n",
    "    \"Avg WMDP\": r\"WMDP $\\downarrow$\",\n",
    "    \"mmlu accuracy\": r\"MMLU $\\uparrow$\"\n",
    "}\n",
    "row_label_map = {\n",
    "    0: \"Avg WMDP\",\n",
    "    1: \"mmlu accuracy\"\n",
    "}\n",
    "column_unlearn_methods = {\n",
    "    0: \"RMU\",\n",
    "    1: \"GA\",\n",
    "    2: \"GD\",\n",
    "    3: \"RMU\",\n",
    "    4: \"GA\",\n",
    "    5: \"GD\",\n",
    "}\n",
    "\n",
    "compositions_by_col = {\n",
    "    # RMU and WANDA + SparseGPT\n",
    "    0: [(\"RMU→SparseGPT\", \"SparseGPT→RMU\"), (\"RMU→Wanda\", \"Wanda→RMU\")],\n",
    "    # GA and WANDA + SparseGPT\n",
    "    1: [(\"GA→SparseGPT\", \"SparseGPT→GA\"), (\"GA→Wanda\", \"Wanda→GA\")],\n",
    "    # FT and WANDA + SparseGPT\n",
    "    2: [(\"GD→SparseGPT\", \"SparseGPT→GD\"), (\"GD→Wanda\", \"Wanda→GD\")],\n",
    "    # RMU and GPTQ + AWQ\n",
    "    3: [(\"RMU→GPTQ\", \"GPTQ→RMU\"), (\"RMU→AWQ\", \"AWQ→RMU\")],\n",
    "    # GA and GPTQ + AWQ\n",
    "    4: [(\"GA→GPTQ\", \"GPTQ→GA\"), (\"GA→AWQ\", \"AWQ→GA\")],\n",
    "    # FT and GPTQ + AWQ\n",
    "    5: [(\"GD→GPTQ\", \"GPTQ→GD\"), (\"GD→AWQ\", \"AWQ→GD\")],\n",
    "}\n",
    "for row_index, y_metric in row_metrics.items():\n",
    "    for col_index, plotting_frame in enumerate([pruning_frame, pruning_frame, pruning_frame, quantization_frame, quantization_frame, quantization_frame]):\n",
    "        ax = axes[row_index][col_index]\n",
    "        x_metric = \"sparsity_ratio\" if col_index < 3 else \"wbits\"\n",
    "        plotting_frame = plotting_frame[plotting_frame[\"unlearn\"] == column_unlearn_methods[col_index]]\n",
    "\n",
    "        for composition in compositions_by_col[col_index]:\n",
    "            compression_method = [method for method in composition[0].split(\"→\") if method not in [\"RMU\", \"GA\", \"GD\"]][0]\n",
    "            first_line = plotting_frame[plotting_frame[\"order\"] == composition[0]]\n",
    "            first_line[\"label\"] = first_line[\"order\"].apply(wrap_label)\n",
    "            second_line = plotting_frame[plotting_frame[\"order\"] == composition[1]].sort_values(x_metric)\n",
    "            second_line[\"label\"] = second_line[\"order\"].apply(wrap_label)\n",
    "            if compression_method in [\"AWQ\", \"GPTQ\"]:\n",
    "                first_line = first_line.sort_values(x_metric, ascending=False)\n",
    "                second_line = second_line.sort_values(x_metric, ascending=False)\n",
    "            else:\n",
    "                first_line = first_line.sort_values(x_metric)\n",
    "                second_line = second_line.sort_values(x_metric)\n",
    "\n",
    "            ax.plot(first_line[x_metric], first_line[y_metric], marker=\"o\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[0]}\")\n",
    "            ax.plot(second_line[x_metric], second_line[y_metric], markerfacecolor='none', marker=\"o\", ls=\"--\", markersize=MARKER_SIZE, color=colors[compression_method], label=f\"{composition[1]}\")\n",
    "            ax.fill_between(\n",
    "                x=first_line[x_metric], y1=first_line[y_metric], y2=second_line[y_metric],\n",
    "                alpha=0.3,\n",
    "                color=colors[compression_method]\n",
    "            )\n",
    "\n",
    "        # if y_metric == \"mmlu accuracy\":\n",
    "        #     ax.set_ylim(0, 0.65)\n",
    "        # else:\n",
    "        #     ax.set_ylim(0.2, 0.65)\n",
    "        #     ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "        ax.set_ylim(0.25, 0.65)\n",
    "        ax.axhline(y=0.25, color=\"gray\", linestyle=\"--\")\n",
    "\n",
    "        if row_index == 0:\n",
    "            title = column_unlearn_methods[col_index]\n",
    "            ax.set_title(title, fontsize=TITLE_FONT_SIZE)\n",
    "\n",
    "            # remove x ticks\n",
    "            ax.set_xticks([])\n",
    "        else:\n",
    "            ax.set_title(\"\")\n",
    "\n",
    "        if col_index == 0:\n",
    "            ax.set_ylabel(row_labels[list(row_labels.keys())[row_index]], fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "\n",
    "        if row_index == 2:\n",
    "            ax.set_xlabel(\"Sparsity\" if col_index < 3 else \"Bits\", fontsize=TITLE_FONT_SIZE)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "        if row_index == 1:\n",
    "            ax.legend(fontsize=LEGEND_FONT_SIZE, frameon=False, loc=\"upper center\", bbox_to_anchor=(0.5, -0.3), ncol=1)\n",
    "\n",
    "fig.subplots_adjust(wspace=WSPACE, hspace=WSPACE * 0.25)\n",
    "plt.savefig(\"figures/main_results_unlearn_compression_with_ga.pdf\", bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
