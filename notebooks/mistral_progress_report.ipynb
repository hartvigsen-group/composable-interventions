{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "import wandb\n",
    "api = wandb.Api()\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting_columns = [\n",
    "    # Overall\n",
    "    \"tag\",\n",
    "    # \"seed\",\n",
    "    \"_timestamp\",\n",
    "\n",
    "    # Interventions\n",
    "    \"interventions\", \"edit\", \"unlearn\", \"compression\", \"model_name\",\n",
    "\n",
    "    # Editing\n",
    "    \"edit_set\", \n",
    "    \"edit_dataset\", \"number_of_edits\",\n",
    "\n",
    "    # Unlearning\n",
    "    \"rmu_layer_id\",\n",
    "\n",
    "    # Compression\n",
    "    \"wbits\", \"compression_dataset\", \"sparsity_ratio\",\n",
    "]\n",
    "evaluation_columns = [\n",
    "    \"qa_question_count_limit\",  # An artifical max number of questions to ask during evaluation. Should be none when not debugging.\n",
    "    \"mmlu accuracy\",            # The accuracy of the model on the MMLU dataset. This measures overall model utility. Llama-3 should be ~62%\n",
    "    \"wmdp_bio accuracy\",        # The accuracy of the model on the WMDP bio split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"wmdp_cyber accuracy\",      # The accuracy of the model on the WMDP cyber split. This is the unlearning target. Should be ~25% when RMU is applied.\n",
    "    \"PPL\",                      # TODO:\n",
    "    \"PPL edits\",                # Perplexity for the edits. Should be low when editing is applied.\n",
    "    \"PPl QA\",                   # Perplexity for the QA. Should be low when QA is applied.\n",
    "    \"Generalization\",           # TODO: \n",
    "    \"FLOPs\",                    # TODO: \n",
    "    \"Success recall\",           # TODO:\n",
    "    \"Generalization recall\",    # TODO:\n",
    "    \"Locality\",                 # TODO:\n",
    "    \"Average bits\",             # TODO:\n",
    "    \"Rewrite accuracy\",         # TODO:\n",
    "    \"PPl edits unmasked\",       # TODO:\n",
    "    \"Local recall\",             # TODO:\n",
    "    \"Latency\",                  # TODO:\n",
    "]\n",
    "relevant_columns = setting_columns + evaluation_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Composable_Interventions has all the results\n",
    "project_paths = [\"dri-ice/Composable_Interventions\",]\n",
    "\n",
    "filter_dict = { \"state\": \"finished\" }\n",
    "data_frames = []\n",
    "for project_path in project_paths:\n",
    "    runs = api.runs(project_path, filters=filter_dict)\n",
    "    \n",
    "    # Iterate over eachrun and capture the c        onfig and summary metrics\n",
    "    for run in tqdm(runs, desc=project_path):\n",
    "        try:\n",
    "            run_start_datetime = datetime.fromtimestamp(run.summary_metrics[\"_timestamp\"])\n",
    "            start_cutoff = datetime.strptime(\"2024-05-18 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            end_cutoff = datetime.strptime(\"2024-09-19 00:00:00\", \"%Y-%m-%d %H:%M:%S\")\n",
    "            if run_start_datetime < start_cutoff or run_start_datetime > end_cutoff:\n",
    "                continue\n",
    "\n",
    "            skip_tags = [\"test\", \"hparam_search\"]\n",
    "            should_skip = False\n",
    "            for tag in skip_tags:\n",
    "                if tag in run.config[\"tag\"].lower():\n",
    "                    should_skip = True\n",
    "            \n",
    "            if should_skip:\n",
    "                continue\n",
    "\n",
    "            config_frame = pd.DataFrame([run.config])\n",
    "            summary_frame = pd.DataFrame([run.summary_metrics])\n",
    "            combined_frame = pd.concat([config_frame, summary_frame], axis=1)\n",
    "            data_frames.append(combined_frame)\n",
    "        except Exception as e:\n",
    "            continue\n",
    "            # print(f\"Error processing run {run.id}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total experiment combinations for Mistral ablation: 51\n"
     ]
    }
   ],
   "source": [
    "unlearning_interventions = [\"rmu\"]\n",
    "editing_interventions = [\"lora\"]\n",
    "pruning_interventions = [\"wanda\"]\n",
    "pruning_levels = [0.25, 0.35, 0.45, 0.55, 0.65, 0.75]\n",
    "quant_interventions = [\"awq\"]\n",
    "quant_levels = [2, 3, 4, 5, 6, 8]\n",
    "\n",
    "experiment_combinations = []\n",
    "\n",
    "# Unlearning and Editing\n",
    "for unlearner in unlearning_interventions:\n",
    "    for editor in editing_interventions:\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"unlearn\", \"edit\"],\n",
    "            \"edit\": editor,\n",
    "            \"unlearn\": unlearner,\n",
    "            \"wbits\": None,\n",
    "            \"sparsity_ratio\": None,\n",
    "        })\n",
    "        experiment_combinations.append({\n",
    "            \"interventions\": [\"edit\", \"unlearn\"],\n",
    "            \"edit\": editor,\n",
    "            \"unlearn\": unlearner,\n",
    "            \"wbits\": None,\n",
    "            \"sparsity_ratio\": None,\n",
    "        })\n",
    "\n",
    "# Unlearning and Compression\n",
    "for unlearner in unlearning_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"],\n",
    "                \"edit\": None,\n",
    "                \"unlearn\": unlearner,\n",
    "                \"compression\": pruner,\n",
    "                \"sparsity_ratio\": pruning_level,\n",
    "            })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"],\n",
    "                \"edit\": None,\n",
    "                \"unlearn\": unlearner,\n",
    "                \"compression\": pruner,\n",
    "                \"sparsity_ratio\": pruning_level,\n",
    "            })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"unlearn\", \"compression\"],\n",
    "                \"edit\": None,\n",
    "                \"unlearn\": unlearner,\n",
    "                \"compression\": quantizer,\n",
    "                \"wbits\": quant_level,\n",
    "                \"sparsity_ratio\": None,\n",
    "            })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"unlearn\"],\n",
    "                \"edit\": None,\n",
    "                \"unlearn\": unlearner,\n",
    "                \"compression\": quantizer,\n",
    "                \"wbits\": quant_level,\n",
    "                \"sparsity_ratio\": None,\n",
    "            })\n",
    "\n",
    "# Editing and Compression\n",
    "for editor in editing_interventions:\n",
    "    for pruner in pruning_interventions:\n",
    "        for pruning_level in pruning_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"],\n",
    "                \"edit\": editor,\n",
    "                \"unlearn\": None,\n",
    "                \"compression\": pruner,\n",
    "                \"sparsity_ratio\": pruning_level,\n",
    "            })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"],\n",
    "                \"edit\": editor,\n",
    "                \"unlearn\": None,\n",
    "                \"compression\": pruner,\n",
    "                \"sparsity_ratio\": pruning_level,\n",
    "            })\n",
    "\n",
    "    for quantizer in quant_interventions:\n",
    "        for quant_level in quant_levels:\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"edit\", \"compression\"],\n",
    "                \"edit\": editor,\n",
    "                \"unlearn\": None,\n",
    "                \"compression\": quantizer,\n",
    "                \"wbits\": quant_level,\n",
    "                \"sparsity_ratio\": None,\n",
    "            })\n",
    "            experiment_combinations.append({\n",
    "                \"interventions\": [\"compression\", \"edit\"],\n",
    "                \"edit\": editor,\n",
    "                \"unlearn\": None,\n",
    "                \"compression\": quantizer,\n",
    "                \"wbits\": quant_level,\n",
    "                \"sparsity_ratio\": None,\n",
    "            })\n",
    "\n",
    "# No interventions\n",
    "experiment_combinations.append({\n",
    "    \"interventions\": [],\n",
    "    \"edit\": None,\n",
    "    \"unlearn\": None,\n",
    "    \"compression\": None,\n",
    "    \"wbits\": None,\n",
    "    \"sparsity_ratio\": None,\n",
    "})\n",
    "\n",
    "print(f\"Total experiment combinations for Mistral ablation: {len(experiment_combinations)}\")\n",
    "for experiment in experiment_combinations:\n",
    "    \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lm-compose",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
